{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspirational Notebooks\n",
    "### Generating new festures according to these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected\n",
    "* https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "* https://www.kaggle.com/aharless/swetha-s-xgboost-revised\n",
    "* https://www.kaggle.com/bk0000/non-blending-lightgbm-model-lb-0-977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            200000 non-null int64\n",
      "ip                                    200000 non-null int64\n",
      "app                                   200000 non-null int64\n",
      "device                                200000 non-null int64\n",
      "os                                    200000 non-null int64\n",
      "channel                               200000 non-null int64\n",
      "click_time                            200000 non-null object\n",
      "attributed_time                       348 non-null object\n",
      "is_attributed                         200000 non-null int64\n",
      "day                                   200000 non-null int64\n",
      "hour                                  200000 non-null int64\n",
      "minute                                200000 non-null int64\n",
      "second                                200000 non-null int64\n",
      "ip_confRate                           200000 non-null float64\n",
      "app_confRate                          200000 non-null float64\n",
      "device_confRate                       200000 non-null float64\n",
      "os_confRate                           200000 non-null float64\n",
      "channel_confRate                      200000 non-null float64\n",
      "app_channel_confRate                  200000 non-null float64\n",
      "app_os_confRate                       200000 non-null float64\n",
      "app_device_confRate                   200000 non-null float64\n",
      "channel_os_confRate                   200000 non-null float64\n",
      "channel_device_confRate               200000 non-null float64\n",
      "os_device_confRate                    200000 non-null float64\n",
      "ip_app_channel_var_day                134217 non-null float64\n",
      "ip_app_os_var_hour                    139465 non-null float64\n",
      "ip_day_channel_var_hour_x             151335 non-null float64\n",
      "ip_day_hour_count_channel             200000 non-null int64\n",
      "ip_app_count_channel                  200000 non-null int64\n",
      "ip_app_os_count_channel               200000 non-null int64\n",
      "ip_app_day_hour_count_channel         200000 non-null int64\n",
      "ip_app_channel_mean_hour              200000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             200000 non-null float64\n",
      "app_count_channel                     200000 non-null int64\n",
      "channel_count_app                     200000 non-null int64\n",
      "ip_nunique_channel                    200000 non-null int64\n",
      "ip_nunique_app                        200000 non-null int64\n",
      "ip_day_nunique_hour                   200000 non-null int64\n",
      "ip_app_nunique_os                     200000 non-null int64\n",
      "ip_nunique_device                     200000 non-null int64\n",
      "app_nunique_channel                   200000 non-null int64\n",
      "ip_device_os_nunique_app              200000 non-null int64\n",
      "ip_device_os_cumcount_app             200000 non-null int64\n",
      "ip_cumcount_app                       200000 non-null int64\n",
      "ip_cumcount_os                        200000 non-null int64\n",
      "ip_day_channel_var_hour_y             151335 non-null float64\n",
      "ip_nextClick                          197456 non-null float64\n",
      "ip_app_nextClick                      163726 non-null float64\n",
      "ip_channel_nextClick                  138039 non-null float64\n",
      "ip_os_nextClick                       182531 non-null float64\n",
      "ip_app_device_os_channel_nextClick    86990 non-null float64\n",
      "ip_os_device_nextClick                181508 non-null float64\n",
      "ip_os_device_app_nextClick            120449 non-null float64\n",
      "prev_identical_clicks                 200000 non-null int64\n",
      "future_identical_clicks               200000 non-null int64\n",
      "prev_app_clicks                       200000 non-null int64\n",
      "future_app_clicks                     200000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 87.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_train= pd.read_csv('data/train.csv',nrows=200000, parse_dates=['click_time'])\n",
    "df_train = pd.read_csv('data/train_new_cols.csv',nrows=200000) #train data subset, original too large\n",
    "df_train.dropna()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
       "       'attributed_time', 'is_attributed', 'day', 'hour', 'minute',\n",
       "       'second', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
       "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
       "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
       "       'channel_device_confRate', 'os_device_confRate',\n",
       "       'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
       "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
       "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
       "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
       "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
       "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
       "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
       "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
       "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
       "       'ip_day_channel_var_hour_y', 'ip_nextClick', 'ip_app_nextClick',\n",
       "       'ip_channel_nextClick', 'ip_os_nextClick',\n",
       "       'ip_app_device_os_channel_nextClick', 'ip_os_device_nextClick',\n",
       "       'ip_os_device_app_nextClick', 'prev_identical_clicks',\n",
       "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
    "       'attributed_time', 'is_attributed', 'prev_identical_clicks',\n",
    "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks']\n",
    "df_train = df_train.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>prev_identical_clicks</th>\n",
       "      <th>future_identical_clicks</th>\n",
       "      <th>prev_app_clicks</th>\n",
       "      <th>future_app_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114221</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:38:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74544</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 14:38:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "5   18787    3       1  16      379  2017-11-06 14:36:26             NaN   \n",
       "6  103022    3       1  23      379  2017-11-06 14:37:44             NaN   \n",
       "7  114221    3       1  19      379  2017-11-06 14:37:59             NaN   \n",
       "8  165970    3       1  13      379  2017-11-06 14:38:10             NaN   \n",
       "9   74544   64       1  22      459  2017-11-06 14:38:23             NaN   \n",
       "\n",
       "   is_attributed  prev_identical_clicks  future_identical_clicks  \\\n",
       "0              0                      0                        0   \n",
       "1              0                      0                        0   \n",
       "2              0                      0                        0   \n",
       "3              0                      0                        0   \n",
       "4              0                      0                        0   \n",
       "5              0                      0                        0   \n",
       "6              0                      0                        0   \n",
       "7              0                      0                        0   \n",
       "8              0                      0                        0   \n",
       "9              0                      0                        0   \n",
       "\n",
       "   prev_app_clicks  future_app_clicks  \n",
       "0                0                 18  \n",
       "1                0                 22  \n",
       "2                0                  9  \n",
       "3                0                 68  \n",
       "4                0                  0  \n",
       "5                0                  3  \n",
       "6                0                  5  \n",
       "7                0                 10  \n",
       "8                0                  3  \n",
       "9                0                  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199652\n",
       "1       348\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEFCAYAAAAmIwo/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_train, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            50000 non-null int64\n",
      "ip                                    50000 non-null int64\n",
      "app                                   50000 non-null int64\n",
      "device                                50000 non-null int64\n",
      "os                                    50000 non-null int64\n",
      "channel                               50000 non-null int64\n",
      "click_time                            50000 non-null object\n",
      "attributed_time                       88 non-null object\n",
      "is_attributed                         50000 non-null int64\n",
      "day                                   50000 non-null int64\n",
      "hour                                  50000 non-null int64\n",
      "minute                                50000 non-null int64\n",
      "second                                50000 non-null int64\n",
      "ip_confRate                           50000 non-null float64\n",
      "app_confRate                          50000 non-null float64\n",
      "device_confRate                       50000 non-null float64\n",
      "os_confRate                           50000 non-null float64\n",
      "channel_confRate                      50000 non-null float64\n",
      "app_channel_confRate                  50000 non-null float64\n",
      "app_os_confRate                       50000 non-null float64\n",
      "app_device_confRate                   50000 non-null float64\n",
      "channel_os_confRate                   50000 non-null float64\n",
      "channel_device_confRate               50000 non-null float64\n",
      "os_device_confRate                    50000 non-null float64\n",
      "ip_app_channel_var_day                34970 non-null float64\n",
      "ip_app_os_var_hour                    36809 non-null float64\n",
      "ip_day_channel_var_hour_x             38512 non-null float64\n",
      "ip_day_hour_count_channel             50000 non-null int64\n",
      "ip_app_count_channel                  50000 non-null int64\n",
      "ip_app_os_count_channel               50000 non-null int64\n",
      "ip_app_day_hour_count_channel         50000 non-null int64\n",
      "ip_app_channel_mean_hour              50000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             50000 non-null float64\n",
      "app_count_channel                     50000 non-null int64\n",
      "channel_count_app                     50000 non-null int64\n",
      "ip_nunique_channel                    50000 non-null int64\n",
      "ip_nunique_app                        50000 non-null int64\n",
      "ip_day_nunique_hour                   50000 non-null int64\n",
      "ip_app_nunique_os                     50000 non-null int64\n",
      "ip_nunique_device                     50000 non-null int64\n",
      "app_nunique_channel                   50000 non-null int64\n",
      "ip_device_os_nunique_app              50000 non-null int64\n",
      "ip_device_os_cumcount_app             50000 non-null int64\n",
      "ip_cumcount_app                       50000 non-null int64\n",
      "ip_cumcount_os                        50000 non-null int64\n",
      "ip_day_channel_var_hour_y             38512 non-null float64\n",
      "ip_nextClick                          48959 non-null float64\n",
      "ip_app_nextClick                      39531 non-null float64\n",
      "ip_channel_nextClick                  32900 non-null float64\n",
      "ip_os_nextClick                       44728 non-null float64\n",
      "ip_app_device_os_channel_nextClick    21355 non-null float64\n",
      "ip_os_device_nextClick                44410 non-null float64\n",
      "ip_os_device_app_nextClick            29197 non-null float64\n",
      "prev_identical_clicks                 50000 non-null int64\n",
      "future_identical_clicks               50000 non-null int64\n",
      "prev_app_clicks                       50000 non-null int64\n",
      "future_app_clicks                     50000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The ratio of df_train to df_test is 0.8 to 0.2 or 0.75 to 0.25\n",
    "df_test = pd.read_csv('data/train_new_cols.csv', nrows=50000,skiprows=range(1, 400000))\n",
    "df_test.dropna()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>prev_identical_clicks</th>\n",
       "      <th>future_identical_clicks</th>\n",
       "      <th>prev_app_clicks</th>\n",
       "      <th>future_app_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115115</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144498</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>237</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1556</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20266</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31564</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>265</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1732</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111114</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0  115115    8       1  13      145  2017-11-06 16:07:47             NaN   \n",
       "1   21633    1       1  19      178  2017-11-06 16:07:47             NaN   \n",
       "2  144498   12       1  17      178  2017-11-06 16:07:47             NaN   \n",
       "3   76919    2       1   6      237  2017-11-06 16:07:47             NaN   \n",
       "4    1556   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "5   67467   15       1  37      245  2017-11-06 16:07:47             NaN   \n",
       "6   20266   64       1  19      459  2017-11-06 16:07:47             NaN   \n",
       "7   31564   15       1  19      265  2017-11-06 16:07:47             NaN   \n",
       "8    1732    9       1  13      134  2017-11-06 16:07:47             NaN   \n",
       "9  111114   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "\n",
       "   is_attributed  prev_identical_clicks  future_identical_clicks  \\\n",
       "0              0                      3                        2   \n",
       "1              0                      1                        0   \n",
       "2              0                      0                        0   \n",
       "3              0                      0                        0   \n",
       "4              0                      0                        3   \n",
       "5              0                      4                        7   \n",
       "6              0                      0                        0   \n",
       "7              0                      0                        0   \n",
       "8              0                     28                        2   \n",
       "9              0                      0                        0   \n",
       "\n",
       "   prev_app_clicks  future_app_clicks  \n",
       "0                3                  2  \n",
       "1                1                  2  \n",
       "2                2                  3  \n",
       "3               24                 49  \n",
       "4                0                  5  \n",
       "5               14                 17  \n",
       "6                0                  1  \n",
       "7                4                  3  \n",
       "8               30                  2  \n",
       "9                2                  0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49912\n",
       "1       88\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsf8DoQTTGbbtqNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_test, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'prev_identical_clicks',\n",
       " 'future_identical_clicks',\n",
       " 'prev_app_clicks',\n",
       " 'future_app_clicks']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columes names except the click_time (object), attributed_time (object) and is_attributed\n",
    "train_cols = []\n",
    "for each_value in df_train.columns.values:\n",
    "    if each_value == 'click_time' or each_value == 'attributed_time' or each_value == 'is_attributed':\n",
    "        continue\n",
    "    train_cols.append(each_value)\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_X\n",
    "X_train = df_train.loc[:,train_cols]\n",
    "X_test = df_test.loc[:,train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_Y\n",
    "y_train = df_train[['is_attributed']]\n",
    "y_test = df_test[['is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_val = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    RF_model = RandomForestClassifier()\n",
    "    # Train the model\n",
    "    RF_fit = RF_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    RF_predict = RF_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    RF_acc = sklearn.metrics.accuracy_score(np.array(RF_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(RF_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return RF_fit, RF_predict, RF_acc, RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "# RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting & AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientBoosting_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    GB_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    # Train the model\n",
    "    GB_fit = GB_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    GB_predict = GB_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    GB_acc = sklearn.metrics.accuracy_score(np.array(GB_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(GB_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return GB_fit, GB_predict, GB_acc, GB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "# GB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    LG_model = LogisticRegression()\n",
    "    # Train the model\n",
    "    LG_fit = LG_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    LG_predict = LG_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    LG_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    return LG_fit, LG_predict, LG_acc, LG_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "# LG_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    svm_model = svm.SVC()\n",
    "    uniq = np.unique(y_train[9000:10000])\n",
    "    # Train the model\n",
    "    SVM_fit = svm_model.fit(X_train[9000:10000], y_train[9000:10000])\n",
    "    # Get the prediction of the test data\n",
    "    SVM_predict = svm_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    SVM_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                     np.array(y_test_val)[:])\n",
    "    return SVM_fit, SVM_predict, SVM_acc, svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_A(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ann_pre(X_train, y_train, X_test, y_test):\n",
    "    ann_model = shallow_net_A()\n",
    "    ann_summary = ann_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_ann = np.nan_to_num(X_train)\n",
    "    y_train_ann = np.nan_to_num(y_train)\n",
    "    X_test_ann = np.nan_to_num(X_test)\n",
    "    y_test_ann = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes), the original one has oly one class\n",
    "    n_classes = 2\n",
    "    y_train_ann = keras.utils.to_categorical(y_train_ann, n_classes)\n",
    "    y_test_ann = keras.utils.to_categorical(y_test_ann, n_classes)\n",
    "    # Training the model\n",
    "    ann_fit = ann_model.fit(X_train_ann, y_train_ann, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_ann, y_test_ann))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    ann_evaluate = ann_model.evaluate(X_test_ann, y_test_ann)\n",
    "    \n",
    "    # Using prediction\n",
    "    ann_pre = ann_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (ann_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ann_output = confusion_matrix(y_test_ann.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    ann_prediction_acc = ann_output[0][0]/(ann_output[0][0]+ann_output[1][0])\n",
    "    \n",
    "    return ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_C(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2, here we have more hidden layers with different activation\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='relu', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='tanh', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='elu', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_pre(X_train, y_train, X_test, y_test):\n",
    "    mlp_model = shallow_net_C()\n",
    "    mlp_summary = mlp_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_mlp = np.nan_to_num(X_train)\n",
    "    y_train_mlp = np.nan_to_num(y_train)\n",
    "    X_test_mlp = np.nan_to_num(X_test)\n",
    "    y_test_mlp = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes)\n",
    "    n_classes = 2\n",
    "    y_train_mlp = keras.utils.to_categorical(y_train_mlp, n_classes)\n",
    "    y_test_mlp = keras.utils.to_categorical(y_test_mlp, n_classes)\n",
    "    # Training the model\n",
    "    mlp_fit = mlp_model.fit(X_train_mlp, y_train_mlp, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_mlp, y_test_mlp))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    mlp_evaluate = mlp_model.evaluate(X_test_mlp, y_test_mlp)\n",
    "    \n",
    "    # Using prediction\n",
    "    mlp_pre = mlp_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (mlp_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mlp_output = confusion_matrix(y_test_mlp.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    mlp_prediction_acc = mlp_output[0][0]/(mlp_output[0][0]+mlp_output[1][0])\n",
    "    \n",
    "    return mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. RNN - Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnn_pre(df_train, train_rate=0.75):\n",
    "    # Set the dataset for train and test\n",
    "    df_rnn_train = df_train.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn_test = df_test.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn = df_rnn_train.append(df_rnn_test)\n",
    "    \n",
    "    pre_col_index = list(df_rnn_train).index('is_attributed')\n",
    "    dataset = df_rnn.values.astype('float32')\n",
    "    dataset = np.nan_to_num(dataset)\n",
    "    \n",
    "    # Normalize the dataset, set all the data of the dataset to be in the range between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(dataset) * train_rate)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    \n",
    "    # Use this function to prepare the train and test datasets for modeling\n",
    "    look_back = 1\n",
    "    trainY = train[:, pre_col_index]\n",
    "    trainX = np.delete(train, pre_col_index, axis = 1) \n",
    "    testY = test[:, pre_col_index]\n",
    "    testX = np.delete(test, pre_col_index, axis = 1) \n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features], here it changes the dimension from 2D to 3D\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(LSTM(5, input_shape=(1, len(trainX[0][0]))))\n",
    "    RNN_model.add(Dense(1))\n",
    "    RNN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    RNN_model.fit(trainX, trainY, epochs=10, batch_size=128, verbose=2)\n",
    "    \n",
    "    # Make predictions, trainPredict should be 1D array\n",
    "    trainPredict = RNN_model.predict(trainX)\n",
    "    testPredict = RNN_model.predict(testX)\n",
    "    \n",
    "    # Change the dimension from 3D to 2D\n",
    "    trainX_2D = trainX.transpose([1,0,2]).reshape(len(trainX),len(trainX[0][0]))\n",
    "    testX_2D = testX.transpose([1,0,2]).reshape(len(testX),len(testX[0][0]))\n",
    "    \n",
    "    # Append prediction back to the model\n",
    "    trainPredict_6cols = np.append(trainX_2D, trainPredict, 1)\n",
    "    testPredict_6cols = np.append(testX_2D, testPredict, 1)\n",
    "\n",
    "    # Invert predictions back to normal values\n",
    "    trainPredict_6cols = scaler.inverse_transform(trainPredict_6cols)\n",
    "    testPredict_6cols = scaler.inverse_transform(testPredict_6cols)\n",
    "    \n",
    "    # Calculating the RMSE\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict_6cols[:, pre_col_index]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict_6cols[:, pre_col_index]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    \n",
    "    final_prediction_train = np.where(trainPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    final_prediction_test = np.where(testPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    \n",
    "    # Change dimension from 2D to 1D\n",
    "    final_prediction_train = np.reshape(final_prediction_train, (-1, 1))\n",
    "    final_prediction_test = np.reshape(final_prediction_test, (-1, 1))\n",
    "    \n",
    "    # Counting the accuracy by using basic calculation\n",
    "    rnn_acc_train = sklearn.metrics.accuracy_score(np.array(final_prediction_train)[:], \n",
    "                                     np.array(trainY)[:])\n",
    "    rnn_acc_test = sklearn.metrics.accuracy_score(np.array(final_prediction_test)[:], \n",
    "                                     np.array(testY)[:])\n",
    "    return rnn_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rnn_acc = rnn_pre(df_train)\n",
    "# rnn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Data (Call the function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.874%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIhdUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy: 99.57000000000001%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBERERHpwBJFREREpANLFBEREZEOfwLRBqkcH/awEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 662\n",
      "Trainable params: 662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0051 - acc: 0.9963 - val_loss: 0.0020 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0019 - acc: 0.9983 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 1s 7us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 1s 7us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 15us/step\n"
     ]
    }
   ],
   "source": [
    "ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 55)                550       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 9,902\n",
      "Trainable params: 9,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0032 - acc: 0.9976 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 4s 22us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 23us/step\n"
     ]
    }
   ],
   "source": [
    "mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. RNN - Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss: 0.0018\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0017\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0017\n",
      "Train Score: 0.04 RMSE\n",
      "Test Score: 0.04 RMSE\n",
      "RNN accuracy: 78.70186666666666%\n"
     ]
    }
   ],
   "source": [
    "rnn_acc = rnn_pre(df_train)\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.85000000000001%\n",
      "Gradient Boosting accuracy: 99.57000000000001%\n",
      "Logistic Regression accuracy: 99.824%\n",
      "SVM accuracy: 99.824%\n",
      "ANN accuracy: 99.824%\n",
      "MLP accuracy: 99.824%\n",
      "RNN accuracy: 78.70186666666666%\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))\n",
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))\n",
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is the best one for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'prev_identical_clicks',\n",
       " 'future_identical_clicks',\n",
       " 'prev_app_clicks',\n",
       " 'future_app_clicks']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns for our current analsis\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "df = pd.read_csv('data/test_small_all_features.csv')[train_cols].astype('float64')\n",
    "df = np.nan_to_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the output of the test data\n",
    "sample_out = pd.read_csv('data/sample_submission.csv', nrows=1000000)[['is_attributed']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predict = rf_model.predict(df)\n",
    "# Compare the prediction with the known values\n",
    "df_acc = sklearn.metrics.accuracy_score(np.array(df_predict)[:], \n",
    "                                         np.array(sample_out)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using the best algorittm, the accuracy of the prediction: 99.9305%\n"
     ]
    }
   ],
   "source": [
    "print('By using the best algorittm, the accuracy of the prediction: {}%'.format(df_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the document is licensed under the MIT License: https://opensource.org/licenses/MIT\n",
    "\n",
    "All writing in the document is licensed bt The Creative Commons Attribution 3.0 https://creativecommons.org/licenses/by/3.0/us/."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
