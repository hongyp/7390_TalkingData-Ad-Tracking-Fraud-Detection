{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspirational Notebooks\n",
    "### Generating new festures according to these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected\n",
    "* https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "* https://www.kaggle.com/aharless/swetha-s-xgboost-revised\n",
    "* https://www.kaggle.com/bk0000/non-blending-lightgbm-model-lb-0-977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            200000 non-null int64\n",
      "ip                                    200000 non-null int64\n",
      "app                                   200000 non-null int64\n",
      "device                                200000 non-null int64\n",
      "os                                    200000 non-null int64\n",
      "channel                               200000 non-null int64\n",
      "click_time                            200000 non-null object\n",
      "attributed_time                       348 non-null object\n",
      "is_attributed                         200000 non-null int64\n",
      "day                                   200000 non-null int64\n",
      "hour                                  200000 non-null int64\n",
      "minute                                200000 non-null int64\n",
      "second                                200000 non-null int64\n",
      "ip_confRate                           200000 non-null float64\n",
      "app_confRate                          200000 non-null float64\n",
      "device_confRate                       200000 non-null float64\n",
      "os_confRate                           200000 non-null float64\n",
      "channel_confRate                      200000 non-null float64\n",
      "app_channel_confRate                  200000 non-null float64\n",
      "app_os_confRate                       200000 non-null float64\n",
      "app_device_confRate                   200000 non-null float64\n",
      "channel_os_confRate                   200000 non-null float64\n",
      "channel_device_confRate               200000 non-null float64\n",
      "os_device_confRate                    200000 non-null float64\n",
      "ip_app_channel_var_day                134217 non-null float64\n",
      "ip_app_os_var_hour                    139465 non-null float64\n",
      "ip_day_channel_var_hour_x             151335 non-null float64\n",
      "ip_day_hour_count_channel             200000 non-null int64\n",
      "ip_app_count_channel                  200000 non-null int64\n",
      "ip_app_os_count_channel               200000 non-null int64\n",
      "ip_app_day_hour_count_channel         200000 non-null int64\n",
      "ip_app_channel_mean_hour              200000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             200000 non-null float64\n",
      "app_count_channel                     200000 non-null int64\n",
      "channel_count_app                     200000 non-null int64\n",
      "ip_nunique_channel                    200000 non-null int64\n",
      "ip_nunique_app                        200000 non-null int64\n",
      "ip_day_nunique_hour                   200000 non-null int64\n",
      "ip_app_nunique_os                     200000 non-null int64\n",
      "ip_nunique_device                     200000 non-null int64\n",
      "app_nunique_channel                   200000 non-null int64\n",
      "ip_device_os_nunique_app              200000 non-null int64\n",
      "ip_device_os_cumcount_app             200000 non-null int64\n",
      "ip_cumcount_app                       200000 non-null int64\n",
      "ip_cumcount_os                        200000 non-null int64\n",
      "ip_day_channel_var_hour_y             151335 non-null float64\n",
      "ip_nextClick                          197456 non-null float64\n",
      "ip_app_nextClick                      163726 non-null float64\n",
      "ip_channel_nextClick                  138039 non-null float64\n",
      "ip_os_nextClick                       182531 non-null float64\n",
      "ip_app_device_os_channel_nextClick    86990 non-null float64\n",
      "ip_os_device_nextClick                181508 non-null float64\n",
      "ip_os_device_app_nextClick            120449 non-null float64\n",
      "prev_identical_clicks                 200000 non-null int64\n",
      "future_identical_clicks               200000 non-null int64\n",
      "prev_app_clicks                       200000 non-null int64\n",
      "future_app_clicks                     200000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 87.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_train= pd.read_csv('data/train.csv',nrows=200000, parse_dates=['click_time'])\n",
    "df_train = pd.read_csv('data/train_new_cols.csv',nrows=200000) #train data subset, original too large\n",
    "df_train.dropna()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
       "       'attributed_time', 'is_attributed', 'day', 'hour', 'minute',\n",
       "       'second', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
       "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
       "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
       "       'channel_device_confRate', 'os_device_confRate',\n",
       "       'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
       "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
       "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
       "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
       "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
       "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
       "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
       "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
       "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
       "       'ip_day_channel_var_hour_y', 'ip_nextClick', 'ip_app_nextClick',\n",
       "       'ip_channel_nextClick', 'ip_os_nextClick',\n",
       "       'ip_app_device_os_channel_nextClick', 'ip_os_device_nextClick',\n",
       "       'ip_os_device_app_nextClick', 'prev_identical_clicks',\n",
       "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
    "       'attributed_time', 'is_attributed', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
    "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
    "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
    "       'channel_device_confRate', 'os_device_confRate']\n",
    "df_train = df_train.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>ip_confRate</th>\n",
       "      <th>app_confRate</th>\n",
       "      <th>device_confRate</th>\n",
       "      <th>os_confRate</th>\n",
       "      <th>channel_confRate</th>\n",
       "      <th>app_channel_confRate</th>\n",
       "      <th>app_os_confRate</th>\n",
       "      <th>app_device_confRate</th>\n",
       "      <th>channel_os_confRate</th>\n",
       "      <th>channel_device_confRate</th>\n",
       "      <th>os_device_confRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114221</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:38:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74544</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 14:38:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "5   18787    3       1  16      379  2017-11-06 14:36:26             NaN   \n",
       "6  103022    3       1  23      379  2017-11-06 14:37:44             NaN   \n",
       "7  114221    3       1  19      379  2017-11-06 14:37:59             NaN   \n",
       "8  165970    3       1  13      379  2017-11-06 14:38:10             NaN   \n",
       "9   74544   64       1  22      459  2017-11-06 14:38:23             NaN   \n",
       "\n",
       "   is_attributed  ip_confRate  app_confRate  device_confRate  os_confRate  \\\n",
       "0              0     0.000000      0.000446         0.001193     0.001146   \n",
       "1              0     0.000000      0.000446         0.001193     0.001394   \n",
       "2              0     0.000000      0.000446         0.001193     0.001146   \n",
       "3              0     0.000775      0.000431         0.001193     0.001146   \n",
       "4              0     0.000000      0.000446         0.001193     0.001146   \n",
       "5              0     0.000000      0.000446         0.001193     0.000851   \n",
       "6              0     0.000000      0.000446         0.001193     0.000328   \n",
       "7              0     0.000000      0.000446         0.001193     0.001394   \n",
       "8              0     0.000000      0.000446         0.001193     0.001146   \n",
       "9              0     0.000000      0.000256         0.001193     0.001859   \n",
       "\n",
       "   channel_confRate  app_channel_confRate  app_os_confRate  \\\n",
       "0          0.000497              0.000360         0.000366   \n",
       "1          0.000497              0.000360         0.000275   \n",
       "2          0.000497              0.000360         0.000366   \n",
       "3          0.004071              0.004164         0.000201   \n",
       "4          0.000497              0.000360         0.000366   \n",
       "5          0.000497              0.000360         0.000559   \n",
       "6          0.000497              0.000360         0.000000   \n",
       "7          0.000497              0.000360         0.000275   \n",
       "8          0.000497              0.000360         0.000366   \n",
       "9          0.000161              0.000256         0.000000   \n",
       "\n",
       "   app_device_confRate  channel_os_confRate  channel_device_confRate  \\\n",
       "0             0.000444             0.000000                 0.000499   \n",
       "1             0.000444             0.000235                 0.000499   \n",
       "2             0.000444             0.000000                 0.000499   \n",
       "3             0.000445             0.001835                 0.004109   \n",
       "4             0.000444             0.000000                 0.000499   \n",
       "5             0.000444             0.002329                 0.000499   \n",
       "6             0.000444             0.000000                 0.000499   \n",
       "7             0.000444             0.000235                 0.000499   \n",
       "8             0.000444             0.000000                 0.000499   \n",
       "9             0.000260             0.000000                 0.000165   \n",
       "\n",
       "   os_device_confRate  \n",
       "0            0.001182  \n",
       "1            0.001428  \n",
       "2            0.001182  \n",
       "3            0.001182  \n",
       "4            0.001182  \n",
       "5            0.000882  \n",
       "6            0.000336  \n",
       "7            0.001428  \n",
       "8            0.001182  \n",
       "9            0.001944  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199652\n",
       "1       348\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEFCAYAAAAmIwo/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHI1JREFUeJzt3XtsVGX+x/H3dFoQOq21EggNFItC\nlLvtCO5auqvYDGxE5FpgLa6oCMvFuguCFVr4tVzMsiWx3IvZkCrLRVgl0XihWWxasMhowRZhWRcq\nt0URlXYQ2s6c3x8bJ9u11NGnM4X280pIOg/fc/o9zcl85pxnzjk2y7IsREREDIS1dAMiInLjU5iI\niIgxhYmIiBhTmIiIiDGFiYiIGAtv6QZagtvtbukWRERuSElJSY2Ot8kwgWv/QUREpHFNfRDXaS4R\nETGmMBEREWMKExERMaYwERERYwoTERExpjARERFjQftqcF1dHZmZmZw5c4ba2lpmzJjBHXfcwYIF\nC7DZbPTq1Yvs7GzCwsJYvXo1e/fuJTw8nMzMTAYMGEBVVZVxrYiIhEbQ3nF3795NTEwMW7ZsYdOm\nTeTk5LB8+XIyMjLYsmULlmVRVFREZWUlBw4cYMeOHeTl5bFkyRIA41oREQmdoB2ZDB8+HJfLBYBl\nWdjtdiorKxk8eDAAKSkplJaWkpCQQHJyMjabjbi4OLxeLxcvXjSuTU1NbbI/XQUvItJ8ghYmkZGR\nANTU1DBnzhwyMjJ48cUXsdls/v+vrq6mpqaGmJiYBstVV1djWZZR7Y8xvQL+4JzpRstL6+R8aX1L\ntyASNC12Bfy5c+eYMmUKo0aNYuTIkQ3mMTweD9HR0TgcDjweT4PxqKgo41oREQmdoIXJhQsXmDp1\nKvPmzWPcuHEA9OnTh7KyMgCKi4txOp0kJiZSUlKCz+fj7Nmz+Hw+YmNjjWtFRCR0gnaaa/369Vy6\ndIm1a9eydu1aAF544QVyc3PJy8ujZ8+euFwu7HY7TqeTtLQ0fD4fWVlZAMyfP59Fixb97FoREQkd\nm2VZVks3EWput1tzJhIUmjOR1qyp905djCEiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJM\nYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEi\nIiLGFCYiImIsaM+ABzh06BArV66ksLCQZ599lgsXLgBw5swZBg4cyKpVq5gxYwZff/01ERERtG/f\nnk2bNlFVVcWCBQuw2Wz06tWL7OxswsLCWL16NXv37iU8PJzMzEwGDBhwzVoREQmdoIVJQUEBu3fv\npkOHDgCsWrUKgG+//ZYpU6bw/PPPA1BVVcWbb76JzWbzL7t8+XIyMjIYMmQIWVlZFBUVERcXx4ED\nB9ixYwfnzp1j9uzZ7Ny5s9Ha1NTUYG2WiIg0ImhhEh8fT35+Ps8991yD8fz8fB599FE6d+7MhQsX\nuHTpEtOnT+fSpUtMmzaN+++/n8rKSgYPHgxASkoKpaWlJCQkkJycjM1mIy4uDq/Xy8WLFxutDSRM\n3G5382+0tHnar6StClqYuFwuTp8+3WDsq6++Yv/+/f6jkrq6OqZOncqUKVP49ttvmTRpEgMGDMCy\nLP+RSmRkJNXV1dTU1BATE+Nf1/fjjdUGIikpyWj7Dm4uMFpeWifT/UrketbUh6WQTi68/fbbPPTQ\nQ9jtdgA6derExIkTCQ8P59Zbb+Wuu+7ixIkTDeY8PB4P0dHROBwOPB5Pg/GoqKhGa0VEJLRCGib7\n9+8nJSXF/3rfvn0888wzwH+C4Pjx4/Ts2ZM+ffpQVlYGQHFxMU6nk8TEREpKSvD5fJw9exafz0ds\nbGyjtSIiElpB/TbX/zpx4gTdu3f3v/7Vr35FSUkJEyZMICwsjD/84Q/ExsYyf/58Fi1aRF5eHj17\n9sTlcmG323E6naSlpeHz+cjKygJotFZERELLZlmW1dJNhJrb7TafM5kzvZm6kdbE+dL6lm5BJGia\neu/UBRkiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIi\nxhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGghomhw4dIj09HYAj\nR44wdOhQ0tPTSU9P56233gJg9erVjBs3jokTJ3L48GEAqqqqmDRpEpMnTyY7Oxufz/eTa0VEJHTC\ng7XigoICdu/eTYcOHQCorKzk8ccfZ+rUqf6ayspKDhw4wI4dOzh37hyzZ89m586dLF++nIyMDIYM\nGUJWVhZFRUXExcUFXJuamhqszRIRkUYELUzi4+PJz8/nueeeA6CiooITJ05QVFREjx49yMzMxO12\nk5ycjM1mIy4uDq/Xy8WLF6msrGTw4MEApKSkUFpaSkJCQsC1gYSJ2+0O1qZLG6b9StqqoIWJy+Xi\n9OnT/tcDBgxg/Pjx9OvXj3Xr1rFmzRqioqKIiYnx10RGRlJdXY1lWdhstgZjNTU1AdcGIikpyWj7\nDm4uMFpeWifT/UrketbUh6WQTcCnpqbSr18//89HjhzB4XDg8Xj8NR6Ph6ioKMLCwhqMRUdH/6Ra\nEREJrZCFyRNPPOGfNN+/fz99+/YlMTGRkpISfD4fZ8+exefzERsbS58+fSgrKwOguLgYp9P5k2pF\nRCS0gnaa638tXryYnJwcIiIi6NSpEzk5OTgcDpxOJ2lpafh8PrKysgCYP38+ixYtIi8vj549e+Jy\nubDb7QHXiohIaNksy7JauolQc7vd5nMmc6Y3UzfSmjhfWt/SLYgETVPvnbpoUUREjClMRETEmMJE\nRESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCRERE\njClMRETEmMJERESMKUxERMSYwkRERIwF9bG9hw4dYuXKlRQWFvLpp5+Sk5OD3W6nXbt2vPjii3Tq\n1Inc3Fw++ugjIiMjAVi7di11dXXMnTuXK1eu0LlzZ5YvX06HDh3Yvn07W7duJTw8nBkzZnD//fdz\n8eLFRmtFRCR0gnZkUlBQwMKFC7l69SoAS5cuZdGiRRQWFpKamkpBQQEAlZWVbNq0icLCQgoLC4mK\nimLt2rU89NBDbNmyhT59+rBt2za+/PJLCgsL2bp1Ky+//DJ5eXnU1tY2WisiIqEVtDCJj48nPz/f\n/zovL4+77roLAK/XS/v27fH5fFRVVZGVlcXEiRN57bXXgP88Z3jo0KEApKSksG/fPg4fPszdd99N\nu3btiIqKIj4+nqNHjzZaKyIioRW001wul4vTp0/7X3fu3BmAjz76iFdeeYVXX32Vy5cv8+ijj/L4\n44/j9XqZMmUK/fr1o6amhqioKAAiIyOprq5uMPb9eE1NTaO1gXC73c21qSJ+2q+krQrqnMn/euut\nt1i3bh0bN24kNjbWHyDfz3Hce++9HD16FIfDgcfj4aabbsLj8RAdHe0f+57H4yEqKqrR2kAkJSUZ\nbcvBzQVGy0vrZLpfiVzPmvqwFLJvc73xxhu88sorFBYW0r17dwBOnjzJpEmT8Hq91NXV8dFHH9G3\nb18SExN5//33ASguLiYpKYkBAwbgdru5evUq1dXVfPbZZ/Tu3bvRWhERCa2QHJl4vV6WLl1K165d\nmT17NgD33HMPc+bMYdSoUUyYMIGIiAhGjRpFr169mDFjBvPnz2f79u3ccsst/PnPf6Zjx46kp6cz\nefJkLMvi2WefpX379o3WiohIaNksy7JauolQc7vd5qe55kxvpm6kNXG+tL6lWxAJmqbeO3XRooiI\nGFOYiIiIMYWJiIgYU5iIiIgxhYmIiBgLKExycnJ+MDZ//vxmb0ZERG5MTV5n8sILL3Dq1CkqKio4\nfvy4f7y+vj7g25aIiEjr12SYzJgxgzNnzrB06VJmzZrlH7fb7dx+++1Bb05ERG4MTYZJt27d6Nat\nG7t376ampobq6mq+v8bx8uXLxMTEhKRJERG5vgV0O5UNGzawYcOGBuFhs9koKioKWmMiInLjCChM\nduzYwZ49e4iNjQ12PyIicgMK6NtcXbt25eabbw52LyIicoMK6MjktttuY/LkyQwZMoR27dr5x/97\nUl5ERNqugMKkS5cudOnSJdi9iIjIDSqgMNERiIiINCWgMLnzzjux2WwNxjp37ux/wqGIiLRtAYXJ\n0aNH/T/X1dWxZ88eysvLg9aUiIjcWH7yjR4jIiIYMWIEH3zwQTD6ERGRG1BARyavv/66/2fLsjh+\n/DgRERE/utyhQ4dYuXIlhYWFVFVVsWDBAmw2G7169SI7O5uwsDBWr17N3r17CQ8PJzMzkwEDBjRL\nrYiIhE5A77plZWX+fwcOHABg1apVTS5TUFDAwoULuXr1KgDLly8nIyODLVu2YFkWRUVFVFZWcuDA\nAXbs2EFeXh5LlixplloREQmtgI5Mli9fTl1dHSdOnMDr9dKrVy/Cw5teND4+nvz8fJ577jkAKisr\nGTx4MAApKSmUlpaSkJBAcnIyNpuNuLg4vF4vFy9eNK5NTU392X8QERH56QIKk4qKCubMmUNMTAw+\nn48LFy6wZs0aBg4ceM1lXC4Xp0+f9r+2LMv/jbDIyEiqq6upqalpcL+v78dNawPhdrsDqhP5KbRf\nSVsVUJjk5uayatUqf3iUl5eTk5PDa6+9FvAv+u95DI/HQ3R0NA6HA4/H02A8KirKuDYQSUlJAffe\nmIObC4yWl9bJdL8SuZ419WEpoDmTy5cvNzgKGTRokH8uJFB9+vShrKwMgOLiYpxOJ4mJiZSUlODz\n+Th79iw+n4/Y2FjjWhERCa2Ajkxuvvlm9uzZw4MPPgjAnj17fvKzTObPn8+iRYvIy8ujZ8+euFwu\n7HY7TqeTtLQ0fD4fWVlZzVIrIiKhZbO+f9pVE06ePMnTTz/NN9984x/bunUrCQkJQW0uWNxut/lp\nrjnTm6kbaU2cL61v6RZEgqap986ATnMVFxfToUMH/v73v7N582ZiY2P9XxEWEREJKEy2b9/OX//6\nVzp27Midd97Jrl27eOWVV4Ldm4iI3CACCpO6uroGV7wHcvW7iIi0HQFNwD/44IM89thjjBgxAoB3\n332XYcOGBbUxERG5cQQUJvPmzePtt9/mww8/JDw8nClTpvi/2SUiIhJQmAAMHz6c4cOHB7MXERG5\nQen2uiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLG\nFCYiImJMYSIiIsYCvtFjc9i1axd/+9vfALh69SqffvopeXl5vPjii3Tt2hWA2bNn43Q6Wbx4MceO\nHaNdu3bk5ubSo0cPysvLWbp0KXa7neTkZGbNmoXP52u0VkREQiekYTJmzBjGjBkDwJIlSxg7diwV\nFRXMmzcPl8vlr3v33Xepra1l27ZtlJeXs2LFCtatW0d2djb5+fl0796dadOmceTIEU6fPt1orYiI\nhE6LnOb65JNP+Oc//0laWhqVlZXs3LmTyZMns2LFCurr63G73QwdOhSAQYMGUVFRQU1NDbW1tcTH\nx2Oz2UhOTmbfvn2N1oqISGiF9Mjkexs2bGDmzJkA3HfffTz44IN069aN7Oxstm7dSk1NDQ6Hw19v\nt9t/MBYZGcmpU6cara2vryc8vOlNc7vdzbxVItqvpO0KeZhcunSJEydOcO+99wIwduxYoqOjARg2\nbBjvvPMOUVFReDwe/zI+nw+Hw9FgzOPxEB0dzZUrV35Q+2NBApCUlGS0HQc3FxgtL62T6X4lcj1r\n6sNSyE9zffjhh/ziF78AwLIsHn74Yf79738DsH//fvr27UtiYiLFxcUAlJeX07t3bxwOBxEREXz+\n+edYlkVJSQlOp7PRWhERCa2QH5mcOHGCbt26AWCz2cjNzWXWrFncdNNN3H777UyYMAG73U5paSkT\nJ07EsiyWLVsG/GfSfu7cuXi9XpKTkxk4cCD9+/dvtFZERELHZlmW1dJNhJrb7TY/zTVnejN1I62J\n86X1Ld2CSNA09d6pixZFRMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwp\nTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMhfwZ\n8KNHj8bhcADQrVs30tLSWLp0KXa7neTkZGbNmoXP52Px4sUcO3aMdu3akZubS48ePSgvLw+4VkRE\nQiekYXL16lUsy6KwsNA/NmrUKPLz8+nevTvTpk3jyJEjnD59mtraWrZt20Z5eTkrVqxg3bp1ZGdn\nB1wrIiKhE9IwOXr0KN999x1Tp06lvr6e2bNnU1tbS3x8PADJycns27ePL7/8kqFDhwIwaNAgKioq\nqKmpCbhWRERCK6RhctNNN/HEE08wfvx4Tp48yVNPPUV0dLT//yMjIzl16hQ1NTX+U2EAdrv9B2NN\n1dbX1xMe3vSmud3uZtwykf/QfiVtVUjDJCEhgR49emCz2UhISCAqKopvvvnG//8ej4fo6GiuXLmC\nx+Pxj/t8PhwOR4Oxpmp/LEgAkpKSjLbl4OYCo+WldTLdr0SuZ019WArpt7lee+01VqxYAcD58+f5\n7rvv6NixI59//jmWZVFSUoLT6SQxMZHi4mIAysvL6d27Nw6Hg4iIiIBqRUQktEJ6ZDJu3Dief/55\nJk2ahM1mY9myZYSFhTF37ly8Xi/JyckMHDiQ/v37U1paysSJE7Esi2XLlgGwZMmSgGtFRCR0bJZl\nWS3dRKi53W7z01xzpjdTN9KaOF9a39ItiARNU++dumhRRESMKUxERMSYwkRERIwpTERExJjCRERE\njClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwp\nTERExJjCREREjClMRETEWEifAV9XV0dmZiZnzpyhtraWGTNm0LVrV55++mluu+02ACZNmsRvfvMb\nVq9ezd69ewkPDyczM5MBAwZQVVXFggULsNls9OrVi+zsbMLCwhqtFRGR0AlpmOzevZuYmBj+9Kc/\n8c033/DII48wc+ZMHn/8caZOneqvq6ys5MCBA+zYsYNz584xe/Zsdu7cyfLly8nIyGDIkCFkZWVR\nVFREXFxco7UiIhI6IQ2T4cOH43K5ALAsC7vdTkVFBSdOnKCoqIgePXqQmZmJ2+0mOTkZm81GXFwc\nXq+XixcvUllZyeDBgwFISUmhtLSUhISERmtjY2NDuWkiIm1aSMMkMjISgJqaGubMmUNGRga1tbWM\nHz+efv36sW7dOtasWUNUVBQxMTENlquursayLGw2W4OxmpqaRmt/LEzcbncQtlDaOu1X0laFNEwA\nzp07x8yZM5k8eTIjR47k0qVLREdHA5CamkpOTg7Dhg3D4/H4l/F4PERFRREWFtZgLDo6GofD0Wjt\nj0lKSjLajoObC4yWl9bJdL8SuZ419WEppN/munDhAlOnTmXevHmMGzcOgCeeeILDhw8DsH//fvr2\n7UtiYiIlJSX4fD7Onj2Lz+cjNjaWPn36UFZWBkBxcTFOp/OatSIiEjohPTJZv349ly5dYu3ataxd\nuxaABQsWsGzZMiIiIujUqRM5OTk4HA6cTidpaWn4fD6ysrIAmD9/PosWLSIvL4+ePXvicrmw2+2N\n1oqISOjYLMuyWrqJUHO73eanueZMb6ZupDVxvrS+pVsQCZqm3jt10aKIiBhTmIiIiDGFiYiIGFOY\niIiIMYWJiIgYU5iIiIgxhYmIiBhTmIiIiDGFiYiIGFOYiIiIMYWJiIgYU5iIiIgxhYmIiBhTmIiI\niDGFiYiIGFOYiIiIMYWJiIgYU5iIiIixkD4DPlh8Ph+LFy/m2LFjtGvXjtzcXHr06NHSbYmItBmt\n4shkz5491NbWsm3bNv74xz+yYsWKlm5JRKRNaRVHJm63m6FDhwIwaNAgKioqWrgjkZY1fd/Blm5B\nrkPrf+kM2rpbRZjU1NTgcDj8r+12O/X19YSHX3vz3G630e+0PfaU0fLSOpnuV83lqfa2lm5BrkPB\n3D9bRZg4HA48Ho//tc/nazJIkpKSQtGWiEib0SrmTBITEykuLgagvLyc3r17t3BHIiJti82yLKul\nmzD1/be5/vGPf2BZFsuWLeP2229v6bZERNqMVhEmIiLSslrFaS4REWlZChMRETGmMBEREWMKE/nZ\nfD4fWVlZpKWlkZ6eTlVVVUu3JNLAoUOHSE9Pb+k22oRWcZ2JtIz/vo1NeXk5K1asYN26dS3dlggA\nBQUF7N69mw4dOrR0K22CjkzkZ9NtbOR6Fh8fT35+fku30WYoTORnu9ZtbESuBy6Xq8k7YUjzUpjI\nz/ZTb2MjIq2XwkR+Nt3GRkS+p4+R8rOlpqZSWlrKxIkT/bexEZG2SbdTERERYzrNJSIixhQmIiJi\nTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhInINn3zyCS+88EKzre+/7177/PPPc+bMmR/UnD9/nqee\negqABQsWsGvXroDXX11dze9///uf1NOuXbtYsGDBT1pGpDEKE5Fr6N+/P0uXLm229R04cMD/c1lZ\nGY1d4tWlSxcKCgp+1vq//fZbjh49+rP7EzGhMBG5hrKyMtLT0/nLX/7Cww8/zCOPPEJWVlaTy9TX\n17Nw4ULS0tIYNmwYTz75JFeuXCE3NxeA8ePHs3HjRr744gumTZvG119/zQMPPEBGRgYul4vDhw/z\nwAMP+Ne3d+9exowZw8iRI3nrrbeAHx5NpKenU1ZWRm5uLl988QUzZ84E4PXXX2f06NGMGjWKzMxM\nrl696h93uVyMHTuWvXv3NuefTNowhYlIE+rr69mwYQM7d+5k165d2Gw2zp8/f836jz/+mIiICLZt\n28Z7773H1atXef/991m4cCEAO3bsYNq0aXTu3JmNGzdyyy23AJCSksI777xDbGxsg/V99913bN++\nnU2bNrFs2TK+/PLLa/7uhQsX0rlzZ9asWcPx48fZvn07W7du5Y033uDWW2/l5Zdf5vz586xcuZJX\nX32Vbdu2NbhRp4gJ3ZtLpAnh4eHcfffdjBs3jmHDhvHb3/6WLl26XLP+nnvuISYmhldffZV//etf\nnDx5ksuXL//o7xk4cGCj46NHjyY8PJwuXbowaNAgDh06FFDfZWVlVFVVMWHCBADq6uro06cPH3/8\nMXfffTedOnUCYOTIkXzwwQcBrVOkKQoTkR+xdu1aysvLKS4u5sknn2TlypUMHjy40dqioiJeeukl\npkyZwpgxY/j6668bnRv5X+3bt2903G63+3+2LIuIiAhsNluDddbV1f1gOa/Xy4gRI/xHRB6PB6/X\ny/79+/H5fP46PTJAmotOc4k04eLFi4wYMYLevXvzzDPPcN9993Hs2LFr1u/fv58RI0YwduxYOnXq\nxIcffojX6wUaPjzMbrf7x5vy5ptvYlkWZ86c4ZNPPqF///7ccsstfPbZZ1iWxalTp/z9hIeH+9c/\nZMgQ3nvvPb766issy2Lx4sVs3ryZpKQkDh06xPnz5/H5fP55GBFT+lgi0oTY2FiGDRvGuHHj6NCh\nA127dmX06NHXrB8/fjxz587l7bffpl27dgwaNIjTp08DMGzYMEaNGsWuXbv49a9/zbRp09i0aVOT\nv79jx46MGTOG+vp6/u///o/Y2Fh++ctfsnPnToYPH05CQgJJSUkA3HrrrcTFxZGenk5hYSGzZs3i\nsccew+fzcddddzFt2jTat2/PwoUL+d3vfkeHDh244447mu+PJW2abkEvIiLGdGQi8hMdPHiQnJyc\nRv9v48aNTU7Qi7RWOjIRERFjmoAXERFjChMRETGmMBEREWMKExERMfb/Bht0YSFsvxQAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_train, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            50000 non-null int64\n",
      "ip                                    50000 non-null int64\n",
      "app                                   50000 non-null int64\n",
      "device                                50000 non-null int64\n",
      "os                                    50000 non-null int64\n",
      "channel                               50000 non-null int64\n",
      "click_time                            50000 non-null object\n",
      "attributed_time                       88 non-null object\n",
      "is_attributed                         50000 non-null int64\n",
      "day                                   50000 non-null int64\n",
      "hour                                  50000 non-null int64\n",
      "minute                                50000 non-null int64\n",
      "second                                50000 non-null int64\n",
      "ip_confRate                           50000 non-null float64\n",
      "app_confRate                          50000 non-null float64\n",
      "device_confRate                       50000 non-null float64\n",
      "os_confRate                           50000 non-null float64\n",
      "channel_confRate                      50000 non-null float64\n",
      "app_channel_confRate                  50000 non-null float64\n",
      "app_os_confRate                       50000 non-null float64\n",
      "app_device_confRate                   50000 non-null float64\n",
      "channel_os_confRate                   50000 non-null float64\n",
      "channel_device_confRate               50000 non-null float64\n",
      "os_device_confRate                    50000 non-null float64\n",
      "ip_app_channel_var_day                34970 non-null float64\n",
      "ip_app_os_var_hour                    36809 non-null float64\n",
      "ip_day_channel_var_hour_x             38512 non-null float64\n",
      "ip_day_hour_count_channel             50000 non-null int64\n",
      "ip_app_count_channel                  50000 non-null int64\n",
      "ip_app_os_count_channel               50000 non-null int64\n",
      "ip_app_day_hour_count_channel         50000 non-null int64\n",
      "ip_app_channel_mean_hour              50000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             50000 non-null float64\n",
      "app_count_channel                     50000 non-null int64\n",
      "channel_count_app                     50000 non-null int64\n",
      "ip_nunique_channel                    50000 non-null int64\n",
      "ip_nunique_app                        50000 non-null int64\n",
      "ip_day_nunique_hour                   50000 non-null int64\n",
      "ip_app_nunique_os                     50000 non-null int64\n",
      "ip_nunique_device                     50000 non-null int64\n",
      "app_nunique_channel                   50000 non-null int64\n",
      "ip_device_os_nunique_app              50000 non-null int64\n",
      "ip_device_os_cumcount_app             50000 non-null int64\n",
      "ip_cumcount_app                       50000 non-null int64\n",
      "ip_cumcount_os                        50000 non-null int64\n",
      "ip_day_channel_var_hour_y             38512 non-null float64\n",
      "ip_nextClick                          48959 non-null float64\n",
      "ip_app_nextClick                      39531 non-null float64\n",
      "ip_channel_nextClick                  32900 non-null float64\n",
      "ip_os_nextClick                       44728 non-null float64\n",
      "ip_app_device_os_channel_nextClick    21355 non-null float64\n",
      "ip_os_device_nextClick                44410 non-null float64\n",
      "ip_os_device_app_nextClick            29197 non-null float64\n",
      "prev_identical_clicks                 50000 non-null int64\n",
      "future_identical_clicks               50000 non-null int64\n",
      "prev_app_clicks                       50000 non-null int64\n",
      "future_app_clicks                     50000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The ratio of df_train to df_test is 0.8 to 0.2 or 0.75 to 0.25\n",
    "df_test = pd.read_csv('data/train_new_cols.csv', nrows=50000,skiprows=range(1, 400000))\n",
    "df_test.dropna()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>ip_confRate</th>\n",
       "      <th>app_confRate</th>\n",
       "      <th>device_confRate</th>\n",
       "      <th>os_confRate</th>\n",
       "      <th>channel_confRate</th>\n",
       "      <th>app_channel_confRate</th>\n",
       "      <th>app_os_confRate</th>\n",
       "      <th>app_device_confRate</th>\n",
       "      <th>channel_os_confRate</th>\n",
       "      <th>channel_device_confRate</th>\n",
       "      <th>os_device_confRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115115</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144498</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>237</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1556</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20266</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31564</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>265</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1732</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111114</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0  115115    8       1  13      145  2017-11-06 16:07:47             NaN   \n",
       "1   21633    1       1  19      178  2017-11-06 16:07:47             NaN   \n",
       "2  144498   12       1  17      178  2017-11-06 16:07:47             NaN   \n",
       "3   76919    2       1   6      237  2017-11-06 16:07:47             NaN   \n",
       "4    1556   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "5   67467   15       1  37      245  2017-11-06 16:07:47             NaN   \n",
       "6   20266   64       1  19      459  2017-11-06 16:07:47             NaN   \n",
       "7   31564   15       1  19      265  2017-11-06 16:07:47             NaN   \n",
       "8    1732    9       1  13      134  2017-11-06 16:07:47             NaN   \n",
       "9  111114   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "\n",
       "   is_attributed  ip_confRate  app_confRate  device_confRate  os_confRate  \\\n",
       "0              0     0.000000      0.001208         0.001193     0.001146   \n",
       "1              0     0.000000      0.000309         0.001193     0.001394   \n",
       "2              0     0.000000      0.000134         0.001193     0.000893   \n",
       "3              0     0.001656      0.000262         0.001193     0.001548   \n",
       "4              0     0.000000      0.000210         0.001193     0.001146   \n",
       "5              0     0.000000      0.000210         0.001193     0.000316   \n",
       "6              0     0.000000      0.000256         0.001193     0.001394   \n",
       "7              0     0.000000      0.000210         0.001193     0.001394   \n",
       "8              0     0.000000      0.000848         0.001193     0.001146   \n",
       "9              0     0.000000      0.000210         0.001193     0.001146   \n",
       "\n",
       "   channel_confRate  app_channel_confRate  app_os_confRate  \\\n",
       "0          0.001055              0.001081         0.001089   \n",
       "1          0.000147              0.000000         0.000098   \n",
       "2          0.000147              0.000157         0.000194   \n",
       "3          0.000205              0.000205         0.000223   \n",
       "4          0.000064              0.000078         0.000069   \n",
       "5          0.000064              0.000078         0.000000   \n",
       "6          0.000161              0.000256         0.000538   \n",
       "7          0.000079              0.000163         0.000254   \n",
       "8          0.000562              0.000655         0.000809   \n",
       "9          0.000064              0.000078         0.000069   \n",
       "\n",
       "   app_device_confRate  channel_os_confRate  channel_device_confRate  \\\n",
       "0             0.001234             0.000889                 0.001076   \n",
       "1             0.000317             0.000216                 0.000157   \n",
       "2             0.000141             0.000239                 0.000157   \n",
       "3             0.000278             0.000000                 0.000213   \n",
       "4             0.000220             0.000042                 0.000068   \n",
       "5             0.000220             0.000000                 0.000068   \n",
       "6             0.000260             0.000330                 0.000165   \n",
       "7             0.000220             0.000000                 0.000082   \n",
       "8             0.000888             0.000418                 0.000583   \n",
       "9             0.000220             0.000042                 0.000068   \n",
       "\n",
       "   os_device_confRate  \n",
       "0            0.001182  \n",
       "1            0.001428  \n",
       "2            0.000944  \n",
       "3            0.001592  \n",
       "4            0.001182  \n",
       "5            0.000273  \n",
       "6            0.001428  \n",
       "7            0.001428  \n",
       "8            0.001182  \n",
       "9            0.001182  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49912\n",
       "1       88\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsf8DoQTTGbbtqNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_test, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'ip_confRate',\n",
       " 'app_confRate',\n",
       " 'device_confRate',\n",
       " 'os_confRate',\n",
       " 'channel_confRate',\n",
       " 'app_channel_confRate',\n",
       " 'app_os_confRate',\n",
       " 'app_device_confRate',\n",
       " 'channel_os_confRate',\n",
       " 'channel_device_confRate',\n",
       " 'os_device_confRate']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columes names except the click_time (object), attributed_time (object) and is_attributed\n",
    "train_cols = []\n",
    "for each_value in df_train.columns.values:\n",
    "    if each_value == 'click_time' or each_value == 'attributed_time' or each_value == 'is_attributed':\n",
    "        continue\n",
    "    train_cols.append(each_value)\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_X\n",
    "X_train = df_train.loc[:,train_cols]\n",
    "X_test = df_test.loc[:,train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_Y\n",
    "y_train = df_train[['is_attributed']]\n",
    "y_test = df_test[['is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_val = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest_pre(X_train, y_train, X_test, y_test):\n",
    "    y_train_model = y_train.values.ravel()\n",
    "    RF_model = RandomForestClassifier()\n",
    "    # Train the model\n",
    "    RF_fit = RF_model.fit(X_train, y_train_model)\n",
    "    # Get the prediction of the test data\n",
    "    RF_predict = RF_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    RF_acc = sklearn.metrics.accuracy_score(np.array(RF_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(RF_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return RF_fit, RF_predict, RF_acc, RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "# RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting & AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientBoosting_pre(X_train, y_train, X_test, y_test):\n",
    "    y_train_model = y_train.values.ravel()\n",
    "    GB_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    # Train the model\n",
    "    GB_fit = GB_model.fit(X_train, y_train_model)\n",
    "    # Get the prediction of the test data\n",
    "    GB_predict = GB_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    GB_acc = sklearn.metrics.accuracy_score(np.array(GB_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(GB_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return GB_fit, GB_predict, GB_acc, GB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "# GB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression_pre(X_train, y_train, X_test, y_test):\n",
    "    y_train_model = y_train.values.ravel()\n",
    "    LG_model = LogisticRegression()\n",
    "    # Train the model\n",
    "    LG_fit = LG_model.fit(X_train, y_train_model)\n",
    "    # Get the prediction of the test data\n",
    "    LG_predict = LG_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    LG_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    return LG_fit, LG_predict, LG_acc, LG_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "# LG_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_pre(X_train, y_train, X_test, y_test):\n",
    "    svm_model = svm.SVC()\n",
    "    uniq = np.unique(y_train[9000:10000])\n",
    "    # Train the model\n",
    "    SVM_fit = svm_model.fit(X_train[9000:10000], y_train[9000:10000])\n",
    "    # Get the prediction of the test data\n",
    "    SVM_predict = svm_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    SVM_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                     np.array(y_test_val)[:])\n",
    "    return SVM_fit, SVM_predict, SVM_acc, svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_A(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ann_pre(X_train, df_train, X_test, df_test):\n",
    "    ann_model = shallow_net_A()\n",
    "    ann_summary = ann_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_ann = X_train.values\n",
    "    y_train_ann = df_train['is_attributed'].values\n",
    "    X_test_ann = X_test.values\n",
    "    y_test_ann = df_test['is_attributed'].values\n",
    "    # Conver the matrix, finally we have two classes (n_classes), the original one has oly one class\n",
    "    n_classes = 2\n",
    "    y_train_ann = keras.utils.to_categorical(y_train_ann, n_classes)\n",
    "    y_test_ann = keras.utils.to_categorical(y_test_ann, n_classes)\n",
    "    # Training the model\n",
    "    ann_fit = ann_model.fit(X_train_ann, y_train_ann, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_ann, y_test_ann))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    ann_evaluate = ann_model.evaluate(X_test_ann, y_test_ann)\n",
    "    \n",
    "    # Using prediction\n",
    "    ann_pre = ann_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (ann_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ann_output = confusion_matrix(y_test_ann.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    ann_prediction_acc = ann_output[0][0]/(ann_output[0][0]+ann_output[1][0])\n",
    "    \n",
    "    return ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, df_train, X_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_C(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2, here we have more hidden layers with different activation\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='relu', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='tanh', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='elu', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_pre(X_train, df_train, X_test, df_test):\n",
    "    mlp_model = shallow_net_C()\n",
    "    mlp_summary = mlp_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_mlp = X_train.values\n",
    "    y_train_mlp = df_train['is_attributed'].values\n",
    "    X_test_mlp = X_test.values\n",
    "    y_test_mlp = df_test['is_attributed'].values\n",
    "    # Conver the matrix, finally we have two classes (n_classes)\n",
    "    n_classes = 2\n",
    "    y_train_mlp = keras.utils.to_categorical(y_train_mlp, n_classes)\n",
    "    y_test_mlp = keras.utils.to_categorical(y_test_mlp, n_classes)\n",
    "    # Training the model\n",
    "    mlp_fit = mlp_model.fit(X_train_mlp, y_train_mlp, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_mlp, y_test_mlp))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    mlp_evaluate = mlp_model.evaluate(X_test_mlp, y_test_mlp)\n",
    "    \n",
    "    # Using prediction\n",
    "    mlp_pre = mlp_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (mlp_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mlp_output = confusion_matrix(y_test_mlp.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    mlp_prediction_acc = mlp_output[0][0]/(mlp_output[0][0]+mlp_output[1][0])\n",
    "    \n",
    "    return mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, df_train, X_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. RNN - Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_pre(df_train, train_rate=0.75):\n",
    "    # Set the dataset for train and test\n",
    "    df_rnn_train = df_train.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn_test = df_test.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn = df_rnn_train.append(df_rnn_test)\n",
    "    \n",
    "    pre_col_index = list(df_rnn_train).index('is_attributed')\n",
    "    dataset = df_rnn.values.astype('float32')\n",
    "    \n",
    "    # Normalize the dataset, set all the data of the dataset to be in the range between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(dataset) * train_rate)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    \n",
    "    # Use this function to prepare the train and test datasets for modeling\n",
    "    look_back = 1\n",
    "    trainY = train[:, pre_col_index]\n",
    "    trainX = np.delete(train, pre_col_index, axis = 1) \n",
    "    testY = test[:, pre_col_index]\n",
    "    testX = np.delete(test, pre_col_index, axis = 1) \n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features], here it changes the dimension from 2D to 3D\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(LSTM(5, input_shape=(1, len(trainX[0][0]))))\n",
    "    RNN_model.add(Dense(1))\n",
    "    RNN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    RNN_model.fit(trainX, trainY, epochs=10, batch_size=128, verbose=2)\n",
    "    \n",
    "    # Make predictions, trainPredict should be 1D array\n",
    "    trainPredict = RNN_model.predict(trainX)\n",
    "    testPredict = RNN_model.predict(testX)\n",
    "    \n",
    "    # Change the dimension from 3D to 2D\n",
    "    trainX_2D = trainX.transpose([1,0,2]).reshape(len(trainX),len(trainX[0][0]))\n",
    "    testX_2D = testX.transpose([1,0,2]).reshape(len(testX),len(testX[0][0]))\n",
    "    \n",
    "    # Append prediction back to the model\n",
    "    trainPredict_6cols = np.append(trainX_2D, trainPredict, 1)\n",
    "    testPredict_6cols = np.append(testX_2D, testPredict, 1)\n",
    "\n",
    "    # Invert predictions back to normal values\n",
    "    trainPredict_6cols = scaler.inverse_transform(trainPredict_6cols)\n",
    "    testPredict_6cols = scaler.inverse_transform(testPredict_6cols)\n",
    "    \n",
    "    # Calculating the RMSE\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict_6cols[:, pre_col_index]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict_6cols[:, pre_col_index]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    \n",
    "    final_prediction_train = np.where(trainPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    final_prediction_test = np.where(testPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    \n",
    "    # Change dimension from 2D to 1D\n",
    "    final_prediction_train = np.reshape(final_prediction_train, (-1, 1))\n",
    "    final_prediction_test = np.reshape(final_prediction_test, (-1, 1))\n",
    "    \n",
    "    # Counting the accuracy by using basic calculation\n",
    "    rnn_acc_train = sklearn.metrics.accuracy_score(np.array(final_prediction_train)[:], \n",
    "                                     np.array(trainY)[:])\n",
    "    rnn_acc_test = sklearn.metrics.accuracy_score(np.array(final_prediction_test)[:], \n",
    "                                     np.array(testY)[:])\n",
    "    return rnn_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rnn_acc = rnn_pre(df_train)\n",
    "# rnn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Data (Call the function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.85199999999999%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy: 99.634%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAAAAAcoUQAAAA5QogAAABz4G/bZMGTq1KhaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 55)                935       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 1,047\n",
      "Trainable params: 1,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0058 - acc: 0.9938 - val_loss: 0.0020 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0019 - acc: 0.9983 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 2s 8us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 2s 10us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 2s 9us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 11us/step\n"
     ]
    }
   ],
   "source": [
    "ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, df_train, X_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 55)                935       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 10,287\n",
      "Trainable params: 10,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0040 - acc: 0.9963 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 13us/step\n"
     ]
    }
   ],
   "source": [
    "mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, df_train, X_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. RNN - Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss: 0.0013\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0013\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0012\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0012\n",
      "Train Score: 0.03 RMSE\n",
      "Test Score: 0.03 RMSE\n",
      "RNN accuracy: 41.82026666666667%\n"
     ]
    }
   ],
   "source": [
    "rnn_acc = rnn_pre(df_train)\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.864%\n",
      "Gradient Boosting accuracy: 99.634%\n",
      "Logistic Regression accuracy: 99.824%\n",
      "SVM accuracy: 99.824%\n",
      "ANN accuracy: 99.824%\n",
      "MLP accuracy: 99.824%\n",
      "RNN accuracy: 41.82026666666667%\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))\n",
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))\n",
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is the best one for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'ip_confRate',\n",
       " 'app_confRate',\n",
       " 'device_confRate',\n",
       " 'os_confRate',\n",
       " 'channel_confRate',\n",
       " 'app_channel_confRate',\n",
       " 'app_os_confRate',\n",
       " 'app_device_confRate',\n",
       " 'channel_os_confRate',\n",
       " 'channel_device_confRate',\n",
       " 'os_device_confRate']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns for our current analsis\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "df = pd.read_csv('data/test_small_all_features.csv')[train_cols].astype('float64')\n",
    "df = np.nan_to_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the output of the test data\n",
    "sample_out = pd.read_csv('data/sample_submission.csv', nrows=1000000)[['is_attributed']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predict = rf_model.predict(df)\n",
    "# Compare the prediction with the known values\n",
    "df_acc = sklearn.metrics.accuracy_score(np.array(df_predict)[:], \n",
    "                                         np.array(sample_out)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using the best algorittm, the accuracy of the prediction: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print('By using the best algorittm, the accuracy of the prediction: {}%'.format(df_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the document is licensed under the MIT License: https://opensource.org/licenses/MIT\n",
    "\n",
    "All writing in the document is licensed bt The Creative Commons Attribution 3.0 https://creativecommons.org/licenses/by/3.0/us/."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
