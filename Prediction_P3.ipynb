{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspirational Notebooks\n",
    "### Generating new festures according to these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected\n",
    "* https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "* https://www.kaggle.com/aharless/swetha-s-xgboost-revised\n",
    "* https://www.kaggle.com/bk0000/non-blending-lightgbm-model-lb-0-977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            200000 non-null int64\n",
      "ip                                    200000 non-null int64\n",
      "app                                   200000 non-null int64\n",
      "device                                200000 non-null int64\n",
      "os                                    200000 non-null int64\n",
      "channel                               200000 non-null int64\n",
      "click_time                            200000 non-null object\n",
      "attributed_time                       348 non-null object\n",
      "is_attributed                         200000 non-null int64\n",
      "day                                   200000 non-null int64\n",
      "hour                                  200000 non-null int64\n",
      "minute                                200000 non-null int64\n",
      "second                                200000 non-null int64\n",
      "ip_confRate                           200000 non-null float64\n",
      "app_confRate                          200000 non-null float64\n",
      "device_confRate                       200000 non-null float64\n",
      "os_confRate                           200000 non-null float64\n",
      "channel_confRate                      200000 non-null float64\n",
      "app_channel_confRate                  200000 non-null float64\n",
      "app_os_confRate                       200000 non-null float64\n",
      "app_device_confRate                   200000 non-null float64\n",
      "channel_os_confRate                   200000 non-null float64\n",
      "channel_device_confRate               200000 non-null float64\n",
      "os_device_confRate                    200000 non-null float64\n",
      "ip_app_channel_var_day                134217 non-null float64\n",
      "ip_app_os_var_hour                    139465 non-null float64\n",
      "ip_day_channel_var_hour_x             151335 non-null float64\n",
      "ip_day_hour_count_channel             200000 non-null int64\n",
      "ip_app_count_channel                  200000 non-null int64\n",
      "ip_app_os_count_channel               200000 non-null int64\n",
      "ip_app_day_hour_count_channel         200000 non-null int64\n",
      "ip_app_channel_mean_hour              200000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             200000 non-null float64\n",
      "app_count_channel                     200000 non-null int64\n",
      "channel_count_app                     200000 non-null int64\n",
      "ip_nunique_channel                    200000 non-null int64\n",
      "ip_nunique_app                        200000 non-null int64\n",
      "ip_day_nunique_hour                   200000 non-null int64\n",
      "ip_app_nunique_os                     200000 non-null int64\n",
      "ip_nunique_device                     200000 non-null int64\n",
      "app_nunique_channel                   200000 non-null int64\n",
      "ip_device_os_nunique_app              200000 non-null int64\n",
      "ip_device_os_cumcount_app             200000 non-null int64\n",
      "ip_cumcount_app                       200000 non-null int64\n",
      "ip_cumcount_os                        200000 non-null int64\n",
      "ip_day_channel_var_hour_y             151335 non-null float64\n",
      "ip_nextClick                          197456 non-null float64\n",
      "ip_app_nextClick                      163726 non-null float64\n",
      "ip_channel_nextClick                  138039 non-null float64\n",
      "ip_os_nextClick                       182531 non-null float64\n",
      "ip_app_device_os_channel_nextClick    86990 non-null float64\n",
      "ip_os_device_nextClick                181508 non-null float64\n",
      "ip_os_device_app_nextClick            120449 non-null float64\n",
      "prev_identical_clicks                 200000 non-null int64\n",
      "future_identical_clicks               200000 non-null int64\n",
      "prev_app_clicks                       200000 non-null int64\n",
      "future_app_clicks                     200000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 87.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_train= pd.read_csv('data/train.csv',nrows=200000, parse_dates=['click_time'])\n",
    "df_train = pd.read_csv('data/train_new_cols.csv',nrows=200000) #train data subset, original too large\n",
    "df_train.dropna()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
       "       'attributed_time', 'is_attributed', 'day', 'hour', 'minute',\n",
       "       'second', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
       "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
       "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
       "       'channel_device_confRate', 'os_device_confRate',\n",
       "       'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
       "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
       "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
       "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
       "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
       "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
       "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
       "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
       "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
       "       'ip_day_channel_var_hour_y', 'ip_nextClick', 'ip_app_nextClick',\n",
       "       'ip_channel_nextClick', 'ip_os_nextClick',\n",
       "       'ip_app_device_os_channel_nextClick', 'ip_os_device_nextClick',\n",
       "       'ip_os_device_app_nextClick', 'prev_identical_clicks',\n",
       "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
    "       'attributed_time', 'is_attributed', 'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
    "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
    "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
    "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
    "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
    "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
    "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
    "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
    "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
    "       'ip_day_channel_var_hour_y',]\n",
    "df_train = df_train.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>ip_app_channel_var_day</th>\n",
       "      <th>ip_app_os_var_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_nunique_app</th>\n",
       "      <th>ip_day_nunique_hour</th>\n",
       "      <th>ip_app_nunique_os</th>\n",
       "      <th>ip_nunique_device</th>\n",
       "      <th>app_nunique_channel</th>\n",
       "      <th>ip_device_os_nunique_app</th>\n",
       "      <th>ip_device_os_cumcount_app</th>\n",
       "      <th>ip_cumcount_app</th>\n",
       "      <th>ip_cumcount_os</th>\n",
       "      <th>ip_day_channel_var_hour_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114221</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:38:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74544</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 14:38:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "5   18787    3       1  16      379  2017-11-06 14:36:26             NaN   \n",
       "6  103022    3       1  23      379  2017-11-06 14:37:44             NaN   \n",
       "7  114221    3       1  19      379  2017-11-06 14:37:59             NaN   \n",
       "8  165970    3       1  13      379  2017-11-06 14:38:10             NaN   \n",
       "9   74544   64       1  22      459  2017-11-06 14:38:23             NaN   \n",
       "\n",
       "   is_attributed  ip_app_channel_var_day  ip_app_os_var_hour  \\\n",
       "0              0                     0.0            0.266667   \n",
       "1              0                     0.0            0.571429   \n",
       "2              0                     NaN            1.333333   \n",
       "3              0                     NaN            0.200000   \n",
       "4              0                     NaN                 NaN   \n",
       "5              0                     0.0                 NaN   \n",
       "6              0                     NaN                 NaN   \n",
       "7              0                     NaN                 NaN   \n",
       "8              0                     NaN                 NaN   \n",
       "9              0                     0.0                 NaN   \n",
       "\n",
       "             ...              ip_nunique_app  ip_day_nunique_hour  \\\n",
       "0            ...                          19                    2   \n",
       "1            ...                          20                    3   \n",
       "2            ...                          17                    2   \n",
       "3            ...                          31                    2   \n",
       "4            ...                           1                    1   \n",
       "5            ...                           4                    3   \n",
       "6            ...                          16                    2   \n",
       "7            ...                           9                    2   \n",
       "8            ...                           9                    2   \n",
       "9            ...                           4                    2   \n",
       "\n",
       "   ip_app_nunique_os  ip_nunique_device  app_nunique_channel  \\\n",
       "0                  5                  1                   34   \n",
       "1                  8                  1                   34   \n",
       "2                  6                  3                   34   \n",
       "3                 18                  6                   26   \n",
       "4                  1                  1                   34   \n",
       "5                  3                  1                   34   \n",
       "6                  4                  2                   34   \n",
       "7                  3                  1                   34   \n",
       "8                  2                  2                   34   \n",
       "9                  2                  1                    1   \n",
       "\n",
       "   ip_device_os_nunique_app  ip_device_os_cumcount_app  ip_cumcount_app  \\\n",
       "0                        16                          0                0   \n",
       "1                        11                          0                0   \n",
       "2                        10                          0                0   \n",
       "3                        24                          0                0   \n",
       "4                         1                          0                0   \n",
       "5                         1                          0                0   \n",
       "6                         1                          0                0   \n",
       "7                         2                          0                0   \n",
       "8                         3                          0                0   \n",
       "9                         1                          0                0   \n",
       "\n",
       "   ip_cumcount_os  ip_day_channel_var_hour_y  \n",
       "0               0                   1.333333  \n",
       "1               0                   1.000000  \n",
       "2               0                   2.000000  \n",
       "3               0                   1.000000  \n",
       "4               0                        NaN  \n",
       "5               0                   0.500000  \n",
       "6               0                   2.000000  \n",
       "7               0                        NaN  \n",
       "8               0                        NaN  \n",
       "9               0                   1.333333  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199652\n",
       "1       348\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEFCAYAAAAmIwo/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHI1JREFUeJzt3XtsVGX+x/H3dFoQOq21EggNFItC\nlLvtCO5auqvYDGxE5FpgLa6oCMvFuguCFVr4tVzMsiWx3IvZkCrLRVgl0XihWWxasMhowRZhWRcq\nt0URlXYQ2s6c3x8bJ9u11NGnM4X280pIOg/fc/o9zcl85pxnzjk2y7IsREREDIS1dAMiInLjU5iI\niIgxhYmIiBhTmIiIiDGFiYiIGAtv6QZagtvtbukWRERuSElJSY2Ot8kwgWv/QUREpHFNfRDXaS4R\nETGmMBEREWMKExERMaYwERERYwoTERExpjARERFjQftqcF1dHZmZmZw5c4ba2lpmzJjBHXfcwYIF\nC7DZbPTq1Yvs7GzCwsJYvXo1e/fuJTw8nMzMTAYMGEBVVZVxrYiIhEbQ3nF3795NTEwMW7ZsYdOm\nTeTk5LB8+XIyMjLYsmULlmVRVFREZWUlBw4cYMeOHeTl5bFkyRIA41oREQmdoB2ZDB8+HJfLBYBl\nWdjtdiorKxk8eDAAKSkplJaWkpCQQHJyMjabjbi4OLxeLxcvXjSuTU1NbbI/XQUvItJ8ghYmkZGR\nANTU1DBnzhwyMjJ48cUXsdls/v+vrq6mpqaGmJiYBstVV1djWZZR7Y8xvQL+4JzpRstL6+R8aX1L\ntyASNC12Bfy5c+eYMmUKo0aNYuTIkQ3mMTweD9HR0TgcDjweT4PxqKgo41oREQmdoIXJhQsXmDp1\nKvPmzWPcuHEA9OnTh7KyMgCKi4txOp0kJiZSUlKCz+fj7Nmz+Hw+YmNjjWtFRCR0gnaaa/369Vy6\ndIm1a9eydu1aAF544QVyc3PJy8ujZ8+euFwu7HY7TqeTtLQ0fD4fWVlZAMyfP59Fixb97FoREQkd\nm2VZVks3EWput1tzJhIUmjOR1qyp905djCEiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJM\nYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEi\nIiLGFCYiImIsaM+ABzh06BArV66ksLCQZ599lgsXLgBw5swZBg4cyKpVq5gxYwZff/01ERERtG/f\nnk2bNlFVVcWCBQuw2Wz06tWL7OxswsLCWL16NXv37iU8PJzMzEwGDBhwzVoREQmdoIVJQUEBu3fv\npkOHDgCsWrUKgG+//ZYpU6bw/PPPA1BVVcWbb76JzWbzL7t8+XIyMjIYMmQIWVlZFBUVERcXx4ED\nB9ixYwfnzp1j9uzZ7Ny5s9Ha1NTUYG2WiIg0ImhhEh8fT35+Ps8991yD8fz8fB599FE6d+7MhQsX\nuHTpEtOnT+fSpUtMmzaN+++/n8rKSgYPHgxASkoKpaWlJCQkkJycjM1mIy4uDq/Xy8WLFxutDSRM\n3G5382+0tHnar6StClqYuFwuTp8+3WDsq6++Yv/+/f6jkrq6OqZOncqUKVP49ttvmTRpEgMGDMCy\nLP+RSmRkJNXV1dTU1BATE+Nf1/fjjdUGIikpyWj7Dm4uMFpeWifT/UrketbUh6WQTi68/fbbPPTQ\nQ9jtdgA6derExIkTCQ8P59Zbb+Wuu+7ixIkTDeY8PB4P0dHROBwOPB5Pg/GoqKhGa0VEJLRCGib7\n9+8nJSXF/3rfvn0888wzwH+C4Pjx4/Ts2ZM+ffpQVlYGQHFxMU6nk8TEREpKSvD5fJw9exafz0ds\nbGyjtSIiElpB/TbX/zpx4gTdu3f3v/7Vr35FSUkJEyZMICwsjD/84Q/ExsYyf/58Fi1aRF5eHj17\n9sTlcmG323E6naSlpeHz+cjKygJotFZERELLZlmW1dJNhJrb7TafM5kzvZm6kdbE+dL6lm5BJGia\neu/UBRkiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIi\nxhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLGghomhw4dIj09HYAj\nR44wdOhQ0tPTSU9P56233gJg9erVjBs3jokTJ3L48GEAqqqqmDRpEpMnTyY7Oxufz/eTa0VEJHTC\ng7XigoICdu/eTYcOHQCorKzk8ccfZ+rUqf6ayspKDhw4wI4dOzh37hyzZ89m586dLF++nIyMDIYM\nGUJWVhZFRUXExcUFXJuamhqszRIRkUYELUzi4+PJz8/nueeeA6CiooITJ05QVFREjx49yMzMxO12\nk5ycjM1mIy4uDq/Xy8WLF6msrGTw4MEApKSkUFpaSkJCQsC1gYSJ2+0O1qZLG6b9StqqoIWJy+Xi\n9OnT/tcDBgxg/Pjx9OvXj3Xr1rFmzRqioqKIiYnx10RGRlJdXY1lWdhstgZjNTU1AdcGIikpyWj7\nDm4uMFpeWifT/UrketbUh6WQTcCnpqbSr18//89HjhzB4XDg8Xj8NR6Ph6ioKMLCwhqMRUdH/6Ra\nEREJrZCFyRNPPOGfNN+/fz99+/YlMTGRkpISfD4fZ8+exefzERsbS58+fSgrKwOguLgYp9P5k2pF\nRCS0gnaa638tXryYnJwcIiIi6NSpEzk5OTgcDpxOJ2lpafh8PrKysgCYP38+ixYtIi8vj549e+Jy\nubDb7QHXiohIaNksy7JauolQc7vd5nMmc6Y3UzfSmjhfWt/SLYgETVPvnbpoUUREjClMRETEmMJE\nRESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCRERE\njClMRETEmMJERESMKUxERMSYwkRERIwF9bG9hw4dYuXKlRQWFvLpp5+Sk5OD3W6nXbt2vPjii3Tq\n1Inc3Fw++ugjIiMjAVi7di11dXXMnTuXK1eu0LlzZ5YvX06HDh3Yvn07W7duJTw8nBkzZnD//fdz\n8eLFRmtFRCR0gnZkUlBQwMKFC7l69SoAS5cuZdGiRRQWFpKamkpBQQEAlZWVbNq0icLCQgoLC4mK\nimLt2rU89NBDbNmyhT59+rBt2za+/PJLCgsL2bp1Ky+//DJ5eXnU1tY2WisiIqEVtDCJj48nPz/f\n/zovL4+77roLAK/XS/v27fH5fFRVVZGVlcXEiRN57bXXgP88Z3jo0KEApKSksG/fPg4fPszdd99N\nu3btiIqKIj4+nqNHjzZaKyIioRW001wul4vTp0/7X3fu3BmAjz76iFdeeYVXX32Vy5cv8+ijj/L4\n44/j9XqZMmUK/fr1o6amhqioKAAiIyOprq5uMPb9eE1NTaO1gXC73c21qSJ+2q+krQrqnMn/euut\nt1i3bh0bN24kNjbWHyDfz3Hce++9HD16FIfDgcfj4aabbsLj8RAdHe0f+57H4yEqKqrR2kAkJSUZ\nbcvBzQVGy0vrZLpfiVzPmvqwFLJvc73xxhu88sorFBYW0r17dwBOnjzJpEmT8Hq91NXV8dFHH9G3\nb18SExN5//33ASguLiYpKYkBAwbgdru5evUq1dXVfPbZZ/Tu3bvRWhERCa2QHJl4vV6WLl1K165d\nmT17NgD33HMPc+bMYdSoUUyYMIGIiAhGjRpFr169mDFjBvPnz2f79u3ccsst/PnPf6Zjx46kp6cz\nefJkLMvi2WefpX379o3WiohIaNksy7JauolQc7vd5qe55kxvpm6kNXG+tL6lWxAJmqbeO3XRooiI\nGFOYiIiIMYWJiIgYU5iIiIgxhYmIiBgLKExycnJ+MDZ//vxmb0ZERG5MTV5n8sILL3Dq1CkqKio4\nfvy4f7y+vj7g25aIiEjr12SYzJgxgzNnzrB06VJmzZrlH7fb7dx+++1Bb05ERG4MTYZJt27d6Nat\nG7t376ampobq6mq+v8bx8uXLxMTEhKRJERG5vgV0O5UNGzawYcOGBuFhs9koKioKWmMiInLjCChM\nduzYwZ49e4iNjQ12PyIicgMK6NtcXbt25eabbw52LyIicoMK6MjktttuY/LkyQwZMoR27dr5x/97\nUl5ERNqugMKkS5cudOnSJdi9iIjIDSqgMNERiIiINCWgMLnzzjux2WwNxjp37ux/wqGIiLRtAYXJ\n0aNH/T/X1dWxZ88eysvLg9aUiIjcWH7yjR4jIiIYMWIEH3zwQTD6ERGRG1BARyavv/66/2fLsjh+\n/DgRERE/utyhQ4dYuXIlhYWFVFVVsWDBAmw2G7169SI7O5uwsDBWr17N3r17CQ8PJzMzkwEDBjRL\nrYiIhE5A77plZWX+fwcOHABg1apVTS5TUFDAwoULuXr1KgDLly8nIyODLVu2YFkWRUVFVFZWcuDA\nAXbs2EFeXh5LlixplloREQmtgI5Mli9fTl1dHSdOnMDr9dKrVy/Cw5teND4+nvz8fJ577jkAKisr\nGTx4MAApKSmUlpaSkJBAcnIyNpuNuLg4vF4vFy9eNK5NTU392X8QERH56QIKk4qKCubMmUNMTAw+\nn48LFy6wZs0aBg4ceM1lXC4Xp0+f9r+2LMv/jbDIyEiqq6upqalpcL+v78dNawPhdrsDqhP5KbRf\nSVsVUJjk5uayatUqf3iUl5eTk5PDa6+9FvAv+u95DI/HQ3R0NA6HA4/H02A8KirKuDYQSUlJAffe\nmIObC4yWl9bJdL8SuZ419WEpoDmTy5cvNzgKGTRokH8uJFB9+vShrKwMgOLiYpxOJ4mJiZSUlODz\n+Th79iw+n4/Y2FjjWhERCa2Ajkxuvvlm9uzZw4MPPgjAnj17fvKzTObPn8+iRYvIy8ujZ8+euFwu\n7HY7TqeTtLQ0fD4fWVlZzVIrIiKhZbO+f9pVE06ePMnTTz/NN9984x/bunUrCQkJQW0uWNxut/lp\nrjnTm6kbaU2cL61v6RZEgqap986ATnMVFxfToUMH/v73v7N582ZiY2P9XxEWEREJKEy2b9/OX//6\nVzp27Midd97Jrl27eOWVV4Ldm4iI3CACCpO6uroGV7wHcvW7iIi0HQFNwD/44IM89thjjBgxAoB3\n332XYcOGBbUxERG5cQQUJvPmzePtt9/mww8/JDw8nClTpvi/2SUiIhJQmAAMHz6c4cOHB7MXERG5\nQen2uiIiYkxhIiIixhQmIiJiTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhIiIixhQmIiJiTGEiIiLG\nFCYiImJMYSIiIsYCvtFjc9i1axd/+9vfALh69SqffvopeXl5vPjii3Tt2hWA2bNn43Q6Wbx4MceO\nHaNdu3bk5ubSo0cPysvLWbp0KXa7neTkZGbNmoXP52u0VkREQiekYTJmzBjGjBkDwJIlSxg7diwV\nFRXMmzcPl8vlr3v33Xepra1l27ZtlJeXs2LFCtatW0d2djb5+fl0796dadOmceTIEU6fPt1orYiI\nhE6LnOb65JNP+Oc//0laWhqVlZXs3LmTyZMns2LFCurr63G73QwdOhSAQYMGUVFRQU1NDbW1tcTH\nx2Oz2UhOTmbfvn2N1oqISGiF9Mjkexs2bGDmzJkA3HfffTz44IN069aN7Oxstm7dSk1NDQ6Hw19v\nt9t/MBYZGcmpU6cara2vryc8vOlNc7vdzbxVItqvpO0KeZhcunSJEydOcO+99wIwduxYoqOjARg2\nbBjvvPMOUVFReDwe/zI+nw+Hw9FgzOPxEB0dzZUrV35Q+2NBApCUlGS0HQc3FxgtL62T6X4lcj1r\n6sNSyE9zffjhh/ziF78AwLIsHn74Yf79738DsH//fvr27UtiYiLFxcUAlJeX07t3bxwOBxEREXz+\n+edYlkVJSQlOp7PRWhERCa2QH5mcOHGCbt26AWCz2cjNzWXWrFncdNNN3H777UyYMAG73U5paSkT\nJ07EsiyWLVsG/GfSfu7cuXi9XpKTkxk4cCD9+/dvtFZERELHZlmW1dJNhJrb7TY/zTVnejN1I62J\n86X1Ld2CSNA09d6pixZFRMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwp\nTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMhfwZ\n8KNHj8bhcADQrVs30tLSWLp0KXa7neTkZGbNmoXP52Px4sUcO3aMdu3akZubS48ePSgvLw+4VkRE\nQiekYXL16lUsy6KwsNA/NmrUKPLz8+nevTvTpk3jyJEjnD59mtraWrZt20Z5eTkrVqxg3bp1ZGdn\nB1wrIiKhE9IwOXr0KN999x1Tp06lvr6e2bNnU1tbS3x8PADJycns27ePL7/8kqFDhwIwaNAgKioq\nqKmpCbhWRERCK6RhctNNN/HEE08wfvx4Tp48yVNPPUV0dLT//yMjIzl16hQ1NTX+U2EAdrv9B2NN\n1dbX1xMe3vSmud3uZtwykf/QfiVtVUjDJCEhgR49emCz2UhISCAqKopvvvnG//8ej4fo6GiuXLmC\nx+Pxj/t8PhwOR4Oxpmp/LEgAkpKSjLbl4OYCo+WldTLdr0SuZ019WArpt7lee+01VqxYAcD58+f5\n7rvv6NixI59//jmWZVFSUoLT6SQxMZHi4mIAysvL6d27Nw6Hg4iIiIBqRUQktEJ6ZDJu3Dief/55\nJk2ahM1mY9myZYSFhTF37ly8Xi/JyckMHDiQ/v37U1paysSJE7Esi2XLlgGwZMmSgGtFRCR0bJZl\nWS3dRKi53W7z01xzpjdTN9KaOF9a39ItiARNU++dumhRRESMKUxERMSYwkRERIwpTERExJjCRERE\njClMRETEmMJERESMKUxERMSYwkRERIwpTERExJjCREREjClMRETEmMJERESMKUxERMSYwkRERIwp\nTERExJjCREREjClMRETEWEifAV9XV0dmZiZnzpyhtraWGTNm0LVrV55++mluu+02ACZNmsRvfvMb\nVq9ezd69ewkPDyczM5MBAwZQVVXFggULsNls9OrVi+zsbMLCwhqtFRGR0AlpmOzevZuYmBj+9Kc/\n8c033/DII48wc+ZMHn/8caZOneqvq6ys5MCBA+zYsYNz584xe/Zsdu7cyfLly8nIyGDIkCFkZWVR\nVFREXFxco7UiIhI6IQ2T4cOH43K5ALAsC7vdTkVFBSdOnKCoqIgePXqQmZmJ2+0mOTkZm81GXFwc\nXq+XixcvUllZyeDBgwFISUmhtLSUhISERmtjY2NDuWkiIm1aSMMkMjISgJqaGubMmUNGRga1tbWM\nHz+efv36sW7dOtasWUNUVBQxMTENlquursayLGw2W4OxmpqaRmt/LEzcbncQtlDaOu1X0laFNEwA\nzp07x8yZM5k8eTIjR47k0qVLREdHA5CamkpOTg7Dhg3D4/H4l/F4PERFRREWFtZgLDo6GofD0Wjt\nj0lKSjLajoObC4yWl9bJdL8SuZ419WEppN/munDhAlOnTmXevHmMGzcOgCeeeILDhw8DsH//fvr2\n7UtiYiIlJSX4fD7Onj2Lz+cjNjaWPn36UFZWBkBxcTFOp/OatSIiEjohPTJZv349ly5dYu3ataxd\nuxaABQsWsGzZMiIiIujUqRM5OTk4HA6cTidpaWn4fD6ysrIAmD9/PosWLSIvL4+ePXvicrmw2+2N\n1oqISOjYLMuyWrqJUHO73eanueZMb6ZupDVxvrS+pVsQCZqm3jt10aKIiBhTmIiIiDGFiYiIGFOY\niIiIMYWJiIgYU5iIiIgxhYmIiBhTmIiIiDGFiYiIGFOYiIiIMYWJiIgYU5iIiIgxhYmIiBhTmIiI\niDGFiYiIGFOYiIiIMYWJiIgYU5iIiIixkD4DPlh8Ph+LFy/m2LFjtGvXjtzcXHr06NHSbYmItBmt\n4shkz5491NbWsm3bNv74xz+yYsWKlm5JRKRNaRVHJm63m6FDhwIwaNAgKioqWrgjkZY1fd/Blm5B\nrkPrf+kM2rpbRZjU1NTgcDj8r+12O/X19YSHX3vz3G630e+0PfaU0fLSOpnuV83lqfa2lm5BrkPB\n3D9bRZg4HA48Ho//tc/nazJIkpKSQtGWiEib0SrmTBITEykuLgagvLyc3r17t3BHIiJti82yLKul\nmzD1/be5/vGPf2BZFsuWLeP2229v6bZERNqMVhEmIiLSslrFaS4REWlZChMRETGmMBEREWMKE/nZ\nfD4fWVlZpKWlkZ6eTlVVVUu3JNLAoUOHSE9Pb+k22oRWcZ2JtIz/vo1NeXk5K1asYN26dS3dlggA\nBQUF7N69mw4dOrR0K22CjkzkZ9NtbOR6Fh8fT35+fku30WYoTORnu9ZtbESuBy6Xq8k7YUjzUpjI\nz/ZTb2MjIq2XwkR+Nt3GRkS+p4+R8rOlpqZSWlrKxIkT/bexEZG2SbdTERERYzrNJSIixhQmIiJi\nTGEiIiLGFCYiImJMYSIiIsYUJiIiYkxhInINn3zyCS+88EKzre+/7177/PPPc+bMmR/UnD9/nqee\negqABQsWsGvXroDXX11dze9///uf1NOuXbtYsGDBT1pGpDEKE5Fr6N+/P0uXLm229R04cMD/c1lZ\nGY1d4tWlSxcKCgp+1vq//fZbjh49+rP7EzGhMBG5hrKyMtLT0/nLX/7Cww8/zCOPPEJWVlaTy9TX\n17Nw4ULS0tIYNmwYTz75JFeuXCE3NxeA8ePHs3HjRr744gumTZvG119/zQMPPEBGRgYul4vDhw/z\nwAMP+Ne3d+9exowZw8iRI3nrrbeAHx5NpKenU1ZWRm5uLl988QUzZ84E4PXXX2f06NGMGjWKzMxM\nrl696h93uVyMHTuWvXv3NuefTNowhYlIE+rr69mwYQM7d+5k165d2Gw2zp8/f836jz/+mIiICLZt\n28Z7773H1atXef/991m4cCEAO3bsYNq0aXTu3JmNGzdyyy23AJCSksI777xDbGxsg/V99913bN++\nnU2bNrFs2TK+/PLLa/7uhQsX0rlzZ9asWcPx48fZvn07W7du5Y033uDWW2/l5Zdf5vz586xcuZJX\nX32Vbdu2NbhRp4gJ3ZtLpAnh4eHcfffdjBs3jmHDhvHb3/6WLl26XLP+nnvuISYmhldffZV//etf\nnDx5ksuXL//o7xk4cGCj46NHjyY8PJwuXbowaNAgDh06FFDfZWVlVFVVMWHCBADq6uro06cPH3/8\nMXfffTedOnUCYOTIkXzwwQcBrVOkKQoTkR+xdu1aysvLKS4u5sknn2TlypUMHjy40dqioiJeeukl\npkyZwpgxY/j6668bnRv5X+3bt2903G63+3+2LIuIiAhsNluDddbV1f1gOa/Xy4gRI/xHRB6PB6/X\ny/79+/H5fP46PTJAmotOc4k04eLFi4wYMYLevXvzzDPPcN9993Hs2LFr1u/fv58RI0YwduxYOnXq\nxIcffojX6wUaPjzMbrf7x5vy5ptvYlkWZ86c4ZNPPqF///7ccsstfPbZZ1iWxalTp/z9hIeH+9c/\nZMgQ3nvvPb766issy2Lx4sVs3ryZpKQkDh06xPnz5/H5fP55GBFT+lgi0oTY2FiGDRvGuHHj6NCh\nA127dmX06NHXrB8/fjxz587l7bffpl27dgwaNIjTp08DMGzYMEaNGsWuXbv49a9/zbRp09i0aVOT\nv79jx46MGTOG+vp6/u///o/Y2Fh++ctfsnPnToYPH05CQgJJSUkA3HrrrcTFxZGenk5hYSGzZs3i\nsccew+fzcddddzFt2jTat2/PwoUL+d3vfkeHDh244447mu+PJW2abkEvIiLGdGQi8hMdPHiQnJyc\nRv9v48aNTU7Qi7RWOjIRERFjmoAXERFjChMRETGmMBEREWMKExERMfb/Bht0YSFsvxQAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_train, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            50000 non-null int64\n",
      "ip                                    50000 non-null int64\n",
      "app                                   50000 non-null int64\n",
      "device                                50000 non-null int64\n",
      "os                                    50000 non-null int64\n",
      "channel                               50000 non-null int64\n",
      "click_time                            50000 non-null object\n",
      "attributed_time                       88 non-null object\n",
      "is_attributed                         50000 non-null int64\n",
      "day                                   50000 non-null int64\n",
      "hour                                  50000 non-null int64\n",
      "minute                                50000 non-null int64\n",
      "second                                50000 non-null int64\n",
      "ip_confRate                           50000 non-null float64\n",
      "app_confRate                          50000 non-null float64\n",
      "device_confRate                       50000 non-null float64\n",
      "os_confRate                           50000 non-null float64\n",
      "channel_confRate                      50000 non-null float64\n",
      "app_channel_confRate                  50000 non-null float64\n",
      "app_os_confRate                       50000 non-null float64\n",
      "app_device_confRate                   50000 non-null float64\n",
      "channel_os_confRate                   50000 non-null float64\n",
      "channel_device_confRate               50000 non-null float64\n",
      "os_device_confRate                    50000 non-null float64\n",
      "ip_app_channel_var_day                34970 non-null float64\n",
      "ip_app_os_var_hour                    36809 non-null float64\n",
      "ip_day_channel_var_hour_x             38512 non-null float64\n",
      "ip_day_hour_count_channel             50000 non-null int64\n",
      "ip_app_count_channel                  50000 non-null int64\n",
      "ip_app_os_count_channel               50000 non-null int64\n",
      "ip_app_day_hour_count_channel         50000 non-null int64\n",
      "ip_app_channel_mean_hour              50000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             50000 non-null float64\n",
      "app_count_channel                     50000 non-null int64\n",
      "channel_count_app                     50000 non-null int64\n",
      "ip_nunique_channel                    50000 non-null int64\n",
      "ip_nunique_app                        50000 non-null int64\n",
      "ip_day_nunique_hour                   50000 non-null int64\n",
      "ip_app_nunique_os                     50000 non-null int64\n",
      "ip_nunique_device                     50000 non-null int64\n",
      "app_nunique_channel                   50000 non-null int64\n",
      "ip_device_os_nunique_app              50000 non-null int64\n",
      "ip_device_os_cumcount_app             50000 non-null int64\n",
      "ip_cumcount_app                       50000 non-null int64\n",
      "ip_cumcount_os                        50000 non-null int64\n",
      "ip_day_channel_var_hour_y             38512 non-null float64\n",
      "ip_nextClick                          48959 non-null float64\n",
      "ip_app_nextClick                      39531 non-null float64\n",
      "ip_channel_nextClick                  32900 non-null float64\n",
      "ip_os_nextClick                       44728 non-null float64\n",
      "ip_app_device_os_channel_nextClick    21355 non-null float64\n",
      "ip_os_device_nextClick                44410 non-null float64\n",
      "ip_os_device_app_nextClick            29197 non-null float64\n",
      "prev_identical_clicks                 50000 non-null int64\n",
      "future_identical_clicks               50000 non-null int64\n",
      "prev_app_clicks                       50000 non-null int64\n",
      "future_app_clicks                     50000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The ratio of df_train to df_test is 0.8 to 0.2 or 0.75 to 0.25\n",
    "df_test = pd.read_csv('data/train_new_cols.csv', nrows=50000,skiprows=range(1, 400000))\n",
    "df_test.dropna()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>ip_app_channel_var_day</th>\n",
       "      <th>ip_app_os_var_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_nunique_app</th>\n",
       "      <th>ip_day_nunique_hour</th>\n",
       "      <th>ip_app_nunique_os</th>\n",
       "      <th>ip_nunique_device</th>\n",
       "      <th>app_nunique_channel</th>\n",
       "      <th>ip_device_os_nunique_app</th>\n",
       "      <th>ip_device_os_cumcount_app</th>\n",
       "      <th>ip_cumcount_app</th>\n",
       "      <th>ip_cumcount_os</th>\n",
       "      <th>ip_day_channel_var_hour_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115115</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144498</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>237</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1556</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20266</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31564</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>265</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1732</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111114</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0  115115    8       1  13      145  2017-11-06 16:07:47             NaN   \n",
       "1   21633    1       1  19      178  2017-11-06 16:07:47             NaN   \n",
       "2  144498   12       1  17      178  2017-11-06 16:07:47             NaN   \n",
       "3   76919    2       1   6      237  2017-11-06 16:07:47             NaN   \n",
       "4    1556   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "5   67467   15       1  37      245  2017-11-06 16:07:47             NaN   \n",
       "6   20266   64       1  19      459  2017-11-06 16:07:47             NaN   \n",
       "7   31564   15       1  19      265  2017-11-06 16:07:47             NaN   \n",
       "8    1732    9       1  13      134  2017-11-06 16:07:47             NaN   \n",
       "9  111114   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "\n",
       "   is_attributed  ip_app_channel_var_day  ip_app_os_var_hour  \\\n",
       "0              0                     0.0                 0.0   \n",
       "1              0                     0.0                 0.0   \n",
       "2              0                     NaN                 0.0   \n",
       "3              0                     0.0                 NaN   \n",
       "4              0                     0.0                 0.0   \n",
       "5              0                     0.0                 0.0   \n",
       "6              0                     0.0                 NaN   \n",
       "7              0                     NaN                 0.0   \n",
       "8              0                     0.0                 0.0   \n",
       "9              0                     0.0                 NaN   \n",
       "\n",
       "             ...              ip_nunique_app  ip_day_nunique_hour  \\\n",
       "0            ...                          15                    1   \n",
       "1            ...                          10                    1   \n",
       "2            ...                          16                    1   \n",
       "3            ...                          26                    1   \n",
       "4            ...                          12                    1   \n",
       "5            ...                          14                    1   \n",
       "6            ...                          18                    1   \n",
       "7            ...                          19                    1   \n",
       "8            ...                           6                    1   \n",
       "9            ...                           5                    1   \n",
       "\n",
       "   ip_app_nunique_os  ip_nunique_device  app_nunique_channel  \\\n",
       "0                  1                  1                    3   \n",
       "1                  1                  1                   24   \n",
       "2                  3                  1                   26   \n",
       "3                 19                  3                   19   \n",
       "4                  1                  1                   25   \n",
       "5                  7                  2                   25   \n",
       "6                  2                  2                    1   \n",
       "7                  3                  2                   25   \n",
       "8                  2                  1                   28   \n",
       "9                  2                  1                   25   \n",
       "\n",
       "   ip_device_os_nunique_app  ip_device_os_cumcount_app  ip_cumcount_app  \\\n",
       "0                         7                          7                7   \n",
       "1                         6                          7               25   \n",
       "2                         4                          5               25   \n",
       "3                         3                          0              110   \n",
       "4                        12                          0                0   \n",
       "5                         3                         11              142   \n",
       "6                        11                         18               63   \n",
       "7                        13                          7               22   \n",
       "8                         4                        168              181   \n",
       "9                         1                          0                6   \n",
       "\n",
       "   ip_cumcount_os  ip_day_channel_var_hour_y  \n",
       "0               7                        0.0  \n",
       "1              25                        0.0  \n",
       "2              25                        0.0  \n",
       "3             110                        0.0  \n",
       "4               0                        0.0  \n",
       "5             142                        0.0  \n",
       "6              63                        0.0  \n",
       "7              22                        0.0  \n",
       "8             181                        0.0  \n",
       "9               6                        0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49912\n",
       "1       88\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsf8DoQTTGbbtqNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_test, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'ip_app_channel_var_day',\n",
       " 'ip_app_os_var_hour',\n",
       " 'ip_day_channel_var_hour_x',\n",
       " 'ip_day_hour_count_channel',\n",
       " 'ip_app_count_channel',\n",
       " 'ip_app_os_count_channel',\n",
       " 'ip_app_day_hour_count_channel',\n",
       " 'ip_app_channel_mean_hour',\n",
       " 'app_AvgViewPerDistinct_ip',\n",
       " 'app_count_channel',\n",
       " 'channel_count_app',\n",
       " 'ip_nunique_channel',\n",
       " 'ip_nunique_app',\n",
       " 'ip_day_nunique_hour',\n",
       " 'ip_app_nunique_os',\n",
       " 'ip_nunique_device',\n",
       " 'app_nunique_channel',\n",
       " 'ip_device_os_nunique_app',\n",
       " 'ip_device_os_cumcount_app',\n",
       " 'ip_cumcount_app',\n",
       " 'ip_cumcount_os',\n",
       " 'ip_day_channel_var_hour_y']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columes names except the click_time (object), attributed_time (object) and is_attributed\n",
    "train_cols = []\n",
    "for each_value in df_train.columns.values:\n",
    "    if each_value == 'click_time' or each_value == 'attributed_time' or each_value == 'is_attributed':\n",
    "        continue\n",
    "    train_cols.append(each_value)\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_X\n",
    "X_train = df_train.loc[:,train_cols]\n",
    "X_test = df_test.loc[:,train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_Y\n",
    "y_train = df_train[['is_attributed']]\n",
    "y_test = df_test[['is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_val = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    RF_model = RandomForestClassifier()\n",
    "    # Train the model\n",
    "    RF_fit = RF_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    RF_predict = RF_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    RF_acc = sklearn.metrics.accuracy_score(np.array(RF_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(RF_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return RF_fit, RF_predict, RF_acc, RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "# RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting & AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientBoosting_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    GB_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    # Train the model\n",
    "    GB_fit = GB_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    GB_predict = GB_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    GB_acc = sklearn.metrics.accuracy_score(np.array(GB_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(GB_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return GB_fit, GB_predict, GB_acc, GB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "# GB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    LG_model = LogisticRegression()\n",
    "    # Train the model\n",
    "    LG_fit = LG_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    LG_predict = LG_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    LG_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    return LG_fit, LG_predict, LG_acc, LG_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "# LG_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    svm_model = svm.SVC()\n",
    "    uniq = np.unique(y_train[9000:10000])\n",
    "    # Train the model\n",
    "    SVM_fit = svm_model.fit(X_train[9000:10000], y_train[9000:10000])\n",
    "    # Get the prediction of the test data\n",
    "    SVM_predict = svm_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    SVM_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                     np.array(y_test_val)[:])\n",
    "    return SVM_fit, SVM_predict, SVM_acc, svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_A(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ann_pre(X_train, y_train, X_test, y_test):\n",
    "    ann_model = shallow_net_A()\n",
    "    ann_summary = ann_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_ann = np.nan_to_num(X_train)\n",
    "    y_train_ann = np.nan_to_num(y_train)\n",
    "    X_test_ann = np.nan_to_num(X_test)\n",
    "    y_test_ann = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes), the original one has oly one class\n",
    "    n_classes = 2\n",
    "    y_train_ann = keras.utils.to_categorical(y_train_ann, n_classes)\n",
    "    y_test_ann = keras.utils.to_categorical(y_test_ann, n_classes)\n",
    "    # Training the model\n",
    "    ann_fit = ann_model.fit(X_train_ann, y_train_ann, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_ann, y_test_ann))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    ann_evaluate = ann_model.evaluate(X_test_ann, y_test_ann)\n",
    "    \n",
    "    # Using prediction\n",
    "    ann_pre = ann_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (ann_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ann_output = confusion_matrix(y_test_ann.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    ann_prediction_acc = ann_output[0][0]/(ann_output[0][0]+ann_output[1][0])\n",
    "    \n",
    "    return ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_C(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2, here we have more hidden layers with different activation\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='relu', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='tanh', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='elu', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_pre(X_train, y_train, X_test, y_test):\n",
    "    mlp_model = shallow_net_C()\n",
    "    mlp_summary = mlp_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_mlp = np.nan_to_num(X_train)\n",
    "    y_train_mlp = np.nan_to_num(y_train)\n",
    "    X_test_mlp = np.nan_to_num(X_test)\n",
    "    y_test_mlp = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes)\n",
    "    n_classes = 2\n",
    "    y_train_mlp = keras.utils.to_categorical(y_train_mlp, n_classes)\n",
    "    y_test_mlp = keras.utils.to_categorical(y_test_mlp, n_classes)\n",
    "    # Training the model\n",
    "    mlp_fit = mlp_model.fit(X_train_mlp, y_train_mlp, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_mlp, y_test_mlp))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    mlp_evaluate = mlp_model.evaluate(X_test_mlp, y_test_mlp)\n",
    "    \n",
    "    # Using prediction\n",
    "    mlp_pre = mlp_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (mlp_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mlp_output = confusion_matrix(y_test_mlp.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    mlp_prediction_acc = mlp_output[0][0]/(mlp_output[0][0]+mlp_output[1][0])\n",
    "    \n",
    "    return mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. RNN - Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnn_pre(df_train, train_rate=0.75):\n",
    "    # Set the dataset for train and test\n",
    "    df_rnn_train = df_train.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn_test = df_test.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn = df_rnn_train.append(df_rnn_test)\n",
    "    \n",
    "    pre_col_index = list(df_rnn_train).index('is_attributed')\n",
    "    dataset = df_rnn.values.astype('float32')\n",
    "    dataset = np.nan_to_num(dataset)\n",
    "    \n",
    "    # Normalize the dataset, set all the data of the dataset to be in the range between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(dataset) * train_rate)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    \n",
    "    # Use this function to prepare the train and test datasets for modeling\n",
    "    look_back = 1\n",
    "    trainY = train[:, pre_col_index]\n",
    "    trainX = np.delete(train, pre_col_index, axis = 1) \n",
    "    testY = test[:, pre_col_index]\n",
    "    testX = np.delete(test, pre_col_index, axis = 1) \n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features], here it changes the dimension from 2D to 3D\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(LSTM(5, input_shape=(1, len(trainX[0][0]))))\n",
    "    RNN_model.add(Dense(1))\n",
    "    RNN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    RNN_model.fit(trainX, trainY, epochs=10, batch_size=128, verbose=2)\n",
    "    \n",
    "    # Make predictions, trainPredict should be 1D array\n",
    "    trainPredict = RNN_model.predict(trainX)\n",
    "    testPredict = RNN_model.predict(testX)\n",
    "    \n",
    "    # Change the dimension from 3D to 2D\n",
    "    trainX_2D = trainX.transpose([1,0,2]).reshape(len(trainX),len(trainX[0][0]))\n",
    "    testX_2D = testX.transpose([1,0,2]).reshape(len(testX),len(testX[0][0]))\n",
    "    \n",
    "    # Append prediction back to the model\n",
    "    trainPredict_6cols = np.append(trainX_2D, trainPredict, 1)\n",
    "    testPredict_6cols = np.append(testX_2D, testPredict, 1)\n",
    "\n",
    "    # Invert predictions back to normal values\n",
    "    trainPredict_6cols = scaler.inverse_transform(trainPredict_6cols)\n",
    "    testPredict_6cols = scaler.inverse_transform(testPredict_6cols)\n",
    "    \n",
    "    # Calculating the RMSE\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict_6cols[:, pre_col_index]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict_6cols[:, pre_col_index]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    \n",
    "    final_prediction_train = np.where(trainPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    final_prediction_test = np.where(testPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    \n",
    "    # Change dimension from 2D to 1D\n",
    "    final_prediction_train = np.reshape(final_prediction_train, (-1, 1))\n",
    "    final_prediction_test = np.reshape(final_prediction_test, (-1, 1))\n",
    "    \n",
    "    # Counting the accuracy by using basic calculation\n",
    "    rnn_acc_train = sklearn.metrics.accuracy_score(np.array(final_prediction_train)[:], \n",
    "                                     np.array(trainY)[:])\n",
    "    rnn_acc_test = sklearn.metrics.accuracy_score(np.array(final_prediction_test)[:], \n",
    "                                     np.array(testY)[:])\n",
    "    return rnn_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rnn_acc = rnn_pre(df_train)\n",
    "# rnn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Data (Call the function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.896%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRURERKQAgygiIiIiBf4/wHfgvHjF/MEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy: 99.816%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 55)                1540      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 1,652\n",
      "Trainable params: 1,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0038 - acc: 0.9979 - val_loss: 0.0020 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0019 - acc: 0.9983 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 17us/step\n"
     ]
    }
   ],
   "source": [
    "ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 55)                1540      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 10,892\n",
      "Trainable params: 10,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0038 - acc: 0.9970 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 5s 25us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 4s 22us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 25us/step\n"
     ]
    }
   ],
   "source": [
    "mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. RNN - Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss: 0.0019\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0017\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0017\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0017\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0017\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0016\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0016\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0016\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0015\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0015\n",
      "Train Score: 0.04 RMSE\n",
      "Test Score: 0.04 RMSE\n",
      "RNN accuracy: 44.299733333333336%\n"
     ]
    }
   ],
   "source": [
    "rnn_acc = rnn_pre(df_train)\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.9%\n",
      "Gradient Boosting accuracy: 99.816%\n",
      "Logistic Regression accuracy: 99.824%\n",
      "SVM accuracy: 99.824%\n",
      "ANN accuracy: 99.824%\n",
      "MLP accuracy: 99.824%\n",
      "RNN accuracy: 44.299733333333336%\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))\n",
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))\n",
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is the best one for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'ip_app_channel_var_day',\n",
       " 'ip_app_os_var_hour',\n",
       " 'ip_day_channel_var_hour_x',\n",
       " 'ip_day_hour_count_channel',\n",
       " 'ip_app_count_channel',\n",
       " 'ip_app_os_count_channel',\n",
       " 'ip_app_day_hour_count_channel',\n",
       " 'ip_app_channel_mean_hour',\n",
       " 'app_AvgViewPerDistinct_ip',\n",
       " 'app_count_channel',\n",
       " 'channel_count_app',\n",
       " 'ip_nunique_channel',\n",
       " 'ip_nunique_app',\n",
       " 'ip_day_nunique_hour',\n",
       " 'ip_app_nunique_os',\n",
       " 'ip_nunique_device',\n",
       " 'app_nunique_channel',\n",
       " 'ip_device_os_nunique_app',\n",
       " 'ip_device_os_cumcount_app',\n",
       " 'ip_cumcount_app',\n",
       " 'ip_cumcount_os',\n",
       " 'ip_day_channel_var_hour_y']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns for our current analsis\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "df = pd.read_csv('data/test_small_all_features.csv')[train_cols].astype('float64')\n",
    "df = np.nan_to_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the output of the test data\n",
    "sample_out = pd.read_csv('data/sample_submission.csv', nrows=1000000)[['is_attributed']].astype('float64')\n",
    "sample_out = np.nan_to_num(sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predict = rf_model.predict(df)\n",
    "# Compare the prediction with the known values\n",
    "df_acc = sklearn.metrics.accuracy_score(np.array(df_predict)[:], \n",
    "                                         np.array(sample_out)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using the best algorittm, the accuracy of the prediction: 99.99090000000001%\n"
     ]
    }
   ],
   "source": [
    "print('By using the best algorittm, the accuracy of the prediction: {}%'.format(df_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the document is licensed under the MIT License: https://opensource.org/licenses/MIT\n",
    "\n",
    "All writing in the document is licensed bt The Creative Commons Attribution 3.0 https://creativecommons.org/licenses/by/3.0/us/."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
