{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspirational Notebooks\n",
    "### Generating new festures according to these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/nuhsikander/lgbm-new-features-corrected\n",
    "* https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "* https://www.kaggle.com/aharless/swetha-s-xgboost-revised\n",
    "* https://www.kaggle.com/bk0000/non-blending-lightgbm-model-lb-0-977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/PP/Documents/7250/Python/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            200000 non-null int64\n",
      "ip                                    200000 non-null int64\n",
      "app                                   200000 non-null int64\n",
      "device                                200000 non-null int64\n",
      "os                                    200000 non-null int64\n",
      "channel                               200000 non-null int64\n",
      "click_time                            200000 non-null object\n",
      "attributed_time                       348 non-null object\n",
      "is_attributed                         200000 non-null int64\n",
      "day                                   200000 non-null int64\n",
      "hour                                  200000 non-null int64\n",
      "minute                                200000 non-null int64\n",
      "second                                200000 non-null int64\n",
      "ip_confRate                           200000 non-null float64\n",
      "app_confRate                          200000 non-null float64\n",
      "device_confRate                       200000 non-null float64\n",
      "os_confRate                           200000 non-null float64\n",
      "channel_confRate                      200000 non-null float64\n",
      "app_channel_confRate                  200000 non-null float64\n",
      "app_os_confRate                       200000 non-null float64\n",
      "app_device_confRate                   200000 non-null float64\n",
      "channel_os_confRate                   200000 non-null float64\n",
      "channel_device_confRate               200000 non-null float64\n",
      "os_device_confRate                    200000 non-null float64\n",
      "ip_app_channel_var_day                134217 non-null float64\n",
      "ip_app_os_var_hour                    139465 non-null float64\n",
      "ip_day_channel_var_hour_x             151335 non-null float64\n",
      "ip_day_hour_count_channel             200000 non-null int64\n",
      "ip_app_count_channel                  200000 non-null int64\n",
      "ip_app_os_count_channel               200000 non-null int64\n",
      "ip_app_day_hour_count_channel         200000 non-null int64\n",
      "ip_app_channel_mean_hour              200000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             200000 non-null float64\n",
      "app_count_channel                     200000 non-null int64\n",
      "channel_count_app                     200000 non-null int64\n",
      "ip_nunique_channel                    200000 non-null int64\n",
      "ip_nunique_app                        200000 non-null int64\n",
      "ip_day_nunique_hour                   200000 non-null int64\n",
      "ip_app_nunique_os                     200000 non-null int64\n",
      "ip_nunique_device                     200000 non-null int64\n",
      "app_nunique_channel                   200000 non-null int64\n",
      "ip_device_os_nunique_app              200000 non-null int64\n",
      "ip_device_os_cumcount_app             200000 non-null int64\n",
      "ip_cumcount_app                       200000 non-null int64\n",
      "ip_cumcount_os                        200000 non-null int64\n",
      "ip_day_channel_var_hour_y             151335 non-null float64\n",
      "ip_nextClick                          197456 non-null float64\n",
      "ip_app_nextClick                      163726 non-null float64\n",
      "ip_channel_nextClick                  138039 non-null float64\n",
      "ip_os_nextClick                       182531 non-null float64\n",
      "ip_app_device_os_channel_nextClick    86990 non-null float64\n",
      "ip_os_device_nextClick                181508 non-null float64\n",
      "ip_os_device_app_nextClick            120449 non-null float64\n",
      "prev_identical_clicks                 200000 non-null int64\n",
      "future_identical_clicks               200000 non-null int64\n",
      "prev_app_clicks                       200000 non-null int64\n",
      "future_app_clicks                     200000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 87.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_train= pd.read_csv('data/train.csv',nrows=200000, parse_dates=['click_time'])\n",
    "df_train = pd.read_csv('data/train_new_cols.csv',nrows=200000) #train data subset, original too large\n",
    "df_train.dropna()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
       "       'attributed_time', 'is_attributed', 'day', 'hour', 'minute',\n",
       "       'second', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
       "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
       "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
       "       'channel_device_confRate', 'os_device_confRate',\n",
       "       'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
       "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
       "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
       "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
       "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
       "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
       "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
       "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
       "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
       "       'ip_day_channel_var_hour_y', 'ip_nextClick', 'ip_app_nextClick',\n",
       "       'ip_channel_nextClick', 'ip_os_nextClick',\n",
       "       'ip_app_device_os_channel_nextClick', 'ip_os_device_nextClick',\n",
       "       'ip_os_device_app_nextClick', 'prev_identical_clicks',\n",
       "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time',\n",
    "       'attributed_time', 'is_attributed', 'day', 'hour', 'minute',\n",
    "       'second', 'ip_confRate', 'app_confRate', 'device_confRate',\n",
    "       'os_confRate', 'channel_confRate', 'app_channel_confRate',\n",
    "       'app_os_confRate', 'app_device_confRate', 'channel_os_confRate',\n",
    "       'channel_device_confRate', 'os_device_confRate',\n",
    "       'ip_app_channel_var_day', 'ip_app_os_var_hour',\n",
    "       'ip_day_channel_var_hour_x', 'ip_day_hour_count_channel',\n",
    "       'ip_app_count_channel', 'ip_app_os_count_channel',\n",
    "       'ip_app_day_hour_count_channel', 'ip_app_channel_mean_hour',\n",
    "       'app_AvgViewPerDistinct_ip', 'app_count_channel',\n",
    "       'channel_count_app', 'ip_nunique_channel', 'ip_nunique_app',\n",
    "       'ip_day_nunique_hour', 'ip_app_nunique_os', 'ip_nunique_device',\n",
    "       'app_nunique_channel', 'ip_device_os_nunique_app',\n",
    "       'ip_device_os_cumcount_app', 'ip_cumcount_app', 'ip_cumcount_os',\n",
    "       'ip_day_channel_var_hour_y', 'ip_nextClick', 'ip_app_nextClick',\n",
    "       'ip_channel_nextClick', 'ip_os_nextClick',\n",
    "       'ip_app_device_os_channel_nextClick', 'ip_os_device_nextClick',\n",
    "       'ip_os_device_app_nextClick', 'prev_identical_clicks',\n",
    "       'future_identical_clicks', 'prev_app_clicks', 'future_app_clicks']\n",
    "df_train = df_train.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_app_nextClick</th>\n",
       "      <th>ip_channel_nextClick</th>\n",
       "      <th>ip_os_nextClick</th>\n",
       "      <th>ip_app_device_os_channel_nextClick</th>\n",
       "      <th>ip_os_device_nextClick</th>\n",
       "      <th>ip_os_device_app_nextClick</th>\n",
       "      <th>prev_identical_clicks</th>\n",
       "      <th>future_identical_clicks</th>\n",
       "      <th>prev_app_clicks</th>\n",
       "      <th>future_app_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>5307.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5307.0</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5177.0</td>\n",
       "      <td>5177.0</td>\n",
       "      <td>5239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5239.0</td>\n",
       "      <td>5547.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>6005.0</td>\n",
       "      <td>5205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5205.0</td>\n",
       "      <td>5925.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5110.0</td>\n",
       "      <td>5137.0</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>5110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4531.0</td>\n",
       "      <td>4531.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5020.0</td>\n",
       "      <td>5005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114221</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:37:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4955.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:38:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5503.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74544</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 14:38:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5111.0</td>\n",
       "      <td>5111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "5   18787    3       1  16      379  2017-11-06 14:36:26             NaN   \n",
       "6  103022    3       1  23      379  2017-11-06 14:37:44             NaN   \n",
       "7  114221    3       1  19      379  2017-11-06 14:37:59             NaN   \n",
       "8  165970    3       1  13      379  2017-11-06 14:38:10             NaN   \n",
       "9   74544   64       1  22      459  2017-11-06 14:38:23             NaN   \n",
       "\n",
       "   is_attributed  day  hour        ...          ip_app_nextClick  \\\n",
       "0              0    6    14        ...                    5340.0   \n",
       "1              0    6    14        ...                    5177.0   \n",
       "2              0    6    14        ...                    5175.0   \n",
       "3              0    6    14        ...                    5110.0   \n",
       "4              0    6    14        ...                       NaN   \n",
       "5              0    6    14        ...                    4531.0   \n",
       "6              0    6    14        ...                    5020.0   \n",
       "7              0    6    14        ...                    4955.0   \n",
       "8              0    6    14        ...                    5503.0   \n",
       "9              0    6    14        ...                    5111.0   \n",
       "\n",
       "   ip_channel_nextClick  ip_os_nextClick  ip_app_device_os_channel_nextClick  \\\n",
       "0                5444.0           5307.0                                 NaN   \n",
       "1                5177.0           5239.0                                 NaN   \n",
       "2                6005.0           5205.0                                 NaN   \n",
       "3                5137.0           5108.0                                 NaN   \n",
       "4                   NaN              NaN                                 NaN   \n",
       "5                4531.0              NaN                                 NaN   \n",
       "6                5005.0              NaN                                 NaN   \n",
       "7                   NaN           5006.0                                 NaN   \n",
       "8                   NaN           5052.0                                 NaN   \n",
       "9                5111.0              NaN                                 NaN   \n",
       "\n",
       "   ip_os_device_nextClick  ip_os_device_app_nextClick  prev_identical_clicks  \\\n",
       "0                  5307.0                      5340.0                      0   \n",
       "1                  5239.0                      5547.0                      0   \n",
       "2                  5205.0                      5925.0                      0   \n",
       "3                  5108.0                      5110.0                      0   \n",
       "4                     NaN                         NaN                      0   \n",
       "5                     NaN                         NaN                      0   \n",
       "6                     NaN                         NaN                      0   \n",
       "7                  5006.0                         NaN                      0   \n",
       "8                  5052.0                         NaN                      0   \n",
       "9                     NaN                         NaN                      0   \n",
       "\n",
       "   future_identical_clicks  prev_app_clicks  future_app_clicks  \n",
       "0                        0                0                 18  \n",
       "1                        0                0                 22  \n",
       "2                        0                0                  9  \n",
       "3                        0                0                 68  \n",
       "4                        0                0                  0  \n",
       "5                        0                0                  3  \n",
       "6                        0                0                  5  \n",
       "7                        0                0                 10  \n",
       "8                        0                0                  3  \n",
       "9                        0                0                  1  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199652\n",
       "1       348\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEFCAYAAAAmIwo/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_train, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 57 columns):\n",
      "Unnamed: 0                            50000 non-null int64\n",
      "ip                                    50000 non-null int64\n",
      "app                                   50000 non-null int64\n",
      "device                                50000 non-null int64\n",
      "os                                    50000 non-null int64\n",
      "channel                               50000 non-null int64\n",
      "click_time                            50000 non-null object\n",
      "attributed_time                       88 non-null object\n",
      "is_attributed                         50000 non-null int64\n",
      "day                                   50000 non-null int64\n",
      "hour                                  50000 non-null int64\n",
      "minute                                50000 non-null int64\n",
      "second                                50000 non-null int64\n",
      "ip_confRate                           50000 non-null float64\n",
      "app_confRate                          50000 non-null float64\n",
      "device_confRate                       50000 non-null float64\n",
      "os_confRate                           50000 non-null float64\n",
      "channel_confRate                      50000 non-null float64\n",
      "app_channel_confRate                  50000 non-null float64\n",
      "app_os_confRate                       50000 non-null float64\n",
      "app_device_confRate                   50000 non-null float64\n",
      "channel_os_confRate                   50000 non-null float64\n",
      "channel_device_confRate               50000 non-null float64\n",
      "os_device_confRate                    50000 non-null float64\n",
      "ip_app_channel_var_day                34970 non-null float64\n",
      "ip_app_os_var_hour                    36809 non-null float64\n",
      "ip_day_channel_var_hour_x             38512 non-null float64\n",
      "ip_day_hour_count_channel             50000 non-null int64\n",
      "ip_app_count_channel                  50000 non-null int64\n",
      "ip_app_os_count_channel               50000 non-null int64\n",
      "ip_app_day_hour_count_channel         50000 non-null int64\n",
      "ip_app_channel_mean_hour              50000 non-null float64\n",
      "app_AvgViewPerDistinct_ip             50000 non-null float64\n",
      "app_count_channel                     50000 non-null int64\n",
      "channel_count_app                     50000 non-null int64\n",
      "ip_nunique_channel                    50000 non-null int64\n",
      "ip_nunique_app                        50000 non-null int64\n",
      "ip_day_nunique_hour                   50000 non-null int64\n",
      "ip_app_nunique_os                     50000 non-null int64\n",
      "ip_nunique_device                     50000 non-null int64\n",
      "app_nunique_channel                   50000 non-null int64\n",
      "ip_device_os_nunique_app              50000 non-null int64\n",
      "ip_device_os_cumcount_app             50000 non-null int64\n",
      "ip_cumcount_app                       50000 non-null int64\n",
      "ip_cumcount_os                        50000 non-null int64\n",
      "ip_day_channel_var_hour_y             38512 non-null float64\n",
      "ip_nextClick                          48959 non-null float64\n",
      "ip_app_nextClick                      39531 non-null float64\n",
      "ip_channel_nextClick                  32900 non-null float64\n",
      "ip_os_nextClick                       44728 non-null float64\n",
      "ip_app_device_os_channel_nextClick    21355 non-null float64\n",
      "ip_os_device_nextClick                44410 non-null float64\n",
      "ip_os_device_app_nextClick            29197 non-null float64\n",
      "prev_identical_clicks                 50000 non-null int64\n",
      "future_identical_clicks               50000 non-null int64\n",
      "prev_app_clicks                       50000 non-null int64\n",
      "future_app_clicks                     50000 non-null int64\n",
      "dtypes: float64(24), int64(31), object(2)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The ratio of df_train to df_test is 0.8 to 0.2 or 0.75 to 0.25\n",
    "df_test = pd.read_csv('data/train_new_cols.csv', nrows=50000,skiprows=range(1, 400000))\n",
    "df_test.dropna()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_app_nextClick</th>\n",
       "      <th>ip_channel_nextClick</th>\n",
       "      <th>ip_os_nextClick</th>\n",
       "      <th>ip_app_device_os_channel_nextClick</th>\n",
       "      <th>ip_os_device_nextClick</th>\n",
       "      <th>ip_os_device_app_nextClick</th>\n",
       "      <th>prev_identical_clicks</th>\n",
       "      <th>future_identical_clicks</th>\n",
       "      <th>prev_app_clicks</th>\n",
       "      <th>future_app_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115115</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144498</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>237</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1556</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20266</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>689.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31564</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>265</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1732</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111114</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-06 16:07:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0  115115    8       1  13      145  2017-11-06 16:07:47             NaN   \n",
       "1   21633    1       1  19      178  2017-11-06 16:07:47             NaN   \n",
       "2  144498   12       1  17      178  2017-11-06 16:07:47             NaN   \n",
       "3   76919    2       1   6      237  2017-11-06 16:07:47             NaN   \n",
       "4    1556   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "5   67467   15       1  37      245  2017-11-06 16:07:47             NaN   \n",
       "6   20266   64       1  19      459  2017-11-06 16:07:47             NaN   \n",
       "7   31564   15       1  19      265  2017-11-06 16:07:47             NaN   \n",
       "8    1732    9       1  13      134  2017-11-06 16:07:47             NaN   \n",
       "9  111114   15       1  13      245  2017-11-06 16:07:47             NaN   \n",
       "\n",
       "   is_attributed  day  hour        ...          ip_app_nextClick  \\\n",
       "0              0    6    16        ...                       0.0   \n",
       "1              0    6    16        ...                     344.0   \n",
       "2              0    6    16        ...                      11.0   \n",
       "3              0    6    16        ...                       6.0   \n",
       "4              0    6    16        ...                      50.0   \n",
       "5              0    6    16        ...                      37.0   \n",
       "6              0    6    16        ...                     689.0   \n",
       "7              0    6    16        ...                      23.0   \n",
       "8              0    6    16        ...                      21.0   \n",
       "9              0    6    16        ...                       NaN   \n",
       "\n",
       "   ip_channel_nextClick  ip_os_nextClick  ip_app_device_os_channel_nextClick  \\\n",
       "0                   0.0              0.0                                 0.0   \n",
       "1                   NaN            140.0                                 NaN   \n",
       "2                   NaN              0.0                                 NaN   \n",
       "3                  73.0            709.0                                 NaN   \n",
       "4                   0.0              0.0                                50.0   \n",
       "5                   0.0              0.0                                37.0   \n",
       "6                  36.0              0.0                                 NaN   \n",
       "7                 609.0              3.0                                 NaN   \n",
       "8                   2.0              0.0                                21.0   \n",
       "9                   NaN              NaN                                 NaN   \n",
       "\n",
       "   ip_os_device_nextClick  ip_os_device_app_nextClick  prev_identical_clicks  \\\n",
       "0                     0.0                         0.0                      3   \n",
       "1                   140.0                       344.0                      1   \n",
       "2                     0.0                       133.0                      0   \n",
       "3                   709.0                         NaN                      0   \n",
       "4                     0.0                        50.0                      0   \n",
       "5                     0.0                        37.0                      4   \n",
       "6                     0.0                         NaN                      0   \n",
       "7                     3.0                       461.0                      0   \n",
       "8                     0.0                        21.0                     28   \n",
       "9                     NaN                         NaN                      0   \n",
       "\n",
       "   future_identical_clicks  prev_app_clicks  future_app_clicks  \n",
       "0                        2                3                  2  \n",
       "1                        0                1                  2  \n",
       "2                        0                2                  3  \n",
       "3                        0               24                 49  \n",
       "4                        3                0                  5  \n",
       "5                        7               14                 17  \n",
       "6                        0                0                  1  \n",
       "7                        0                4                  3  \n",
       "8                        2               30                  2  \n",
       "9                        0                2                  0  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49912\n",
       "1       88\n",
       "Name: is_attributed, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsf8DoQTTGbbtqNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='is_attributed', data=df_test, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second',\n",
       " 'ip_confRate',\n",
       " 'app_confRate',\n",
       " 'device_confRate',\n",
       " 'os_confRate',\n",
       " 'channel_confRate',\n",
       " 'app_channel_confRate',\n",
       " 'app_os_confRate',\n",
       " 'app_device_confRate',\n",
       " 'channel_os_confRate',\n",
       " 'channel_device_confRate',\n",
       " 'os_device_confRate',\n",
       " 'ip_app_channel_var_day',\n",
       " 'ip_app_os_var_hour',\n",
       " 'ip_day_channel_var_hour_x',\n",
       " 'ip_day_hour_count_channel',\n",
       " 'ip_app_count_channel',\n",
       " 'ip_app_os_count_channel',\n",
       " 'ip_app_day_hour_count_channel',\n",
       " 'ip_app_channel_mean_hour',\n",
       " 'app_AvgViewPerDistinct_ip',\n",
       " 'app_count_channel',\n",
       " 'channel_count_app',\n",
       " 'ip_nunique_channel',\n",
       " 'ip_nunique_app',\n",
       " 'ip_day_nunique_hour',\n",
       " 'ip_app_nunique_os',\n",
       " 'ip_nunique_device',\n",
       " 'app_nunique_channel',\n",
       " 'ip_device_os_nunique_app',\n",
       " 'ip_device_os_cumcount_app',\n",
       " 'ip_cumcount_app',\n",
       " 'ip_cumcount_os',\n",
       " 'ip_day_channel_var_hour_y',\n",
       " 'ip_nextClick',\n",
       " 'ip_app_nextClick',\n",
       " 'ip_channel_nextClick',\n",
       " 'ip_os_nextClick',\n",
       " 'ip_app_device_os_channel_nextClick',\n",
       " 'ip_os_device_nextClick',\n",
       " 'ip_os_device_app_nextClick',\n",
       " 'prev_identical_clicks',\n",
       " 'future_identical_clicks',\n",
       " 'prev_app_clicks',\n",
       " 'future_app_clicks']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columes names except the click_time (object), attributed_time (object) and is_attributed\n",
    "train_cols = []\n",
    "for each_value in df_train.columns.values:\n",
    "    if each_value == 'click_time' or each_value == 'attributed_time' or each_value == 'is_attributed':\n",
    "        continue\n",
    "    train_cols.append(each_value)\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_X\n",
    "X_train = df_train.loc[:,train_cols]\n",
    "X_test = df_test.loc[:,train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 53)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 53)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_Y\n",
    "y_train = df_train[['is_attributed']]\n",
    "y_test = df_test[['is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_val = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomForest_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    RF_model = RandomForestClassifier()\n",
    "    # Train the model\n",
    "    RF_fit = RF_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    RF_predict = RF_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    RF_acc = sklearn.metrics.accuracy_score(np.array(RF_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(RF_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return RF_fit, RF_predict, RF_acc, RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "# RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting & AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientBoosting_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    GB_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    # Train the model\n",
    "    GB_fit = GB_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    GB_predict = GB_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    GB_acc = sklearn.metrics.accuracy_score(np.array(GB_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(GB_predict, color='red', label='Prediction')\n",
    "    plt.plot(y_test, label='Y_test')\n",
    "    plt.legend(['Prediction', 'Y_test'])\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    return GB_fit, GB_predict, GB_acc, GB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "# GB_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    LG_model = LogisticRegression()\n",
    "    # Train the model\n",
    "    LG_fit = LG_model.fit(X_train, y_train)\n",
    "    # Get the prediction of the test data\n",
    "    LG_predict = LG_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    LG_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                         np.array(y_test_val)[:])\n",
    "    \n",
    "    return LG_fit, LG_predict, LG_acc, LG_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "# LG_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_pre(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = np.nan_to_num(y_test)\n",
    "    svm_model = svm.SVC()\n",
    "    uniq = np.unique(y_train[9000:10000])\n",
    "    # Train the model\n",
    "    SVM_fit = svm_model.fit(X_train[9000:10000], y_train[9000:10000])\n",
    "    # Get the prediction of the test data\n",
    "    SVM_predict = svm_model.predict(X_test)\n",
    "    # Compare the prediction with the known values\n",
    "    SVM_acc = sklearn.metrics.accuracy_score(np.array(LG_predict)[:], \n",
    "                                     np.array(y_test_val)[:])\n",
    "    return SVM_fit, SVM_predict, SVM_acc, svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "# svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_A(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ann_pre(X_train, y_train, X_test, y_test):\n",
    "    ann_model = shallow_net_A()\n",
    "    ann_summary = ann_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_ann = np.nan_to_num(X_train)\n",
    "    y_train_ann = np.nan_to_num(y_train)\n",
    "    X_test_ann = np.nan_to_num(X_test)\n",
    "    y_test_ann = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes), the original one has oly one class\n",
    "    n_classes = 2\n",
    "    y_train_ann = keras.utils.to_categorical(y_train_ann, n_classes)\n",
    "    y_test_ann = keras.utils.to_categorical(y_test_ann, n_classes)\n",
    "    # Training the model\n",
    "    ann_fit = ann_model.fit(X_train_ann, y_train_ann, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_ann, y_test_ann))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    ann_evaluate = ann_model.evaluate(X_test_ann, y_test_ann)\n",
    "    \n",
    "    # Using prediction\n",
    "    ann_pre = ann_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (ann_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ann_output = confusion_matrix(y_test_ann.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    ann_prediction_acc = ann_output[0][0]/(ann_output[0][0]+ann_output[1][0])\n",
    "    \n",
    "    return ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ann_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallow_net_C(n=55,i=len(train_cols),o=2):\n",
    "    # Create simple one dense layer net\n",
    "    # Default 55 neurons, input 5, output 2, here we have more hidden layers with different activation\n",
    "    net = Sequential()\n",
    "    net.add(Dense(n, activation='sigmoid', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='relu', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='tanh', input_shape=(i,)))\n",
    "    net.add(Dense(n, activation='elu', input_shape=(i,)))\n",
    "    net.add(Dense(2, activation='softmax'))\n",
    "    # Compile net\n",
    "    net.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_pre(X_train, y_train, X_test, y_test):\n",
    "    mlp_model = shallow_net_C()\n",
    "    mlp_summary = mlp_model.summary()\n",
    "    # Convert the values\n",
    "    X_train_mlp = np.nan_to_num(X_train)\n",
    "    y_train_mlp = np.nan_to_num(y_train)\n",
    "    X_test_mlp = np.nan_to_num(X_test)\n",
    "    y_test_mlp = np.nan_to_num(y_test)\n",
    "    # Conver the matrix, finally we have two classes (n_classes)\n",
    "    n_classes = 2\n",
    "    y_train_mlp = keras.utils.to_categorical(y_train_mlp, n_classes)\n",
    "    y_test_mlp = keras.utils.to_categorical(y_test_mlp, n_classes)\n",
    "    # Training the model\n",
    "    mlp_fit = mlp_model.fit(X_train_mlp, y_train_mlp, batch_size=128, epochs=99, verbose=1, validation_data=(X_test_mlp, y_test_mlp))\n",
    "    \n",
    "    # Evaluate: loss & accuracy -> Using Evaluation to get the accracy\n",
    "    mlp_evaluate = mlp_model.evaluate(X_test_mlp, y_test_mlp)\n",
    "    \n",
    "    # Using prediction\n",
    "    mlp_pre = mlp_model.predict(X_test)\n",
    "    # Convert value to boolean value\n",
    "    y_pre = (mlp_pre > 0.5)\n",
    "    # Counting the boolean value, counting the accuracy by using basic calculation\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mlp_output = confusion_matrix(y_test_mlp.argmax(axis=1), y_pre.argmax(axis=1))\n",
    "    mlp_prediction_acc = mlp_output[0][0]/(mlp_output[0][0]+mlp_output[1][0])\n",
    "    \n",
    "    return mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlp_prediction_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7. RNN - Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnn_pre(df_train, train_rate=0.75):\n",
    "    # Set the dataset for train and test\n",
    "    df_rnn_train = df_train.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn_test = df_test.loc[:,train_cols + ['is_attributed']]\n",
    "    df_rnn = df_rnn_train.append(df_rnn_test)\n",
    "    \n",
    "    pre_col_index = list(df_rnn_train).index('is_attributed')\n",
    "    dataset = df_rnn.values.astype('float32')\n",
    "    dataset = np.nan_to_num(dataset)\n",
    "    \n",
    "    # Normalize the dataset, set all the data of the dataset to be in the range between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(dataset) * train_rate)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    \n",
    "    # Use this function to prepare the train and test datasets for modeling\n",
    "    look_back = 1\n",
    "    trainY = train[:, pre_col_index]\n",
    "    trainX = np.delete(train, pre_col_index, axis = 1) \n",
    "    testY = test[:, pre_col_index]\n",
    "    testX = np.delete(test, pre_col_index, axis = 1) \n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features], here it changes the dimension from 2D to 3D\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    RNN_model = Sequential()\n",
    "    RNN_model.add(LSTM(5, input_shape=(1, len(trainX[0][0]))))\n",
    "    RNN_model.add(Dense(1))\n",
    "    RNN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    RNN_model.fit(trainX, trainY, epochs=10, batch_size=128, verbose=2)\n",
    "    \n",
    "    # Make predictions, trainPredict should be 1D array\n",
    "    trainPredict = RNN_model.predict(trainX)\n",
    "    testPredict = RNN_model.predict(testX)\n",
    "    \n",
    "    # Change the dimension from 3D to 2D\n",
    "    trainX_2D = trainX.transpose([1,0,2]).reshape(len(trainX),len(trainX[0][0]))\n",
    "    testX_2D = testX.transpose([1,0,2]).reshape(len(testX),len(testX[0][0]))\n",
    "    \n",
    "    # Append prediction back to the model\n",
    "    trainPredict_6cols = np.append(trainX_2D, trainPredict, 1)\n",
    "    testPredict_6cols = np.append(testX_2D, testPredict, 1)\n",
    "\n",
    "    # Invert predictions back to normal values\n",
    "    trainPredict_6cols = scaler.inverse_transform(trainPredict_6cols)\n",
    "    testPredict_6cols = scaler.inverse_transform(testPredict_6cols)\n",
    "    \n",
    "    # Calculating the RMSE\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict_6cols[:, pre_col_index]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict_6cols[:, pre_col_index]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    \n",
    "    final_prediction_train = np.where(trainPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    final_prediction_test = np.where(testPredict_6cols[:, pre_col_index] > 0, 1, 0)\n",
    "    \n",
    "    # Change dimension from 2D to 1D\n",
    "    final_prediction_train = np.reshape(final_prediction_train, (-1, 1))\n",
    "    final_prediction_test = np.reshape(final_prediction_test, (-1, 1))\n",
    "    \n",
    "    # Counting the accuracy by using basic calculation\n",
    "    rnn_acc_train = sklearn.metrics.accuracy_score(np.array(final_prediction_train)[:], \n",
    "                                     np.array(trainY)[:])\n",
    "    rnn_acc_test = sklearn.metrics.accuracy_score(np.array(final_prediction_test)[:], \n",
    "                                     np.array(testY)[:])\n",
    "    return rnn_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rnn_acc = rnn_pre(df_train)\n",
    "# rnn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Data (Call the function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.902%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmAE/X9P/5nkr03y7Ecy7kLLKzI\nVdhoaVWU4ofqV+tHP1qBUvm1n2q19rAerVbrgcoHodbqp7beFS31AI+PR6kXiiI3Btay3At7L3uf\nyR7ZbOb3R3azk2wyM5lMkknyfPwDmcy85/U+ZvLaHO+3QRAEAUREREQUFGO0AyAiIiKKRUyiiIiI\niFRgEkVERESkApMoIiIiIhWYRBERERGpwCSKiIiISIWkSJ/QarVG+pREREREqlksFr/bI55EAYGD\n0YrVag37OSh47Bf9YZ/oE/tFf9gn+hSJfpF684cf5xERERGpwCSKiIiISAUmUUREREQqMIkiIiIi\nUoFJFBEREZEKTKKIiIiIVGASRURERKSCoiTq66+/xqpVq4Zs/+yzz3DNNddg+fLl2Lx5s+bBERER\nEemV7GSbzz//PN577z2kp6d7be/t7cUjjzyCN998E+np6fjBD36AJUuWYPTo0WELloiIiEgvZN+J\nys3NxZNPPjlk+6lTp5Cbm4vhw4cjJSUFFosF+/fvD0uQwejp7cO+EzZsf/lfKH77U7/7fP6XTSjf\ncUCynJKte7DzubfDEaJfzu4ebHnkZbScrkRLezf+tasUfS4BAFC6bT++fPpNReW4XAI+2FWKprYu\nfHmwGqV7i4ENG1THdbq6DTu+rkZ3Szu2rH0JBw+UYk/xGQBA07FSvPY//8A/vzyFr47WwXqsDlt2\nnEZHp0OyzKa2Ljyw5l0c/2AHAGD3C+/gxIc7FcfUfLIc/1r3Mvp6nZ5tdc2d+GhPGQRBAJxO4Kmn\ngNpav8d/8tgrOHPgiOQ52mw92LLjNHqdLhw4Vo/Dp5tw4Hg9ik81+t2//tBJ/P3Op/DRoxshuFyK\n6/Lp46+iet8hyX0e/8Wfcd+9m3CysgW9The27DiNNlsPeu1d2LL2JbRVnFF8PgBAUxN6H38CWx56\nAd1nmryeau3owTNv/xv/3HEaW3acRmd3LwBAEATc98wufL7zJLasfQmdjS3BnVOkoaULv39qB55c\n/SpaSirQ1dSK2+95AyePVSk6vvhUIw4cq/f73LY/v47KXUWKYzn8zjZ8tXELAODAK//Cn3/5Z9Ts\nLwbgfS0BwNY/vYIa62HFZctxdNixZe1L6KiuU3X8qU/3Yuezb+OD3WVoaOnybK9v7sSHu/uvhQC6\nHU5s2XEatq5e7D50Bp99VYHPrZUA4DXGAjn05lYcfO1DVXGfqGjx3EP8KTvTju0HlY0FpcTXStXe\nf+OzJ15TdNyxsmbsOzJ4HxkYE42tXV77/bukAQeP+x+T/pR+/hW2//UNz+Oy7Vb8+sZn0NnQjNbS\namx55GU4uwO3/4AdX1fjdHWb1zb3uHgLu5//P5z8aBcAoGZ/MbY+/qpkWeLxvuv5t/HgTU+ir8eB\nL9/bjdK/vT64oyAAL7wAlJai9uAxfPLYK4rrLbhceHHNq3jtjX3K9hcEfLC7DC++fxi1lQ3YsvYl\n2OuaZI+LJIMgdaX1q6qqwu233+71kd1XX32Ff/zjH3jiiScAAP/7v/+LCRMm4Nprr5UsK9xr531+\nqB2fH2r3PF69cpLX813VDVj/RY/f58RWv+q+iO+/dhyMyeFfHefopu3Y1DcNM1or0DE1H7Utvbhy\n4UgsyM/0xHLvFdlIysqQLOdwRSfe2NGMjFQjOnvcL+bv/+kqHHnlFXSddVbQcQ2c+6LOEnyRMX1w\n+8pJePbZAziTNXbIMQUT07DyosDvSP75/Vo0dzg95QycQ6o/xF58Zh8qhk3AdWnlmH71+QCAdW9W\no9sh4P9bMhrn7vkQU9asgf3ss3Fs40avY5v2H8OTJ81I6uvFvaumBjzHy582oLSuB99dMBwfH/S+\nSfmL809/O4L29GEAgJtzW5BzwVzZerQfLcOfDiYFLBMA7Keq8ejewUv0ksLh+OhAG6aMTUVh7WG8\nbZyOOS2l+P4vFsmeb0D+rbfiS9twPLfkp5jZWo4VPz/f89zfPq5HZeNgEnzOjEx879yROFLZhc1f\nDt68Fnccx+KbLlZ8TrFH366Bvds9NvNbK5GaloQjaeMBKBsDgcaLvewMHt3Vp7gc37IG/j/weOBa\nyjYn4bpJ7fjzsYygypZjfWkb3k+ZgQUtp3DlLy4K+nhxvMMyTLj9Kncb/uGtGnT2uLDqO6ORPz7N\n77GfFLVh55EOzM5Nx+GKwYTg9qvGo7i8Ex8fbMPUnFT86OIxkudW0xZyxw48f9f3JyA9RZuv7Rb9\nfRveSZqBua2ncWjENADAHRYXss7KDSrWo5Vd2PRlE0ZkmnDrleMD7idnYP97Lh2GlOxhnscT2+uQ\n6erBiRG5WGY8jVkrLgxYhrNPwJpN1UPOKx4XA88NbLttrgPD507zW554vDfb3Pfnq5Ir8U7vZADA\nw5eZ0TdiBMwHDuCsG29EX2Ymvn/DS3CakvHL6R0Y/c2zZetd9fFXeKFxHADgpkvHYnx2iuT+FQ09\nePGTBq9t3247iUtu/o7subSm+dp5ZrMZdrvd89hutyMrKyukYLTw+XErgMEkyvdcZwxHAJyUj6N/\n0BVaLDBFIIkqfn0vAKA0azycLe6//s0jc2CxnOWJZc7Zs5CZM0qynGr7KQDNngRqwKzx4wE17d5/\n7kZkem22WCw4k+X/r8XWLqPfth1Y46j51Xe9yhk4h9JxsXqYe3+jMc1zTHd/GeMmTMEUo/vGm3n0\n6JAyvzpSC8AJpylZ8nyPvfMvAEBKRjYA7yTK33HtohvX8PRhiupyvK4TQHPAMgGgzA4Ag2WnZI4C\n0IaGDhe6XSmAEahIHx3cNVVWhvppS93/zRjrdezaze977eoQ0mGxWFDdeQrAYBLVhAzV17Fd1Fal\nwyYgRejzPFZUZoDxUt51AECl8nJ8yxLFZbFYPNdSs82JscOyAXQHV7aM7S+6332tThkxpExF64GJ\n4m3v7PPs39m/fez4XFgsk/0e+tGhfQA6YHN439vOmjkLJxpOA2hDY4crcAxBXrNBHdv//Ow5czEy\ny38SGKzdL7vfkalKHbx/ThozDtMVtrHFYoHVasXI0RMANKHV3ucdf7Dt0b//zPzpGDltsudx9bAc\npDjdf8T0CamS5XX3OIH+JMpfLAPEY3tc9hjMClCmeLx7ziEMtv/8mTOBiROBsjIAgMluh9OUDAAY\nZR6pqO6Nnw1+AjA5bzq+UeA/SR/QW3wGgHcSVWc0e50rZtfOy8/PR3l5OVpbW+FwOPDVV19hwYIF\naosjIiIiiilBv8Xy/vvvo7OzE8uXL8fvfvc7XH/99RAEAddccw1ycnLCESMRERGR7ihKoiZNmuT5\nPtQVV1zh2b5kyRIsWbIkPJERERER6Rgn2yQiIiJSgUkUERERkQpMooiIiIhUYBJFREREpAKTKCIi\nIiIVmESR9uQnwY+l0xAAAwzRDoEiIN4vKXH9BFe813aoRKxzuMVdEqX5rT6IddC0MVgD3yRBwQo9\ngRsgQTIOQeZlwGAIboSoarVItLXoHEGfTdwGCtvDdzetaigE2R9Sgu3beKekj6T2ifotQ8PzazYy\ntB5jEkmN3L0s4qQGhIrBorZ+OmuV+Eui5BgM+qwy7/8a0qQxw98hSl70fXcxSDwXnAC3Ig7EQdo1\ntu5IVie+qhp7lCYkWveT0vJCuhaCOzYWhqI+MwoiIiIinWMSRURERKQCkygiIiIiFZhEEREREanA\nJIqIiIhIBSZRRERERCowiSIiIiJSgUkUaS5Sk6HpbdK1eBYL87VQ6BRN6BvTxJMZx3td/UjEOodZ\n3CVRWs9aHOkLzetsvudWMHt6wOU5EuTikatmsMNDTf9HYsx4nyHISokaQS5ST1V8Gk7QKK0SNJz8\nNtZmLB8IV6u29KVkGEpOQq1dKKpoeX6tWljrISZ1r9DHLVsUhGSsau6TauIJ3/WiVtwlUbKM+uqA\nQXqNKwZpcKeLyOuxkpNITFkeynp2hgAvUdHIQ/Q68sXtG2sJmhypsRNvdY01ga7NIftp3E+K7ych\nnDfYQ2NhLCZeEkVEuqKLP7iJiFRgEkVERESkApMoIiIiIhWYRBERERGpwCSKiIiISAUmUUREREQq\nMIkiIiIiUoFJFBEREZEKTKJIcxGbaVcfU/omhBiY8440EO+XlCAex/FeWT8ScqmbMGMSJUNwRXjZ\nF4klOZRcAAFf7EK9eGLkVVS2lkHWQ02rReI+JT6HEGzXeI0x6YOF/haIid7X7WoE/g1EG3T/KaZk\nIEqt+xLdF1xNX/A1amOtu0py2ReNz6WKOAiNl6jRRf00kHBJlF6nkddpWLEpRpZ9UTIWffcJZakX\nr3IC3MGiMQz1OvTFTa/X+4ZqEtWJs5rGHKXtr3U/KR7iIS37Euy6L6pPFTEJl0QRERERaYFJFBFF\nVby8rU9EiYdJFBEREZEKTKKIiIiIVGASRURERKQCkygiIiIiFZhEEREREanAJIq0F6FJ+virrgiK\nt3mSKCGJJ5dNxNm7E7DKYRd3SVSi3+vDV/34uPribtJENVS0QSy0Wqz1bWxFG9s0a+sYG2OhSqza\nqhN3SZTmopi6+546pCVoQq5HjFxOWveXXtd9EQUmt3SLJJkXhUBViY+UWi/Cc20pGYZS+7CPIyDC\ny4oFyys6ycESuXVf9NZiCZdE6fWvVX1GFaO0WPYlAj1iULDW25BlXwz+/x/0uQPciqJxeeh17HvF\npdP7hlqStYmvqsYcg8KEROshqbi4kJZ9CXJ/1WeKnIRLooiIiIi0IJtEuVwu3H///Vi+fDlWrVqF\n8vJyr+dffPFFXH311bjmmmvwySefhC1QIiIiIj1Jktth69atcDgc2LRpE4qKirBu3To8/fTTAID2\n9nb8/e9/x8cff4yuri5cddVVWLp0adiDJqL4obfvOBARKSX7TpTVasWiRYsAAPPnz0dxcbHnufT0\ndEyYMAFdXV3o6urS7feNiIiIiLQm+06UzWaD2Wz2PDaZTHA6nUhKch86fvx4XH755ejr68NNN90U\nvkiJiIiIdEQ2iTKbzbDb7Z7HLpfLk0Bt374d9fX1+PTTTwEA119/PQoLCzFv3jzJMq1WaygxS2pq\napY8l720Jqg4Dh48CFN6qjbBSbDZbECa97YzZ2pgtQ62fXFxMVLrqyXLqai0+d1+4sQJdGRnq47P\n6XR6PZZqO0dvb8DnfbeLHwc7LtrbO4YcU1pahhk1NZgYoMyaqioAY2TP1+vsBQA0NDQMeU4uzrr6\nekV1aS4tBZApWWZ7SSmA5MGy6+oAAH19LnR2dgJmZTGJzXE4vB6Lj+3rc3k9Z7O527i8wntc9fX1\naXcdi36NFEyZvvu2nyzDwC0t2Nj8jUvxtVRZWQEgW1XZgXT39ACp7kkf/ZUZah3KyspgNQ4dvwDQ\n0tLijqG722v74cOHUV/nvuco6eNQ2kLu2H//+xCGZZhUly/W1dUNZMFrrJWVl8NmzVB0/ECsFaLv\nBGvRZ0eOHkWG3fs1ayBCu90uWZ6zT9l1I36usrICjgD7+nvt6Oy0A/0vf4cOHYKjsRHDS0ow3We/\nmjNnFNW9sbERAzetkydPQrBXSu5fUt01ZJvLz/USzpxCjmwSVVhYiG3btuGyyy5DUVERCgoKPM8N\nHz4caWlpSElJgcFgQFZWFtrb22VParFYQotawpcnDwCnOwOeqz5lGLD7iHwcr1YBABYsWIDkzHTt\nA/VxdPM+wDtPwfjxE2CxzPTEMmfOHAybPE6ynNqu08BXrUO2FxQUAGravf/cA4nzAIvF4nnOV3Jy\nst+2tVqtQ44TP1Y8Lvr3z8rKGjymf9vUqVMwccIE7/JFjCcagNoe2fMlv9cAoAdjxowBSuxez/k9\nTlSnnLFjFdWlpNkBHK+XjKWyxwR8PXjjzsnJAY7ZYDIZkZEx+AIQ1DWVkuL1UHys6a0zgLPP89hs\ndrdxY28ZsG9wXJlMJvXXsc+4EX8NQFGZAcZLlTMZOFiqvBzfsnzGpfhamjw5F+h/kdHq/rUzdScA\nd/19y/RcKwpiF8cs3j5lyhRYLLl+D916eD9Q0YW0tDSgffDFc9asWajsKAeO26T7ONhrNphj+5+f\nN28uRg3X5t67L30XAEAQjbW83FzMVNjGFosFVqsVuXl5wP5WzzZ/+ynSv/+ss8/GqJlTvfpyIMLM\nzEzJ8nqdfcCm6oCxDBCP7cmTJmNugDL9vXZkZGQC/beDuXPnAnl5QNXQ+/6E8eMV1b3li2NA//sA\nM2bMQOHMsZL7u9JrgS+avLYZfa4XRddKiKSSNNkkaunSpdi5cydWrFgBQRCwdu1abNiwAbm5ubj4\n4ouxa9cuLFu2DEajEYWFhTj//PM1DT5YkZjfR9f4vTRJ/N4eVI4R/bdbzPVtjIUby7QaGonWZYHm\nk6NBskmU0WjEQw895LUtPz/f8/9bbrkFt9xyi/aR6YTgcsnvpOX5RFe74DOAQ1rrKUEWTdK6lnqd\nsFyrc6gtJjFGU2SEqy1DnrE8yp0c7fNHgtQ9XQ/194pBMtbgg/V9fVN+nL5SWU62SURERKRC4iVR\nen3LX6PlPAjaNGAk+kBJnBJLw4QUYsC/HDn4PET9E2/XpNRHnwn/lYiYofW6LwrLC2m9qeCOjYWP\n6BMviSIiIiLSAJMoIiIiIhWYRBERERGpwCSKiIiISAUmUUREREQqMIkizUVufhMdTKRCFEfi/4oS\n/dor/is7REhzDZJfTKKIiIiIVIi7JCoGppUIq0Svvxy2D1Q1Qiy0WyzMKSPG+ZgiR6u2jrEhFrIE\nq64qcZdEaS3Sb38KBlGX+J6ay77I0rqaqpYziEBbe63GEMKdXe5Yvv0ffuFbxkJJ30ntE92+T4Sh\nJ7nsiw4+b/SKQOMlatT2b/RbxVvCJVEGiRmgo0n8l5I+I4whGvy5GJkJy+XP4ruP1+NQJg4OcCtK\ntL+0pXg1dZw1jFRt4qyqMSdai/4q7vcQBkg8Dq2ES6KIiIiItMAkioiIiEgFJlFEREREKjCJIiIi\nIlKBSRQRERGRCkyiiIiIiFRgEkVhEJmf6CbCPDJEERXn15QgXvUlAW8giVjncGMSFWficR4OTXES\nHHUzlochDM3pdA64QGIrWnJLrF5LrNqqwySKiIiISAUmUTIEV/Te/hyy6ksosYT6Nm7MvIMT/ber\nI7Fcg7g7w7dsSOBhE85zkjaUXPJS+0T7kx89LHsSbpL3dB1U36sPJJd9iWCwOrv1JFwSpdflG7zC\n0mmMMUOLZV8i0AWqln3x+n8Iyy8EuOdx5A3yaot4uybjrDrxxBCl7FXxkAhl2Zcgj42Fyy7hkigi\nIiIiLTCJIiIiIlKBSRQRERGRCkyiiIiIiFRgEkVERESkQsIlUXqdsdUrLD3GGERMkQo/4Hk0CCAS\ndVAyFn338RomIfwGWgjwqxcdjryo8WoLPV6ToQg4dUV8E0/NodvXAsU/SVMRv9Q0BX62+Y0khHYL\nts112kVe4i6J0noKA0MUZ0H2PbOiWALVP8R2iYWfmrpJBxqJKS5CmXpA8TlEpzAEezMNog0Gdg1n\ns2l1n9Tr9CUB6SBcqSaLteaUolVdtG4TyXu63tpfLwNCZ4lV3CVRRERERJHAJEoGZywPEItu32eN\nflyJMWM5aUX5xzdBlqtknyjOWC57D0mAQab3Gcu96GV6e528ITaASRQRERGRCgmXROn1exNc9kVD\nXPZFvlwdLfui19HOZV8oGrjsiyanipiES6KIiIiItMAkioiIiEgFJlFEREREKjCJIiIiIlKBSRRp\nLlJfi4zEVAJEiUS/U5doL5rT10RLAnVvxDCJIiIiIlIh7pKoWPhJZDiFq/p6alaD4FJ/bKIPEEDl\nRRLGCT01KsdgiK3bGUdi5GjV1uwz8hVbdx0iIiIinUiS28HlcmH16tU4fvw4UlJSsGbNGuTl5Xme\n/+KLL/DXv/4VgiBg9uzZeOCBB+Lrr/0ofojs+/0EIYR3YEJf9sW7T/X62brWcakqLxJto1FFw7lk\nDCkTruGiZIhI7RLuYSwI0m+K6vQWoy2JTtJF/cVBSMYafLRqv3+nt3uW7DtRW7duhcPhwKZNm3DH\nHXdg3bp1nudsNhseffRRPPPMM3jjjTcwceJEtLS0hDVgIiIiIj2QTaKsVisWLVoEAJg/fz6Ki4s9\nzx08eBAFBQVYv349Vq5cidGjRyM7Ozt80WpAr++SicPSZ4QxRJM+Dn8vqFr2xeD//8ELtO5L5Eef\nbse7qC0MRt1GqYrUkkF6vUdSmCnt91DGR7DLvuj37uAh+3GezWaD2Wz2PDaZTHA6nUhKSkJLSwv2\n7t2Ld955BxkZGfjhD3+I+fPnY+rUqZJlWq3W0CMPoKHB+50w33N1VtQFFcfXX3+NpKwMbYKT0N7e\nAaSOBzD4NmdtbS2s1i7PPkcOH0FaS71kOeUVNr/bT548ifaxY1XH53Q6vR5bDwRuu97e3oBt67td\n/DjYcWGz2YYcU1ZWhurqakwMUGZtZSWAbNnz9fY6AACNjY1DnpOLs76+QVFdWk6fApAuWWbHyQqI\n/9apra0FALgEF+x2O5DpToeCabvZPT1ej8XH9vn080Abl5Xbvbb39bk0u47Fb+sHU6bvvraTVarK\n8be/1WpFRfngtVReXg5ghKqyA+nu7gKS/Z9fzXl89y8vL4c1eej4BYDm5iYAQE+391g4cuQI6uo6\nAQAuBX0cSltYD1hhlHhRPXToEKrMsi9RinR2dXmulQEVlRXoVhj/QD3LysuHbPO3n1LHjh9DpaPd\n73OdnZ2S5Tn7lF034ueqqqrQF2Bf8XgXx9B/i8Kh4mI4WlsxrKQEM3z2q62tU1T3hoYGALkAgJKS\nEhi7qiX3L6npHrJNcAmSryORJjtCzWaz+2bdz+VyISnJfdiIESMwd+5cjBkzBgBwzjnn4OjRo7JJ\nlMViCSVmSbtPFwGnBuP1PVdTZimw49/ycbzqviF/4xvfQNrIYdoH6uPEW/uB/vuZwWAABAHjxo2D\nxTLLE8us2bMwctpkyXIaHGXAvtYh22fMmAGoaff+cw/0+QBLoQV4zf8FkJyc7LdtrVare/urgy92\n4seKx8UrFQDcY9NzTH8ZU6ZMwcSSiZ5dfcs8VNoCVNllz5f8z0agqxujR4/2Gk8BjxPVaezYMYrq\nUtruAo7USMZS40oFrKc8j8eNGwccLYHRYERmZiYA9zs5QV1TqaleD8XHmv6vDujt9TweaOOWvgpg\nz+AfKCaTUf11LGorwPudD0VlBhgvtcZMYP9x5eX4luUzLusdZcB+97WUl5cHlLUFV7aMPWm7vM4n\n5rlWpPi0o++1kJeXB4slz/coAMC2o1agvAqpaamAbTBxnjVrFuq6qtxjTKqPg71m/R1baIHR3zt8\n/c/PnTsXOdna/AF74B+7AXi/65k7ORezFbaxxWKB1WrFlLw8YG+LZ5u//RTp33/mWTMxdu6MIX0J\nABkZGZLl9Tr7gE3VAWMZIB7bkyZNwvwAZYrHuziGgcxz7pw5QH4+0P+HnNi4cTmK6t624yTgvn1j\n+vTpsMwaJ7m/IbMe+Nz7DwGD0eB1LkXXSoikkjTZj/MKCwuxfft2AEBRUREKCgo8z82ePRsnTpxA\nc3MznE4nvv76a0yfPl2DkImIiIj0TfadqKVLl2Lnzp1YsWIFBEHA2rVrsWHDBuTm5uLiiy/GHXfc\ngRtuuAEAcOmll3olWZSgIjdlORGRYoL440O9/sQ4jBJpRvpIkU2ijEYjHnroIa9t+fn5nv9ffvnl\nuPzyy7WPjIiIiEjHONlmnAnXD2v09BsJQyh/TfGXR6raICaaLcZ+QRdb0cY4jRo7Jq4DiigmUURE\nREQqMIkiIiIiUoFJlAzBFcJSK1pzhfAxVsjLvkg/1gvtl32J3HIGQZ1D/P8QPmOQOzZQXfTa/7Ep\nXJ8RhbbuS7iHsVzxifAlaKk66qP6oiA0jlVt9XTRLCKJl0Tp9nsTotmR9RpirNCgASPSB0pOEqbx\nGuh7ZRx6g8RtEW+zeEtVJ75qGnsMUUoTFPd7CNdC0IfGwGBMvCSKiIiISANMooiIiIhUYBJFRERE\npAKTKCIiIiIVtFkim0hEiNAXI/X2Kw2iWKePX4SFjyD6pnIi/PrPVyTqvHfvXtx6662edXR7enpw\nxRVXYNWqVUGV88c//hGmjNHobuuCve4wRhUs9bvf/v37MWnSJBiNRvz1r3/F6tWrQ61CUOIuiYq3\nX9EEL0y/5gpLqZGX8MMDiNsZy2Pu2o+xcGOZQbPGZqcp8a1vfQuPP/44AMDhcODSSy/FlVdeqaqs\ntOETkDZ8QsDnP/zwQyxduhT5+fkRT6CAOEyiiIiIEt1/f/ESzj+5E3jr13ihpRMAMOLvBuCedL/7\nX9TjxIJOh9e2dPThGpjcDzalAD/4AfCd7wQVh81mg9FoxI9//GOkdgNVbT2YcO5P8Pxf1uN/2+rh\ncrlw6623YuHChfjoo4/w9NNPIzs7G729vSj89sXobDyFtoo9GF/4Q7RV7MOZ01/iqqu2YMmSJZg3\nbx7Ky8tx11134dFHH8Vdd92FzZs3Y+fOnXjiiSeQmpqKESNGYO3atTh69Cief/55JCcno6qqCpdd\ndhluvvnm4BvWB5MoIiIi0syePXuwatUqGAwGJCcn47777sMLL7yABbnTYDMVorVsN86aMRzPP/U4\nWlpacN111+Gdd97BunXr8Pbbb2PEiBG48cYbvcp09tjQXLIN37Zch+eevxmPPfYYzj33XOTl5WH9\n+vVITk4G4P7I8r777sNrr72GnJwcvPzyy3j66aexePFi1NTU4L333oPD4cCiRYuYRBEREdFQGy76\nMTZc9GO8/9iVuOGOdwEAD1pSULjy//nd/4vdZfjrm197bft/hjP4QBgPAHj/5tnA9OnAv/4le27x\nx3kDXnjhBeSMGAV0AD0dtfjaWuv5npTT6URDQwOGDx+OkSNHAgAWLFiAHtHxvZ1NSMkaB5MpGQaD\nAb/5zW/8nrulpQVmsxk5OTkRkfSbAAAgAElEQVQAgHPPPRd/+tOfsHjxYhQUFCApKQlJSUlIS0uT\nrYcS/HWejGh++dD31CHFovGyL/r9Bmr044pE04jPEc7TBSpb4HdDNCOEqSmVjEPJH4GEfd2X6F+r\n0ab7L7d7rS8V+lgx9n9vMcU8Bt++4GJs3LgRzz//PC699FKMHj0a7e3taG5uBgAcOnTI69jkjFHo\ntTfA5eoDANxyyy2oq6uDwWDwaseRI0fCZrOhvr4eALBv3z5MmTIFQHi+N5lw70Tp9cun3mEZoIdk\nIGZpseyLBmHInkPBki6+41X8OJQYAx2r08sjKsRtodf7hmpSy77EWVVjjSFKt37F/R7Ssi/uY4fn\nfgs11Z/juuuug81mw8qVK5GSkoL7778f119/PYYPH46kJO/0JCnVjJH5i3Hw4OtYvnwbvvOd7yAn\nJwcFBQW488478fDDD3vOsWbNGvzqV7+CwWDA8OHD8cgjj+DkyZOq45aScEkUERERhcfChQuxcOHC\nIds3btyIz5/cBLQBRlMSfvbr3+Obs8d57bN48WIsXrzY8/jg8Xp8dmo3MkbnAwCGTz4Hs0bm4Zln\nb/Dss2zZMlgsFgDA5s2bAQDnnXcezjvvPMm4du7cGVpF+/HjPCIiIiIVmEQRERERqcAkiohk6f37\nr0SkPV728phEEVHQDLy9aiZcXyTmF8QpYhJ4sDGJIiIiIlKBSRQRERGRCkyiiIiISBO33HILnn32\nWc9jm82GSy65BMeOHfO7/6ZNm9Db2xvUOWpqavDZZ5+FFKdWmETJieqM5YLk4yALCzEa78+89fqN\nGK27S1V5ERkzguh/6r+PIMh9lyFAVThjuXaiOmO51CTU2oUSlfJjgitwK0jOJh8hXhEonLF89erV\neP3111FSUgIA+MMf/oDly5dj5syZPoe4j3n22WfhcrmCimnPnj04cOCA4mPCiZNtEhERxanr13zs\n+f/jhxxIET0W6+pxDtn2BcYMlvNKCc4/pxc/kckasrOzcd999+Hee+/FbbfdhqqqKjz44IN+933j\njTfQ0NCA2267DU899RQee+wxfPXVV3C5XPjxj3+McdMsaC3bhfYqKwAD0kZMxvi8b+G5555Dd3c3\nFixYgBEjRsg3Qhgl3DtRel2+QRyVTkOMHVo0YAQ6QckpDAajz+Pgjg8s0F+VHHyDDH7/Gw/irDpx\nJvrvQElScONZsmQJpk6dirvvvhuPPPLI4Ouuz6HXXnstxowZg8cffxxffPEFqqqq8Nprr+Hvf/87\nnnnmGXTaO9BW+RXGzrkKuRf8EinmsRAE4MYbb8T3vvc9XHzxxWGoYHD4ThQREVGc+tu938UVd7wL\nALhtbgoKV37X734f7SnHX94o8tp2ERrwEca7y/nhdKCgAPiwUtF5r7rqKnR3dyMnJ0fR/idOnMDh\nw4exatUqAIDT6URDfS3GfWMZWk5/gd7OZqSNzIPekkwmUURERBQVBoMBLpcL06ZNw8KFC/Hwww/D\n5XLhqaeeQs64iWir+BvGzr0aRlMyqva+gPascTAac4L6HlU4JdzHeRR+kfouPmfRJtJWSD9eiTEJ\nVNVBOqz0OeecgxtvvBFLlixBRkYGVq5ciauvvhoAkJ6RgdRh41C562lU7n4WphQzsrLGo6CgAJ9+\n+im2bNkS5ej5ThQRERFpbOHChVi4cKHsfuvXr/f8/+677/Z6ruhEPYbnLsTw3MFyTLYGzJo1Cx99\n9BEAwGq1ahSxOnGXRCX6FybD9n3ocK1NoYIhhL+m9PrDgohS0Qax0Gyx1rexFW1s02poxNgQ041N\nmzbhn//8J1qr61HZ5f4AbG3pK1h9391YsGBBlKMLTdwlUURERKQfy5cvx/Lly/H5XzbhsdI0AMA9\n//1NLJgzPsqRhY7fiSIiIiJSgUkUERERkQpMomQIEtPyR1wosWi97IuOmkVM67DULL0QiV84eZ0i\nhC9qCAbpW0Cg+uu0+2NSuJbQUdJHUvuEexjLla/Xe4yWBCHwz/R1V3+JgNTc89RWT2/NwiSKiIiI\nSIXES6KMOv15hejdBJ1GGDs0+AlNRH6Fo+QkEuPVEMJICfQLR/76aJD3Ejvx1TBS9Ym3usaaaLW+\n4m4PYXwEe88K5R4XKYmXRBERERFpgEkUaS5yn+Xr7dNxotgW71eUIH4XRXdfOgq/BKxy2DGJIiIi\nIlJBNolyuVy4//77sXz5cqxatQrl5eV+97nhhhvw2muvhSXIoOj/I9SwSoTqh1RHft9DZRvEQLvF\nWN/GWLgE9hkNJZtEbd26FQ6HA5s2bcIdd9yBdevWDdnniSeeQHt7e1gCJCIiItIj2STKarVi0aJF\nAID58+ejuLjY6/kPP/wQBoPBsw8RERFRIpBNomw2G8xms+exyWSC0+kEAJw4cQL//Oc/8etf/zp8\nERIRERHpkOwCxGazGXa73fPY5XIhKcl92DvvvIO6ujr86Ec/QnV1NZKTkzFx4kRceOGFkmVardYQ\nww6soaFF8lzdNY1BxfHvQ4eQUpWlTXAS2tvbgeQcAICrfxbb2tpaWK3dnn2OHD2KDHuzZDll5Xa/\n20tKStAWQrs7e3uB1MHHBw4cCLxvnzNg2/puFz9WPi7cPzGx2exDjikvL0dVVRUmBSizvrICwAjZ\n8zl6HACApqamIc/JxdnQ2KioLm0lpwGkSJZpK6nyelxbWwvAPUOwzW4DMpTFJDaru9vrsfjYgT+Q\nBtjt7jYuK/MeVy6XS7vrWDRrczBl+u5rLzujqhx/+1utVpSLrqWy8nIAWarKDqSrs8tdpCD4LTPU\nOlSUl8OaMnT8AkBTk/s+4ujp8dp+9OhR1NZ2AXDPpi0XQyhtceDAASSZAn/JqLi4GDVZsi9RinR2\ndnqulQEVlZVwKIx/oJ6lpWVDtvnbT6njJ06iRujy3tj/E7qurm7J8px9gz+1k9pP/Fx1dTUQYN9y\nP68dXZ1dnnYrLi5Gj82GYSdPYobPfnV19YrqXl9fD2AyAODUqVNI7qmR3P90bfeQbYKf6yWcOYUc\n2RFaWFiIbdu24bLLLkNRUREKCgo8z915552e/z/55JMYPXq0bAIFABaLRWW48vaWfQ2cHBwMvudq\nGVkJfH5APo5X3S9ec+fMgXncaO0D9VHyf1ag/1oyGowAXMjJGQeLZbYnlrNnzsTos6dJltPsLAf2\ntgzZPj0/H1DT7v3nTkpO9tpcWLgA2FTt95AkU5LftrVare7trw4mBuLHisfFxjIAgNmcOXhMfxm5\nuXmYVD7Js6tvmYcr24GydtnzpXzwMdDZhezsUcDpTq/n/B4nqtPo0aMV1aW8ywAcqpSMpTbJDOw7\n5nk8btw44HAHYDDAnGkGBHdKGdQ1lZbm9VB8bNK79UB/AgkAGRnuNm4TKoHdg+PKaDSqv45f9U4M\nxZM7KiozwHipTy0Bdh1WXo5vWT7jskl0LU3JywNKmoMrW8b+jF0A3D+79y3Tc60oiF0cs3h7bm4u\nLJapfg/dfuIAUNqJlJQUwD74In722Wej2VEDHOmAwU9cvudW1Rb9xxYWLkByking87PnzMaE0eah\nz6tQ9OqeIdtyJ0/GXIVtXFhYiAMHDmDq1CnAHveY8Kp7sO3Rv3/BjOmYILrHA/B8ez0tPU2yvF5n\nn+ce7C+WAeKxPXHixIBlNvl57UhLT/f8f87s2cDMmUBjo++hGDt2rKK623afAkrd/582LR+WueMl\n90860QB85n0+g8H73qPoWgmRVJImm0QtXboUO3fuxIoVKyAIAtauXYsNGzYgNzcXF198saaBRoJB\nZq2waPH6e4w/AQmNFjOWaxCG7DkUxOm7j9djA1RP7BPozNEYenod7eK4EmkW7wSqqi4ZojRbl+Ju\nD2XG8mCPjYGxKJtEGY1GPPTQQ17b8vPzh+z3q1/9SruoiChhcP4/IopV+nxbhoiIiEjnmERRGETm\nvQUuYUCksTi/psTVExLwBpKIdQ63uEuiYuAj1LBKjO8zqL8RGIwJ0UDSVAySWBhXsda3sbBCfbzQ\nrqXZZ+Qt7pIoIiIiokhgEkVERESkApMoIiIiIhWYRBERERGpwCRKjsslv0+Y+H59OqRfVmj8qwz9\n/shDB4FFonFE5xDC+K3vQDXRQSvHkfD0n5I+kton3MNYtnwdDbKwtYVLomAd1N8rBKlGUNVA6ioo\n6Oy7/UyiiIiIiFRIuCRKrz+D9lrNQ58hxg4tGjACnaBq2ZcA/w/63AH+cozGz+71OtwNhkAPYl+c\nVSeuGKL0DpTiMRHSsi/h3T8aEi6JIiIiItJCwiVRgtRn0FEkfmNAv983UiZS8Qc8jRYBRKASSr7j\n5ruPEOD/QZ87wJ94QhS+iKHX4e7V9LF+UfoIVJ1o9H8kCaL3PfU6e7fS7/yo+xpS4IMUlxdCuwV7\nqE67yEvCJVFEpC+Cbj/QIyKSFndJlJLvmcQK35ooq1uAfUJsFz21aqDv8/Q/K31sJMZHhM8h3R7S\nx8ru6vOvnsXTtR8pUi0WT82pVV00bxOp7+jqoP29QtC88urKi9Z3xgKJuySKiIiIKBKYRBERERGp\nwCSKiIiISAUmUUREREQqMImSEc2fwepp2ZchsYRUWjjpILKEWPZFB996jRPhWsZCyTCM6rIvIT4f\nSWGLJU6WfVE3VrjsCxEREVHCSrgkisu+JAAu+yJfrq6WfdHBn9x+cNkXigYu+6LJqSIm4ZIoCr+I\n3QP0+dpLFLNiYYbokIhfleO+skPpdZb2WMYkioiIiIZi0iUr7pKoGHj3L6zC9fannt5WDeljLD1V\nJFrUtEFYv7yuTdmx1rcxFm5M0+pjanYZ+Yq7JIqIiIgoEphEEREREanAJIqIiIhIBSZRRERERCow\niSIiIiJSgUmUDEFqWv5wn9vn56UhxaL1si86/emr1mGpqWdEVn3xehTG3wzptJ/jSdiW0FHQd1K7\nhLvn5a4tXd1jwhSLVB31UHvly75E7j6ptyWnEi+J0uvvikVx6TTC2KFBH0ekD5TMnu9bF81mtg9w\nB4vC4NPrjOXixoi16RPkSP3kP97qGnuidT0o7PdQxkeQx0ZjBYVgJV4SRURERKQBJlGkvQi9DS/o\n9h0MItIj8R1DT58WRkqwdU7AJgpa/CVR+n/3L6zCNmN5eIpVJ5S7n64qEiUqBklMNJtOFxcPJLai\njXFaNTY/6iQf8ZdEEVFM0dsXRYmIlGISRURERKQCkygiIiIiFZhEEREREanAJIqIiIhIBSZRRERE\nRCowiZIRN0sPhLzsi8F3gy5pHZaa8iIxZsSnCOfZApWt0+4nEUV9JLnuS5h7WaZ4Xd16w1Wu3pd9\nUTixlpo5+9TWTw/tIsYkSifEKQqnIgmRFsu+RKAPlCyvYfCZ+8h7GQT1QRr0s+qLbpd9EXePbz/E\nOqmhF181jT3Ran/F97wQbo5BHxoDgzFJbgeXy4XVq1fj+PHjSElJwZo1a5CXl+d5/qWXXsKWLVsA\nABdddBF++ctfhi9aigmReknU01+qRPFAV++8h4EgehWP97r6lYh1DjPZd6K2bt0Kh8OBTZs24Y47\n7sC6des8z1VWVuK9997D66+/js2bN2PHjh04duxYWAOWw8Uzw1N/PbVqKO9ccHxA3YzlMdBsMde3\nMRZuLNNswnKNyqH4IftOlNVqxaJFiwAA8+fPR3Fxsee5cePG4YUXXoDJZAIAOJ1OpKamhilUIiIi\nIv2QTaJsNhvMZrPnsclkgtPpRFJSEpKTk5GdnQ1BEPCHP/wBs2bNwtSpU2VParVaQ4taQn1dq+S5\nuutbgoqj+PBhpDXUaBOchLa2NiBpLACgr88FAKirq4PV2uPZ59jxY6h0tEuWU1Zm97v91KlTaA2h\n3Xt7e4GUwccHiw4G3Levry9g2/puFz8OdlzYOzuHHFNRXo7KykpMDlBmY3k5gCzZ8/X0uNu9ual5\nyHNycTY1NSmqS/vJMgxcgoH2t5ed8Xp85szgWLTZbEC6spjEzu7q8hzne2xvb6/Xvp12dxufLuv0\n2u5yCZpdx+KPVYIp03ffruoGVeX4299qtXpdS6WlpQAyVZUdSKe9EzC7P/72V2aodaioqITV2uJ3\n38ZG97h2+PT3sWPHcOZMN4DAcYUSo9jBooNISQr8Ycjhw4dRX5Wsunwxm93uNeYBoKqqCi6F8R84\ncAAmo6F/HLhp0WcnT55EXZJ3HwxcD91dXZLl9fYpu27Ez9WcORNwX3+vHd3d3QPDHocPH0Z3dzey\nTpxAgc9+9fUNiupeV1cPYCIA4PSpU0jrPSO5f1ldz9CNwtB7TzhzCjmySZTZbIbdPti4LpcLSUmD\nh/X09OCee+5BZmYmHnjgAUUntVgsKkJVxlp5CDhhC3iutoozwNZ98nG8WgUAmDN7Nobnjtc+UB+l\n7x4A+pvZZDICzj7k5OTAYpnjiWXmWTMxdu4MyXLahEpg99AbZ35+PqCm3fvPnZzsfTNbMH8BsNl/\ncmkymfy2rdVqdW/vLxOA12PF4+LlEgBAZkbG4DH9ZeTm5WHymcmeXX3LPF7XCZQ0y54v9aNPAFsn\nskdlAz4JhN/jRHUaNWqUorpUOZOBg6WSsTSknwJ2Db77O378BKD4OAD3tYk+iZgCSfd+NREfm/x+\nA9A9eOPKyHS3sd1YBewaTCiNRoP661jUVoD3x3CKygwwXpqHlQNfFCkvx7csn3HZ6qoA9rivpalT\npwLH64MrW8aBzN0A3B8R+ZbpuVYUxC6OWbw9N3cyLJZpfg/dWXIQOF2BlORkeAYRgJkzZ6LDVQcc\n7vAbl++5VbVF/7EL5i9AWqqfl6D+52fPno3JOVnBl+9H8et7AZf3tkmTJmGBwjYuLCzE10UH3eNg\nl5/7R7Dt0b//jBkzMMkyz6svB66HtPR0yfIcvX3ApuqAsQwQj+0J48cHLFM83gekpaV5/j979mxg\n9mygtdX3UIwdO0ZR3bv2lwL97wNMy8+HZd4Eyf1TTjUCnzZ4bzR433sUXSshkkrSZL8TVVhYiO3b\ntwMAioqKUFAwmIMKgoCf//znOOuss/DQQw95PtYjIiIiiney70QtXboUO3fuxIoVKyAIAtauXYsN\nGzYgNzcXLpcL+/btg8PhwJdffgkAuP3227FgwYKwB05EREQUTbJJlNFoxEMPPeS1LT8/3/P/Q4cO\naR8VERERkc5xsk05UZxXw/fUIc1rEvKM5dKPdUPr/lJRXKSHjBDGn/YHqsuQGexJtXD1n5JxKLVL\nuIexbu8hfoTrmpa8p+uggbxC0DpWHdRPC0yiiIiIiFRgEqUT3hMFxvZf+ZF6JybgabRY9iUCfaBo\n2ReffbyWIgkhxEATlkZjvkq9jnbvS1KvUWpLAPTbIZrQ/4zlhjDGJVXnyCz7EtyxsTAUmUQRERHR\nEDrNM3Ul7pKoWMhcwylcfzBrWWyoMYZyeMwtDRIOapZ9iYErK9b6NhbaNF5oNTRibIhRBMRdEkVE\nREQUCUyiiIiIiFRgEkVERESkApMoIooqfneViGIVkygiIiIiFZhEEREREanAJEqG4Irisi8+H3To\natkXnU4gonVU6qqpz7ZRJY6qIkVwuaJ37jBNdeB7//C7j9RKHmHue7l7iL7uMWGKReL1RU+1ByA5\nINT0lZLx6f84fc0zwSSKwkB3lz8RKRHnl67iteDiVAJWOeyYROmEVst5ELRpwAj0gaplXwL8P2gB\n76aRH3z6He6DkcXaRJ5ypOrDSUAT1dB+93uXCGm9qSCXfYmB6y7+kij9t3lYhav6Wo7lUIsKaW2p\nGLgow05NG8RCsxljIchBHIqRpE1jM8EkX/GXRBERERFFAJMoIiIiIhWYRBERERGpwCSKiIiISAUm\nUUREREQqMIkioqji1DVEFKuYRBERERGpwCRKhiBEbzmIIX+ih7IEjcbLvuiV1jPyqlmaINKzAgth\nnHAoUP1jZTwoFc3lncJGUZX0W289RRaua1pquRS1y6JoySs8yWVfQiw7mON0NlUXkygd0tkYCcgQ\nIMGMVBIReNLt0FswIn2gZHJI3328prZXf+pAh0ZjAki9jnfvVQT0GqU6gaojCPE9Caj4Dw69LoFi\nCGPyJJW0+e93P/uHMEDicWzFXRKV8DPKhmmUalpqFK+keHsxVEVFG7DZKJZpNn55HZCPuEuiiIiI\niCKBSRQRERGRCkyiiIiIiFRgEkVERESkApMoIiIiIhWYRBERERGpwCSKiKJKp9P1EBHJYhIlJ4oz\nGfueOaTZ00Oesdx7ghS9TlQXhinLVYQQ2cYRDOG7jANVxXc8xLpI95nXucM0CZeSGkXzOpY9t47u\nMeEKRXLc6aD+XiFIxqrmRhn8IW76uvcwiSLNRera18OyCETxJJGuqWgmzlGTiHUOMyZROmHwXmMi\neoEEwaDXC1KLZV8i0AVKZk/33cd71ZcQll8I0HfRGHl6He3iuBJppvvEqak+Rav9/Z3X720ilGVf\ngqxdLFx2cZdExUKjh1O4qq9luaGWFcraUgYl69XFOzXLvvClVXNs0cjRbNUXdhr5iLskioiIiCgS\nmEQRERERqcAkioiIiEgFJlFEREREKjCJIiIiIlJBNolyuVy4//77sXz5cqxatQrl5eVez2/evBlX\nX301li1bhm3btoUtUCIiIiI9SZLbYevWrXA4HNi0aROKioqwbt06PP300wCAhoYGbNy4EW+99RZ6\nenqwcuVKnH/++UhJSQl74ERERETRZBBkpm195JFHMG/ePFx++eUAgEWLFuHLL78EAHz66af44osv\n8NBDDwEAfvGLX+Cmm27CvHnzApZntVphsVi0in+Iv7y6Hx9ZazyPfzqy2ev57u5ebOzK8fuc2PMt\n2QCA69JqkZ4e/qRwZ0UnjmRN8to2PqkX38vq8MRyrakGI4alSZZzqDsNe7oyvLb9dNvzwDfmA/n5\nQcc1cG6Tqw99RpNn+49GtODl1pEBj/PXti2tLRg5YqSnzIH9Bh5L9Ye/mCbYGnD5ZJPXtnlpXVh4\nci9QctK989XXeB1b22TH+8bJsucbKC/L2IcOl8nrOX/Hies0v6MC5+aaZevR2t6NN/omSMbS2eXA\nK93jPI+np/SgxJEKAJjWcQans8bL1mWIt9/C9pkX4vj4s4YcK67HgJ+ObEZxTyp2d2YO2a6Gv3ME\nU2ag8dLV5cA/+tsq2LF0w4gmvNA6yiuOf3enYW//tXSlUIV3DZOCKlvOh5W9qDT7vxcNXCtKYhfH\nLN4+O7Ub52V0+j32nfZhaOgb+jf0peYOnHSk4FT/GAtU12CvWX/H/mhEC1IMQ19+Bp6/algbxpj6\ngi7fn60VPSjtv1YGLO4ux4zxWYpi/e8RLehoa0ZN+jjs6r8O/F03wY67/0IVRo/M8HtNZHe24pqJ\ngZf66gPwop/z+hsXA9su6CzH2RP911k83gdk9djQkeq+l/1UKAGys4EzNcDu3e5zfeenAIBzbRWY\nP1n+nne0ugM7MvIAAN9O78SctG7J/at6k/GBbWi8A/U1mYwYMWcczr/iEtlzh0Iqb5FNon7/+9/j\nu9/9Li666CIAwOLFi7F161YkJSXh3XffxYkTJ/Db3/4WAHDnnXfiqquuwnnnnScZTDh98vYh7OyW\nvvkQERFR7PtPxwkU/nhJ2M8TKImS/TjPbDbDbrd7HrtcLiQlJfl9zm63IytLOrOXCkYL35g9ByMe\nfR3jjQKMEDBq7PAh+9RUNmHYsHSYh2f4KcGts6MLLa2dmDh5VMB9tFZ6qh6TJmXDmJKMcjswNVOA\nwQB02rrR3GTDpLzRisoptxswPg1ocgBmwYGsxlogd7KqmDqdBrT0AhPSBJw+VYfRk8agUzBhfLqA\nvt4+lFY0wZiTgxEp7rWa23uBvAzAZByam9fW1mHcuBz0uQz4qsqOszL7MGJUFurPtCI1JQnDR8n/\nJQMAfb19KC9vxLTpOZ5tvS4DqruAKZn95y0rByZOBJKHDvHK8kaMGZ2FtMzUgOdwCUCp3YBpmQKa\nHe5pig0G9zIIo1KH1q23x4nS8kakJBkxZdpYRfUAgOqKRozMNiPDHPgdxsNHatCVlokZk0dgeLKA\n0zYDcjOAJKO7T3Inj0ZSiing8UMr5wLKylEqZCA1tQ8TJk3wPNUnGHCsHchKBnpd7jE4MMn7vmYD\npmYIaK+qw9SpY2A0qftditNlwP4WILO1CWdPGoakZBO+LGnHOVOHISNZfkrotl4DevqAsWlD+6G6\nsgkjhmcgc1i6oljaW+zo6nIgZ8JINNW3obrBhhl5o5De3x8D11KKSUBleSNGjzJ7ntPC6ZI65OWN\nhinZu/8GrhUpnR1daGmxwzlqDMalAakmd3v0ugyo6nL3XSBC//jOywSaetzrXTpcwOQM9zHiMeZP\nW5MNPQ4nxo4fEURt3WxOAzp6gfHp/svu6jOgsWcwFq0MXCt9fX2oq2tD7pQxssd09BpgdwLj0gVP\nn4jHxIBWhwEOl/8x6U+XrRtNonu6o6cXOw7VYfGCCRAEoKysAdPyc2RnSK/tNiDDBAxLHjzvwLhI\nTjIhNS0Zw7PN6OlyoLa2DXlTpes8ULfO1nYcqWjDt+dPQm2bA+b2ZmTlDr4jjsoqYMwYOAxGnKlp\nQd5U5fe8ktJGuIaPQEG2bPrhPlWnuw/yMwVUltYhb8oYmJLc9x6TyQRh6sKw5hSA9Js/srUoLCzE\ntm3bcNlll6GoqAgFBQWe5+bNm4cnnngCPT09cDgcOHXqlNfz0ZCUlopzL5sT9kYNB/H7d4s0KkdL\n5/vZFkyc4rdEQ6mfFscrcUGQ+18UliiG9ud5Es8FW66/t6kDta2W4+pCn8f+xpYehOtakis/3F97\nAKTbPNz1joZQ6zTQJ+Fqm8Wi/0fi/uaPuG6XReAcWgj3p1tyZJOopUuXYufOnVixYgUEQcDatWux\nYcMG5Obm4uKLL8aqVauwcuVKCIKA2267Dampgf+6JyIiIooXskmU0Wj0fHF8QL7oC8rLli3DsmXL\ntI+MiIiISMc42SYREYSJFHkAAAWdSURBVBGRCkyiiIiIiFRgEkVERESkApMoIiIiIhWYRBERERGp\nwCSKiIiISAUmUUREREQqMIkiIiIiUkF2AWKtRXuKdiIiIqJgBFqGKeJJFBEREVE84Md5RERERCow\niSIiIiJSgUkUERERkQpMooiIiIhUYBJFREREpEJStAPQksvlwurVq3H8+HGkpKRgzZo1yMvLi3ZY\ncevrr7/GH//4R2zcuBHl5eX43e9+B4PBgBkzZuCBBx6A0WjEX/7yF3z++edISkrCPffcg3nz5gW1\nLynX29uLe+65B9XV1XA4HLj55psxffp09ksU9fX14d5770VpaSkMBgMefPBBpKamsk90oqmpCVdf\nfTVefPFFJCUlsV+i7L/+679gNpsBAJMmTcLy5cvxP//zPzCZTLjgggvwy1/+MuDrfFFRkeJ9NSXE\nkY8++ki46667BEEQhIMHDwo/+9nPohxR/HruueeE733ve8K1114rCIIg3HTTTcKePXsEQRCE++67\nT/j444+F4uJiYdWqVYLL5RKqq6uFq6++Ouh9Sbk333xTWLNmjSAIgtDS0iJcdNFF7Jco++STT4Tf\n/e53giAIwp49e4Sf/exn7BOdcDgcws9//nPhu9/9rlBSUsJ+ibLu7m7hyiuv9Nr2n//5n0J5ebng\ncrmEG264QTh8+HDA1/lg9tVSXL0TZbVasWjRIgDA/PnzUVxcHOWI4ldubi6efPJJ3HnnnQCAw4cP\n45vf/CYA4MILL8TOnTsxdepUXHDBBTAYDJgwYQL6+vrQ3Nwc1L7Z2dlRq2OsufTSS3HJJZcAAARB\ngMlkYr9E2X/8x39g8eLFAICamhoMGzYMu3btYp/owPr167FixQo899xzAHgPi7Zjx46hq6sLP/nJ\nT+B0OvGrX/0KDocDubm5AIALLrgAu3btQkNDw5DXeZvNpnhfrcXVd6JsNpvnrUAAMJlMcDqdUYwo\nfl1yySVIShrMwQVBgMFgAABkZmaio6NjSH8MbA9mX1IuMzMTZrMZNpsNt9xyC2699Vb2iw4kJSXh\nrrvuwsMPP4wrrriCfaIDb7/9NrKzsz0vsADvYdGWlpaG66+/Hn/729/w4IMP4u6770Z6errn+UDt\nbDKZArZ9JHKCuHonymw2w263ex67XC6vF3oKH6NxMB+32+0YNmzYkP6w2+3IysoKal8KzpkzZ/CL\nX/wCK1euxBVXXIFHH33U8xz7JXrWr1+P3/zmN1i2bBl6eno829kn0fHWW2/BYDBg9+7dOHr0KO66\n6y40Nzd7nme/RN7UqVORl5cHg8GAqVOnIisrC62trZ7nB9q5u7t7yOu8v7YPtK/WOUFcvRNVWFiI\n7du3AwCKiopQUFAQ5YgSx6xZs7B3714AwPbt23HOOeegsLAQO3bsgMvlQk1NDVwuF7Kzs4Pal5Rr\nbGzET37yE/z2t7/F97//fQDsl2h755138OyzzwIA0tPTYTAYMGfOHPZJlL3yyiv4xz/+gY0bN+Ls\ns8/G+vXrceGFF7JfoujNN9/EunXrAAB1dXXo6upCRkYGKioqIAgCduzY4Wln39d5s9mM5ORkRftq\nLa7Wzhv4Jv6JEycgCALWrl2L/Pz8aIcVt6qqqnD77bdj8+bNKC0txX333Yfe3l5MmzYNa9asgclk\nwpNPPont27fD5XLh7rvvxjnnnBPUvqTcmjVr8MEHH2DatGmebb///e+xZs0a9kuUdHZ24u6770Zj\nYyOcTid++tOfIj8/n9eKjqxatQqrV6+G0Whkv0SRw+HA3XffjZqaGhgMBvzmN7+B0WjE2rVr0dfX\nhwsuuAC33XZbwNf5oqIixftqKa6SKCIiIqJIiauP84iIiIgihUkUERERkQpMooiIiIhUYBJFRERE\npAKTKCIiIiIVmEQRERERqcAkioiIiEgFJlFEREREKvz/l2pZnZruUHQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_fit, RF_pre, RF_acc, rf_model = randomForest_pre(X_train, y_train, X_test, y_test)\n",
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy: 99.634%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAEuCAYAAACu4EdXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAAAAAcoUQAAAA5QogAAABz4G/bZMGTq1KhaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GB_fit, GB_predict, GB_acc, gb_model = gradientBoosting_pre(X_train, y_train, X_test, y_test)\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "LG_fit, LG_predict, LG_acc, lg_model = logisticRegression_pre(X_train, y_train, X_test, y_test)\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "svm_fit, svm_predict, svm_acc, svm_model = svm_pre(X_train, y_train, X_test, y_test)\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 55)                2970      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 3,082\n",
      "Trainable params: 3,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0020 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0019 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 3s 17us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 3s 16us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 2s 12us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 2s 11us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 3s 13us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 3s 15us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 3s 14us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 16us/step\n"
     ]
    }
   ],
   "source": [
    "ann_summary, ann_fit, ann_evaluate, ann_prediction_acc, ann_model = ann_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. MLP - Multi-layered Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 55)                2970      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 12,322\n",
      "Trainable params: 12,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0057 - acc: 0.9941 - val_loss: 0.0019 - val_acc: 0.9982\n",
      "Epoch 2/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 3/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 4/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0018 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 5/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0018 - val_acc: 0.9982\n",
      "Epoch 6/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 7/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 8/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 9/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 10/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 11/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 12/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 13/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 14/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 15/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 16/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 17/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 18/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 19/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 20/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 21/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 22/99\n",
      "200000/200000 [==============================] - 4s 18us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 23/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 24/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 25/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 26/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 27/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 28/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 29/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 30/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 31/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 32/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 33/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 34/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 35/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 36/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 37/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 38/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 39/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 40/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 41/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 42/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 43/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 44/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 45/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 46/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 47/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 48/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 49/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 50/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 51/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 52/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 53/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 54/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 55/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 56/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 57/99\n",
      "200000/200000 [==============================] - 4s 19us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 58/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 59/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 60/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 61/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 62/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 63/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 64/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 65/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 66/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 67/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 68/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 69/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 70/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 71/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 72/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 73/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 74/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 75/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 76/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 77/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 78/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 79/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 80/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 81/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 82/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 83/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 84/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 85/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 86/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 87/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 88/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 89/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 90/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 91/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 92/99\n",
      "200000/200000 [==============================] - 4s 20us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 93/99\n",
      "200000/200000 [==============================] - 4s 22us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 94/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 95/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 96/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 97/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 98/99\n",
      "200000/200000 [==============================] - 5s 24us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "Epoch 99/99\n",
      "200000/200000 [==============================] - 4s 21us/step - loss: 0.0017 - acc: 0.9983 - val_loss: 0.0017 - val_acc: 0.9982\n",
      "50000/50000 [==============================] - 1s 23us/step\n"
     ]
    }
   ],
   "source": [
    "mlp_summary, mlp_fit, mlp_evaluate, mlp_prediction_acc, mlp_model = mlp_pre(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy: 99.824%\n"
     ]
    }
   ],
   "source": [
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. RNN - Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss: 0.0014\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0012\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0012\n",
      "Train Score: 0.03 RMSE\n",
      "Test Score: 0.03 RMSE\n",
      "RNN accuracy: 92.27680000000001%\n"
     ]
    }
   ],
   "source": [
    "rnn_acc = rnn_pre(df_train)\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 99.92%\n",
      "Gradient Boosting accuracy: 99.634%\n",
      "Logistic Regression accuracy: 99.824%\n",
      "SVM accuracy: 99.824%\n",
      "ANN accuracy: 99.824%\n",
      "MLP accuracy: 99.824%\n",
      "RNN accuracy: 92.27680000000001%\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest accuracy: {}%'.format(RF_acc * 100))\n",
    "print('Gradient Boosting accuracy: {}%'.format(GB_acc * 100))\n",
    "print('Logistic Regression accuracy: {}%'.format(LG_acc * 100))\n",
    "print('SVM accuracy: {}%'.format(svm_acc * 100))\n",
    "print('ANN accuracy: {}%'.format(ann_prediction_acc * 100))\n",
    "print('MLP accuracy: {}%'.format(mlp_prediction_acc * 100))\n",
    "print('RNN accuracy: {}%'.format(rnn_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is the best one for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'app',\n",
       " 'device',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second',\n",
       " 'ip_confRate',\n",
       " 'app_confRate',\n",
       " 'device_confRate',\n",
       " 'os_confRate',\n",
       " 'channel_confRate',\n",
       " 'app_channel_confRate',\n",
       " 'app_os_confRate',\n",
       " 'app_device_confRate',\n",
       " 'channel_os_confRate',\n",
       " 'channel_device_confRate',\n",
       " 'os_device_confRate',\n",
       " 'ip_app_channel_var_day',\n",
       " 'ip_app_os_var_hour',\n",
       " 'ip_day_channel_var_hour_x',\n",
       " 'ip_day_hour_count_channel',\n",
       " 'ip_app_count_channel',\n",
       " 'ip_app_os_count_channel',\n",
       " 'ip_app_day_hour_count_channel',\n",
       " 'ip_app_channel_mean_hour',\n",
       " 'app_AvgViewPerDistinct_ip',\n",
       " 'app_count_channel',\n",
       " 'channel_count_app',\n",
       " 'ip_nunique_channel',\n",
       " 'ip_nunique_app',\n",
       " 'ip_day_nunique_hour',\n",
       " 'ip_app_nunique_os',\n",
       " 'ip_nunique_device',\n",
       " 'app_nunique_channel',\n",
       " 'ip_device_os_nunique_app',\n",
       " 'ip_device_os_cumcount_app',\n",
       " 'ip_cumcount_app',\n",
       " 'ip_cumcount_os',\n",
       " 'ip_day_channel_var_hour_y',\n",
       " 'ip_nextClick',\n",
       " 'ip_app_nextClick',\n",
       " 'ip_channel_nextClick',\n",
       " 'ip_os_nextClick',\n",
       " 'ip_app_device_os_channel_nextClick',\n",
       " 'ip_os_device_nextClick',\n",
       " 'ip_os_device_app_nextClick',\n",
       " 'prev_identical_clicks',\n",
       " 'future_identical_clicks',\n",
       " 'prev_app_clicks',\n",
       " 'future_app_clicks']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns for our current analsis\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "df = pd.read_csv('data/test_small_all_features.csv')[train_cols].astype('float64')\n",
    "df = np.nan_to_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the output of the test data\n",
    "sample_out = pd.read_csv('data/sample_submission.csv', nrows=1000000)[['is_attributed']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_predict = rf_model.predict(df)\n",
    "# Compare the prediction with the known values\n",
    "df_acc = sklearn.metrics.accuracy_score(np.array(df_predict)[:], \n",
    "                                         np.array(sample_out)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using the best algorittm, the accuracy of the prediction: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print('By using the best algorittm, the accuracy of the prediction: {}%'.format(df_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the document is licensed under the MIT License: https://opensource.org/licenses/MIT\n",
    "\n",
    "All writing in the document is licensed bt The Creative Commons Attribution 3.0 https://creativecommons.org/licenses/by/3.0/us/."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
